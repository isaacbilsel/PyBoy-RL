{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacbilsel/PyBoy-RL/blob/Baseline_DDQN/PyBoy_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J64vmJA4gR0w",
        "outputId": "04f8d97c-092e-4dd2-aeb3-dbfceeb5cd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyBoy-RL'...\n",
            "remote: Enumerating objects: 314, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 314 (delta 15), reused 8 (delta 8), pack-reused 298 (from 1)\u001b[K\n",
            "Receiving objects: 100% (314/314), 327.05 MiB | 17.13 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/isaacbilsel/PyBoy-RL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PyBoy-RL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_ArUsACgkJ_",
        "outputId": "7183670d-24ef-41a7-9fc8-7c35a327f10d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyBoy-RL/PyBoy-RL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install libsdl2-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lDkUUYNig2D5",
        "outputId": "54fe1916-9fd2-4c44-de12-8f98acdc21ea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsdl2-dev is already the newest version (2.0.20+dfsg-2ubuntu1.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LMTBtVkbwI_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip3 install pyboy==1.4.7"
      ],
      "metadata": {
        "id": "hfDa6zJtiPx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==65.5.0 \"wheel<0.40.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "b5WnvXnImyY4",
        "outputId": "431e0fad-4ffd-4908-e559-d5aeff0f1e64",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting setuptools==65.5.0\n",
            "  Downloading setuptools-65.5.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting wheel<0.40.0\n",
            "  Downloading wheel-0.38.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: wheel, setuptools\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-65.5.0 wheel-0.38.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "26da60495f3b4f5781812e8e30806154"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install gym==0.22.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "16lHb_pPkxWA",
        "outputId": "082192d6-473a-4e05-b3ee-24bc8672864c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.22.0\n",
            "  Using cached gym-0.22.0.tar.gz (631 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (1.21.5)\n",
            "Collecting cloudpickle>=1.2.0 (from gym==0.22.0)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gym_notices>=0.0.4 (from gym==0.22.0)\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.22.0-py3-none-any.whl size=708477 sha256=03583a2b3c2d4d14d5c4f440838ff41ef7b7250c660ce79dcf972e2b7c73518c\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/e8/e8/6dfbc92a1dcd76c1a5e2bb982750fd6b7e792239f46039e6b1\n",
            "Successfully built gym\n",
            "Installing collected packages: gym_notices, cloudpickle, gym\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [gym]\n",
            "\u001b[1A\u001b[2KSuccessfully installed cloudpickle-3.1.1 gym-0.22.0 gym_notices-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downgrade python version. Most of these library versions used for this code need <python3.11\n",
        "# Select python 3.10 here (type 1 in user input box)\n",
        "!apt-get update -y\n",
        "!apt-get install python3.10 python3.10-distutils\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!update-alternatives --config python3\n",
        "!apt-get install python3-pip\n",
        "!python3 -m pip install --upgrade pip --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z5KIM8D2F_-C",
        "outputId": "7351e272-84cc-4c0b-f819-2f93143f5d82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,607 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [47.4 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,701 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,543 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,154 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,863 kB]\n",
            "Fetched 18.3 MB in 5s (4,015 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.9).\n",
            "python3.10 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "update-alternatives: error: alternative path /usr/bin/python3.8 doesn't exist\n",
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.11   2         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.11   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 1\n",
            "update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in manual mode\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,968 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.2 [340 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.5 [1,306 kB]\n",
            "Fetched 1,677 kB in 2s (676 kB/s)\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 127576 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed pip-25.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "j5pqbVqwNnru",
        "outputId": "a7c8ddbe-e1eb-4a6e-c48d-36898dd0df09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install matplotlib==3.5.1\n",
        "!pip3 install scikit-image==0.19.2\n",
        "!pip install matplotlib-inline\n",
        "!pip install ipython\n",
        "!pip install numpy==1.23.5\n",
        "!pip3 install opencv-python==4.5.5.64\n",
        "!pip3 install numpy==1.21.5\n",
        "!pip install torch==2.4\n",
        "!pip install torchvision==0.19"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ll_BHhaBl2c4",
        "outputId": "6a3c314f-e000-40f8-960d-0d3f163d0a85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.5.1)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.5.1)\n",
            "  Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.5.1)\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting numpy>=1.17 (from matplotlib==3.5.1)\n",
            "  Downloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib==3.5.1)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pillow>=6.2.0 (from matplotlib==3.5.1)\n",
            "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib==3.5.1) (2.4.7)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib==3.5.1)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1) (1.16.0)\n",
            "Downloading matplotlib-3.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m149.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Installing collected packages: python-dateutil, pillow, packaging, numpy, kiwisolver, fonttools, cycler, matplotlib\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [matplotlib]\n",
            "\u001b[1A\u001b[2KSuccessfully installed cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.5.1 numpy-2.2.5 packaging-25.0 pillow-11.2.1 python-dateutil-2.9.0.post0\n",
            "Collecting scikit-image==0.19.2\n",
            "  Downloading scikit_image-0.19.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.2) (2.2.5)\n",
            "Collecting scipy>=1.4.1 (from scikit-image==0.19.2)\n",
            "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting networkx>=2.2 (from scikit-image==0.19.2)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.2) (11.2.1)\n",
            "Collecting imageio>=2.4.1 (from scikit-image==0.19.2)\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting tifffile>=2019.7.26 (from scikit-image==0.19.2)\n",
            "  Downloading tifffile-2025.3.30-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting PyWavelets>=1.1.1 (from scikit-image==0.19.2)\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.2) (25.0)\n",
            "Downloading scikit_image-0.19.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m144.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tifffile-2025.3.30-py3-none-any.whl (226 kB)\n",
            "Installing collected packages: tifffile, scipy, PyWavelets, networkx, imageio, scikit-image\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [scikit-image]\n",
            "\u001b[1A\u001b[2KSuccessfully installed PyWavelets-1.8.0 imageio-2.37.0 networkx-3.4.2 scikit-image-0.19.2 scipy-1.15.2 tifffile-2025.3.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIl6M2ZkqAsL",
        "outputId": "f94186e4-b524-48ce-fa7e-8ea725dbf367"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting filelock (from torch==2.4)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (4.13.2)\n",
            "Collecting sympy (from torch==2.4)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (3.4.2)\n",
            "Collecting jinja2 (from torch==2.4)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.4)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.4) (2.0.1)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m161.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m141.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jinja2, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 1.11.0\n",
            "\u001b[2K    Uninstalling torch-1.11.0:\n",
            "\u001b[2K      Successfully uninstalled torch-1.11.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [torch]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0 requires torch==1.11.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.0 triton-3.0.0\n",
            "Collecting torchvision==0.19\n",
            "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (1.23.5)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (2.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->torchvision==0.19) (12.8.93)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.4.0->torchvision==0.19) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision==0.19) (1.3.0)\n",
            "Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0\n",
            "    Uninstalling torchvision-0.12.0:\n",
            "      Successfully uninstalled torchvision-0.12.0\n",
            "Successfully installed torchvision-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PyBoy-RL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CuL-ai6jVz6",
        "outputId": "b7a3a044-c610-419f-8819-ae27c48221a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyBoy-RL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUyIpNyIjXp5",
        "outputId": "13c8c1ed-2f24-4f0f-e1d4-aa3ffcde54da"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UserWarning: Using SDL2 binaries from pysdl2-dll 2.32.0\n",
            "\n",
            "Avaliable games:  ['games/Kirby_Dream_Land.gb', 'games/Super_Mario_Land.gb']\n",
            "[1] games/Kirby_Dream_Land.gb\n",
            "[2] games/Super_Mario_Land.gb\n",
            "Select game[1-2]: 2\n",
            "[1] Evaluate (HEADLESS)\n",
            "[2] Evaluate (UI)\n",
            "[3] Train (HEADLESS)\n",
            "[4] Train (UI)\n",
            "[5] Playtest (UI)\n",
            "Select mode[1-5]: 4\n",
            "Possible actions:  [['PRESS_ARROW_RIGHT'], ['PRESS_BUTTON_A'], ['PRESS_ARROW_LEFT'], ['PRESS_ARROW_RIGHT', 'PRESS_BUTTON_A'], ['PRESS_BUTTON_A', 'PRESS_ARROW_LEFT']]\n",
            "Training mode\n",
            "Total Episodes:  400\n",
            "Episode 0 - Steps this episode 10100 - Epsilon 0.001 - Learning Rate 0.0002499993625010201 - Cummulative Reward -40.0 - Max Length 373 - Mean Loss 0.204 - Mean Q Value -0.099 - Time Delta 63.267 - Time 2025-04-26T20:09:09\n",
            "Episode 1 - Steps this episode 10357 - Epsilon 0.001 - Learning Rate 0.00024999713126797784 - Cummulative Reward 54.5 - Max Length 373 - Mean Loss 0.219 - Mean Q Value -0.091 - Time Delta 2.226 - Time 2025-04-26T20:09:12\n",
            "Episode 2 - Steps this episode 10611 - Epsilon 0.001 - Learning Rate 0.00024999392507504917 - Cummulative Reward 86.0 - Max Length 373 - Mean Loss 0.22 - Mean Q Value -0.077 - Time Delta 2.198 - Time 2025-04-26T20:09:14\n",
            "Episode 3 - Steps this episode 10865 - Epsilon 0.001 - Learning Rate 0.0002499907564218533 - Cummulative Reward 101.75 - Max Length 373 - Mean Loss 0.23 - Mean Q Value -0.06 - Time Delta 2.367 - Time 2025-04-26T20:09:16\n",
            "Episode 4 - Steps this episode 11119 - Epsilon 0.001 - Learning Rate 0.00024998758780889923 - Cummulative Reward 111.2 - Max Length 373 - Mean Loss 0.232 - Mean Q Value 0.03 - Time Delta 2.194 - Time 2025-04-26T20:09:18\n",
            "Episode 5 - Steps this episode 11373 - Epsilon 0.001 - Learning Rate 0.00024998440048723536 - Cummulative Reward 117.5 - Max Length 373 - Mean Loss 0.238 - Mean Q Value 0.183 - Time Delta 2.216 - Time 2025-04-26T20:09:21\n",
            "Episode 6 - Steps this episode 11627 - Epsilon 0.001 - Learning Rate 0.00024998123195476305 - Cummulative Reward 122.0 - Max Length 373 - Mean Loss 0.252 - Mean Q Value 0.292 - Time Delta 2.225 - Time 2025-04-26T20:09:23\n",
            "Episode 7 - Steps this episode 11881 - Epsilon 0.001 - Learning Rate 0.00024997806346253084 - Cummulative Reward 125.375 - Max Length 373 - Mean Loss 0.25 - Mean Q Value 0.38 - Time Delta 2.208 - Time 2025-04-26T20:09:25\n",
            "Episode 8 - Steps this episode 12135 - Epsilon 0.001 - Learning Rate 0.00024997487626230157 - Cummulative Reward 128.0 - Max Length 373 - Mean Loss 0.267 - Mean Q Value 0.511 - Time Delta 2.197 - Time 2025-04-26T20:09:27\n",
            "Episode 9 - Steps this episode 12389 - Epsilon 0.001 - Learning Rate 0.00024997170785054807 - Cummulative Reward 130.1 - Max Length 373 - Mean Loss 0.273 - Mean Q Value 0.678 - Time Delta 2.202 - Time 2025-04-26T20:09:29\n",
            "Episode 10 - Steps this episode 12646 - Epsilon 0.001 - Learning Rate 0.0002499685207314316 - Cummulative Reward 131.818 - Max Length 373 - Mean Loss 0.277 - Mean Q Value 0.811 - Time Delta 2.206 - Time 2025-04-26T20:09:32\n",
            "Episode 11 - Steps this episode 12906 - Epsilon 0.001 - Learning Rate 0.0002499652774107137 - Cummulative Reward 133.167 - Max Length 373 - Mean Loss 0.287 - Mean Q Value 0.932 - Time Delta 2.294 - Time 2025-04-26T20:09:34\n",
            "Episode 12 - Steps this episode 13160 - Epsilon 0.001 - Learning Rate 0.00024996207162622796 - Cummulative Reward 134.385 - Max Length 373 - Mean Loss 0.297 - Mean Q Value 1.091 - Time Delta 2.2 - Time 2025-04-26T20:09:36\n",
            "Episode 13 - Steps this episode 13414 - Epsilon 0.001 - Learning Rate 0.0002499589033768513 - Cummulative Reward 135.429 - Max Length 373 - Mean Loss 0.302 - Mean Q Value 1.268 - Time Delta 2.208 - Time 2025-04-26T20:09:38\n",
            "Episode 14 - Steps this episode 13671 - Epsilon 0.001 - Learning Rate 0.00024995569767427225 - Cummulative Reward 136.333 - Max Length 373 - Mean Loss 0.307 - Mean Q Value 1.423 - Time Delta 2.417 - Time 2025-04-26T20:09:41\n",
            "Episode 15 - Steps this episode 13925 - Epsilon 0.001 - Learning Rate 0.00024995251075912543 - Cummulative Reward 137.125 - Max Length 373 - Mean Loss 0.309 - Mean Q Value 1.555 - Time Delta 2.201 - Time 2025-04-26T20:09:43\n",
            "Episode 16 - Steps this episode 14182 - Epsilon 0.001 - Learning Rate 0.00024994932388477074 - Cummulative Reward 137.824 - Max Length 373 - Mean Loss 0.315 - Mean Q Value 1.705 - Time Delta 2.256 - Time 2025-04-26T20:09:45\n",
            "Episode 17 - Steps this episode 14439 - Epsilon 0.001 - Learning Rate 0.0002499460995590483 - Cummulative Reward 138.444 - Max Length 373 - Mean Loss 0.323 - Mean Q Value 1.854 - Time Delta 2.272 - Time 2025-04-26T20:09:48\n",
            "Episode 18 - Steps this episode 14696 - Epsilon 0.001 - Learning Rate 0.000249942894020597 - Cummulative Reward 139.0 - Max Length 373 - Mean Loss 0.328 - Mean Q Value 1.99 - Time Delta 2.243 - Time 2025-04-26T20:09:50\n",
            "Episode 19 - Steps this episode 14953 - Epsilon 0.001 - Learning Rate 0.0002499396885233367 - Cummulative Reward 139.5 - Max Length 373 - Mean Loss 0.333 - Mean Q Value 2.111 - Time Delta 2.233 - Time 2025-04-26T20:09:52\n",
            "Episode 20 - Steps this episode 15207 - Epsilon 0.001 - Learning Rate 0.00024993648306710636 - Cummulative Reward 139.952 - Max Length 373 - Mean Loss 0.338 - Mean Q Value 2.26 - Time Delta 2.212 - Time 2025-04-26T20:09:54\n",
            "Episode 21 - Steps this episode 15464 - Epsilon 0.001 - Learning Rate 0.0002499332963970238 - Cummulative Reward 140.364 - Max Length 373 - Mean Loss 0.34 - Mean Q Value 2.407 - Time Delta 2.252 - Time 2025-04-26T20:09:56\n",
            "Episode 22 - Steps this episode 15718 - Epsilon 0.001 - Learning Rate 0.00024993010976757105 - Cummulative Reward 140.739 - Max Length 373 - Mean Loss 0.346 - Mean Q Value 2.537 - Time Delta 2.196 - Time 2025-04-26T20:09:59\n",
            "Episode 23 - Steps this episode 15975 - Epsilon 0.001 - Learning Rate 0.0002499269044342678 - Cummulative Reward 141.083 - Max Length 373 - Mean Loss 0.346 - Mean Q Value 2.66 - Time Delta 2.201 - Time 2025-04-26T20:10:01\n",
            "Episode 24 - Steps this episode 16229 - Epsilon 0.001 - Learning Rate 0.0002499237178862323 - Cummulative Reward 141.4 - Max Length 373 - Mean Loss 0.35 - Mean Q Value 2.802 - Time Delta 2.189 - Time 2025-04-26T20:10:03\n",
            "Episode 25 - Steps this episode 16483 - Epsilon 0.001 - Learning Rate 0.0002499205501229864 - Cummulative Reward 141.692 - Max Length 373 - Mean Loss 0.354 - Mean Q Value 2.939 - Time Delta 2.373 - Time 2025-04-26T20:10:05\n",
            "Episode 26 - Steps this episode 16740 - Epsilon 0.001 - Learning Rate 0.00024991734491228466 - Cummulative Reward 141.963 - Max Length 373 - Mean Loss 0.356 - Mean Q Value 3.065 - Time Delta 2.222 - Time 2025-04-26T20:10:08\n",
            "Episode 27 - Steps this episode 16995 - Epsilon 0.001 - Learning Rate 0.0002499141397426093 - Cummulative Reward 142.214 - Max Length 373 - Mean Loss 0.36 - Mean Q Value 3.183 - Time Delta 2.214 - Time 2025-04-26T20:10:10\n",
            "Episode 28 - Steps this episode 17252 - Epsilon 0.001 - Learning Rate 0.00024991095335740224 - Cummulative Reward 142.448 - Max Length 373 - Mean Loss 0.365 - Mean Q Value 3.324 - Time Delta 2.222 - Time 2025-04-26T20:10:12\n",
            "Episode 29 - Steps this episode 17507 - Epsilon 0.001 - Learning Rate 0.00024990776701282137 - Cummulative Reward 142.667 - Max Length 373 - Mean Loss 0.37 - Mean Q Value 3.451 - Time Delta 2.192 - Time 2025-04-26T20:10:14\n",
            "Episode 30 - Steps this episode 17761 - Epsilon 0.001 - Learning Rate 0.0002499045807088663 - Cummulative Reward 142.871 - Max Length 373 - Mean Loss 0.373 - Mean Q Value 3.573 - Time Delta 2.21 - Time 2025-04-26T20:10:16\n",
            "Episode 31 - Steps this episode 18018 - Epsilon 0.001 - Learning Rate 0.00024990137570297103 - Cummulative Reward 143.062 - Max Length 373 - Mean Loss 0.373 - Mean Q Value 3.69 - Time Delta 2.223 - Time 2025-04-26T20:10:19\n",
            "Episode 32 - Steps this episode 18272 - Epsilon 0.001 - Learning Rate 0.0002498981894804249 - Cummulative Reward 143.242 - Max Length 373 - Mean Loss 0.375 - Mean Q Value 3.81 - Time Delta 2.22 - Time 2025-04-26T20:10:21\n",
            "Episode 33 - Steps this episode 18526 - Epsilon 0.001 - Learning Rate 0.0002498950220407495 - Cummulative Reward 143.412 - Max Length 373 - Mean Loss 0.376 - Mean Q Value 3.92 - Time Delta 2.281 - Time 2025-04-26T20:10:23\n",
            "Episode 34 - Steps this episode 18783 - Epsilon 0.001 - Learning Rate 0.0002498918171574433 - Cummulative Reward 143.571 - Max Length 373 - Mean Loss 0.377 - Mean Q Value 4.025 - Time Delta 2.22 - Time 2025-04-26T20:10:25\n",
            "Episode 35 - Steps this episode 19037 - Epsilon 0.001 - Learning Rate 0.0002498886310567679 - Cummulative Reward 143.722 - Max Length 373 - Mean Loss 0.38 - Mean Q Value 4.126 - Time Delta 2.207 - Time 2025-04-26T20:10:28\n",
            "Episode 36 - Steps this episode 19294 - Epsilon 0.001 - Learning Rate 0.00024988544499687424 - Cummulative Reward 143.865 - Max Length 373 - Mean Loss 0.381 - Mean Q Value 4.232 - Time Delta 2.432 - Time 2025-04-26T20:10:30\n",
            "Episode 37 - Steps this episode 19548 - Epsilon 0.001 - Learning Rate 0.00024988224023631293 - Cummulative Reward 144.0 - Max Length 373 - Mean Loss 0.383 - Mean Q Value 4.335 - Time Delta 2.197 - Time 2025-04-26T20:10:32\n",
            "Episode 38 - Steps this episode 19802 - Epsilon 0.001 - Learning Rate 0.0002498790729987138 - Cummulative Reward 144.128 - Max Length 373 - Mean Loss 0.386 - Mean Q Value 4.434 - Time Delta 2.221 - Time 2025-04-26T20:10:34\n",
            "Episode 39 - Steps this episode 20059 - Epsilon 0.001 - Learning Rate 0.0002498758870606847 - Cummulative Reward 144.25 - Max Length 373 - Mean Loss 0.386 - Mean Q Value 4.531 - Time Delta 2.246 - Time 2025-04-26T20:10:37\n",
            "Episode 40 - Steps this episode 20313 - Epsilon 0.001 - Learning Rate 0.00024987268242270303 - Cummulative Reward 144.366 - Max Length 373 - Mean Loss 0.387 - Mean Q Value 4.638 - Time Delta 2.22 - Time 2025-04-26T20:10:39\n",
            "Episode 41 - Steps this episode 20570 - Epsilon 0.001 - Learning Rate 0.0002498694965660736 - Cummulative Reward 144.476 - Max Length 373 - Mean Loss 0.39 - Mean Q Value 4.738 - Time Delta 2.245 - Time 2025-04-26T20:10:41\n",
            "Episode 42 - Steps this episode 20824 - Epsilon 0.001 - Learning Rate 0.0002498663107500635 - Cummulative Reward 144.581 - Max Length 373 - Mean Loss 0.393 - Mean Q Value 4.834 - Time Delta 2.183 - Time 2025-04-26T20:10:43\n",
            "Episode 43 - Steps this episode 21081 - Epsilon 0.001 - Learning Rate 0.00024986310623497727 - Cummulative Reward 144.682 - Max Length 373 - Mean Loss 0.396 - Mean Q Value 4.929 - Time Delta 2.229 - Time 2025-04-26T20:10:46\n",
            "Episode 44 - Steps this episode 21340 - Epsilon 0.001 - Learning Rate 0.00024985988302145544 - Cummulative Reward 144.778 - Max Length 373 - Mean Loss 0.397 - Mean Q Value 5.03 - Time Delta 2.243 - Time 2025-04-26T20:10:48\n",
            "Episode 45 - Steps this episode 21594 - Epsilon 0.001 - Learning Rate 0.0002498566785887243 - Cummulative Reward 144.87 - Max Length 373 - Mean Loss 0.398 - Mean Q Value 5.124 - Time Delta 2.202 - Time 2025-04-26T20:10:50\n",
            "Episode 46 - Steps this episode 21848 - Epsilon 0.001 - Learning Rate 0.00024985351167511685 - Cummulative Reward 144.957 - Max Length 373 - Mean Loss 0.399 - Mean Q Value 5.216 - Time Delta 2.192 - Time 2025-04-26T20:10:52\n",
            "Episode 47 - Steps this episode 22105 - Epsilon 0.001 - Learning Rate 0.0002498503260629925 - Cummulative Reward 145.042 - Max Length 373 - Mean Loss 0.4 - Mean Q Value 5.308 - Time Delta 2.205 - Time 2025-04-26T20:10:54\n",
            "Episode 48 - Steps this episode 22359 - Epsilon 0.001 - Learning Rate 0.0002498471217528287 - Cummulative Reward 145.122 - Max Length 373 - Mean Loss 0.401 - Mean Q Value 5.403 - Time Delta 2.181 - Time 2025-04-26T20:10:57\n",
            "Episode 49 - Steps this episode 22616 - Epsilon 0.001 - Learning Rate 0.0002498439362220958 - Cummulative Reward 145.2 - Max Length 373 - Mean Loss 0.402 - Mean Q Value 5.494 - Time Delta 2.49 - Time 2025-04-26T20:10:59\n",
            "Episode 50 - Steps this episode 22870 - Epsilon 0.001 - Learning Rate 0.0002498407507319781 - Cummulative Reward 145.275 - Max Length 373 - Mean Loss 0.403 - Mean Q Value 5.58 - Time Delta 2.207 - Time 2025-04-26T20:11:01\n",
            "Episode 51 - Steps this episode 23127 - Epsilon 0.001 - Learning Rate 0.000249837546544697 - Cummulative Reward 145.346 - Max Length 373 - Mean Loss 0.405 - Mean Q Value 5.668 - Time Delta 2.249 - Time 2025-04-26T20:11:04\n",
            "Episode 52 - Steps this episode 23381 - Epsilon 0.001 - Learning Rate 0.00024983436113596753 - Cummulative Reward 145.415 - Max Length 373 - Mean Loss 0.407 - Mean Q Value 5.754 - Time Delta 2.219 - Time 2025-04-26T20:11:06\n",
            "Episode 53 - Steps this episode 23635 - Epsilon 0.001 - Learning Rate 0.0002498311945053112 - Cummulative Reward 145.481 - Max Length 373 - Mean Loss 0.408 - Mean Q Value 5.839 - Time Delta 2.23 - Time 2025-04-26T20:11:08\n",
            "Episode 54 - Steps this episode 23889 - Epsilon 0.001 - Learning Rate 0.0002498280091776495 - Cummulative Reward 145.545 - Max Length 373 - Mean Loss 0.408 - Mean Q Value 5.922 - Time Delta 2.252 - Time 2025-04-26T20:11:10\n",
            "Episode 55 - Steps this episode 24143 - Epsilon 0.001 - Learning Rate 0.0002498248426274246 - Cummulative Reward 145.607 - Max Length 373 - Mean Loss 0.41 - Mean Q Value 6.004 - Time Delta 2.235 - Time 2025-04-26T20:11:13\n",
            "Episode 56 - Steps this episode 24397 - Epsilon 0.001 - Learning Rate 0.0002498216761174147 - Cummulative Reward 145.667 - Max Length 373 - Mean Loss 0.412 - Mean Q Value 6.086 - Time Delta 2.235 - Time 2025-04-26T20:11:15\n",
            "Episode 57 - Steps this episode 24654 - Epsilon 0.001 - Learning Rate 0.00024981847217476414 - Cummulative Reward 145.724 - Max Length 373 - Mean Loss 0.413 - Mean Q Value 6.163 - Time Delta 2.244 - Time 2025-04-26T20:11:17\n",
            "Episode 58 - Steps this episode 24908 - Epsilon 0.001 - Learning Rate 0.00024981528700923134 - Cummulative Reward 145.78 - Max Length 373 - Mean Loss 0.415 - Mean Q Value 6.237 - Time Delta 2.217 - Time 2025-04-26T20:11:19\n",
            "Episode 59 - Steps this episode 25162 - Epsilon 0.001 - Learning Rate 0.0002498121206203381 - Cummulative Reward 145.833 - Max Length 373 - Mean Loss 0.416 - Mean Q Value 6.312 - Time Delta 2.226 - Time 2025-04-26T20:11:21\n",
            "Episode 60 - Steps this episode 25417 - Epsilon 0.001 - Learning Rate 0.00024980893553586673 - Cummulative Reward 145.885 - Max Length 373 - Mean Loss 0.417 - Mean Q Value 6.388 - Time Delta 2.259 - Time 2025-04-26T20:11:24\n",
            "Episode 61 - Steps this episode 25670 - Epsilon 0.001 - Learning Rate 0.0002498057692273988 - Cummulative Reward 145.935 - Max Length 373 - Mean Loss 0.418 - Mean Q Value 6.46 - Time Delta 2.224 - Time 2025-04-26T20:11:26\n",
            "Episode 62 - Steps this episode 25929 - Epsilon 0.001 - Learning Rate 0.0002498025654888328 - Cummulative Reward 145.984 - Max Length 373 - Mean Loss 0.419 - Mean Q Value 6.531 - Time Delta 2.266 - Time 2025-04-26T20:11:28\n",
            "Episode 63 - Steps this episode 26183 - Epsilon 0.001 - Learning Rate 0.0002497993617911143 - Cummulative Reward 146.031 - Max Length 373 - Mean Loss 0.42 - Mean Q Value 6.601 - Time Delta 2.479 - Time 2025-04-26T20:11:31\n",
            "Episode 64 - Steps this episode 26436 - Epsilon 0.001 - Learning Rate 0.00024979619560407194 - Cummulative Reward 146.077 - Max Length 373 - Mean Loss 0.42 - Mean Q Value 6.672 - Time Delta 2.229 - Time 2025-04-26T20:11:33\n",
            "Episode 65 - Steps this episode 26692 - Epsilon 0.001 - Learning Rate 0.00024979301072264337 - Cummulative Reward 146.121 - Max Length 373 - Mean Loss 0.421 - Mean Q Value 6.738 - Time Delta 2.259 - Time 2025-04-26T20:11:35\n",
            "Episode 66 - Steps this episode 26946 - Epsilon 0.001 - Learning Rate 0.0002497898258818217 - Cummulative Reward 146.164 - Max Length 373 - Mean Loss 0.422 - Mean Q Value 6.803 - Time Delta 2.222 - Time 2025-04-26T20:11:37\n",
            "Episode 67 - Steps this episode 27200 - Epsilon 0.001 - Learning Rate 0.000249786659815567 - Cummulative Reward 146.206 - Max Length 373 - Mean Loss 0.422 - Mean Q Value 6.867 - Time Delta 2.221 - Time 2025-04-26T20:11:40\n",
            "Episode 68 - Steps this episode 27457 - Epsilon 0.001 - Learning Rate 0.0002497834750557985 - Cummulative Reward 146.246 - Max Length 373 - Mean Loss 0.423 - Mean Q Value 6.931 - Time Delta 2.263 - Time 2025-04-26T20:11:42\n",
            "Episode 69 - Steps this episode 27711 - Epsilon 0.001 - Learning Rate 0.00024978027160299336 - Cummulative Reward 146.286 - Max Length 373 - Mean Loss 0.424 - Mean Q Value 6.993 - Time Delta 2.214 - Time 2025-04-26T20:11:44\n",
            "Episode 70 - Steps this episode 27970 - Epsilon 0.001 - Learning Rate 0.00024977706819135227 - Cummulative Reward 146.324 - Max Length 373 - Mean Loss 0.425 - Mean Q Value 7.052 - Time Delta 2.296 - Time 2025-04-26T20:11:46\n",
            "Episode 71 - Steps this episode 28227 - Epsilon 0.001 - Learning Rate 0.0002497738460877141 - Cummulative Reward 146.361 - Max Length 373 - Mean Loss 0.426 - Mean Q Value 7.112 - Time Delta 2.291 - Time 2025-04-26T20:11:49\n",
            "Episode 72 - Steps this episode 28481 - Epsilon 0.001 - Learning Rate 0.00024977066149116015 - Cummulative Reward 146.397 - Max Length 373 - Mean Loss 0.427 - Mean Q Value 7.172 - Time Delta 2.23 - Time 2025-04-26T20:11:51\n",
            "Episode 73 - Steps this episode 28734 - Epsilon 0.001 - Learning Rate 0.0002497674956678922 - Cummulative Reward 146.432 - Max Length 373 - Mean Loss 0.429 - Mean Q Value 7.23 - Time Delta 2.231 - Time 2025-04-26T20:11:53\n",
            "Episode 74 - Steps this episode 28988 - Epsilon 0.001 - Learning Rate 0.00024976432988467164 - Cummulative Reward 146.467 - Max Length 373 - Mean Loss 0.43 - Mean Q Value 7.286 - Time Delta 2.218 - Time 2025-04-26T20:11:55\n",
            "Episode 75 - Steps this episode 29241 - Epsilon 0.001 - Learning Rate 0.0002497611641416557 - Cummulative Reward 146.5 - Max Length 373 - Mean Loss 0.431 - Mean Q Value 7.343 - Time Delta 2.469 - Time 2025-04-26T20:11:58\n",
            "Episode 76 - Steps this episode 29495 - Epsilon 0.001 - Learning Rate 0.0002497579984386864 - Cummulative Reward 146.532 - Max Length 373 - Mean Loss 0.432 - Mean Q Value 7.399 - Time Delta 2.261 - Time 2025-04-26T20:12:00\n",
            "Episode 77 - Steps this episode 29752 - Epsilon 0.001 - Learning Rate 0.0002497548140443482 - Cummulative Reward 146.564 - Max Length 373 - Mean Loss 0.432 - Mean Q Value 7.452 - Time Delta 2.25 - Time 2025-04-26T20:12:02\n",
            "Episode 78 - Steps this episode 30009 - Epsilon 0.001 - Learning Rate 0.00024975159222778666 - Cummulative Reward 146.595 - Max Length 373 - Mean Loss 0.433 - Mean Q Value 7.505 - Time Delta 2.238 - Time 2025-04-26T20:12:05\n",
            "Episode 79 - Steps this episode 30264 - Epsilon 0.001 - Learning Rate 0.0002497483891838761 - Cummulative Reward 146.625 - Max Length 373 - Mean Loss 0.435 - Mean Q Value 7.558 - Time Delta 2.216 - Time 2025-04-26T20:12:07\n",
            "Episode 80 - Steps this episode 30518 - Epsilon 0.001 - Learning Rate 0.0002497452236428283 - Cummulative Reward 146.654 - Max Length 373 - Mean Loss 0.436 - Mean Q Value 7.608 - Time Delta 2.222 - Time 2025-04-26T20:12:09\n",
            "Episode 81 - Steps this episode 30775 - Epsilon 0.001 - Learning Rate 0.0002497420394113677 - Cummulative Reward 146.683 - Max Length 373 - Mean Loss 0.437 - Mean Q Value 7.657 - Time Delta 2.282 - Time 2025-04-26T20:12:11\n",
            "Episode 82 - Steps this episode 31029 - Epsilon 0.001 - Learning Rate 0.00024973883648997115 - Cummulative Reward 146.711 - Max Length 373 - Mean Loss 0.439 - Mean Q Value 7.704 - Time Delta 2.235 - Time 2025-04-26T20:12:14\n",
            "Episode 83 - Steps this episode 31282 - Epsilon 0.001 - Learning Rate 0.0002497356710700032 - Cummulative Reward 146.738 - Max Length 373 - Mean Loss 0.44 - Mean Q Value 7.75 - Time Delta 2.176 - Time 2025-04-26T20:12:16\n",
            "Episode 84 - Steps this episode 31536 - Epsilon 0.001 - Learning Rate 0.0002497325056902357 - Cummulative Reward 146.765 - Max Length 373 - Mean Loss 0.441 - Mean Q Value 7.795 - Time Delta 2.198 - Time 2025-04-26T20:12:18\n",
            "Episode 85 - Steps this episode 31790 - Epsilon 0.001 - Learning Rate 0.00024972934035050995 - Cummulative Reward 146.791 - Max Length 373 - Mean Loss 0.442 - Mean Q Value 7.839 - Time Delta 2.184 - Time 2025-04-26T20:12:20\n",
            "Episode 86 - Steps this episode 32044 - Epsilon 0.001 - Learning Rate 0.0002497261750509838 - Cummulative Reward 146.816 - Max Length 373 - Mean Loss 0.442 - Mean Q Value 7.883 - Time Delta 2.221 - Time 2025-04-26T20:12:22\n",
            "Episode 87 - Steps this episode 32298 - Epsilon 0.001 - Learning Rate 0.00024972299106231155 - Cummulative Reward 146.841 - Max Length 373 - Mean Loss 0.443 - Mean Q Value 7.925 - Time Delta 2.271 - Time 2025-04-26T20:12:25\n",
            "Episode 88 - Steps this episode 32555 - Epsilon 0.001 - Learning Rate 0.00024971980711423485 - Cummulative Reward 146.865 - Max Length 373 - Mean Loss 0.443 - Mean Q Value 7.967 - Time Delta 2.235 - Time 2025-04-26T20:12:27\n",
            "Episode 89 - Steps this episode 32809 - Epsilon 0.001 - Learning Rate 0.00024971662320675316 - Cummulative Reward 146.889 - Max Length 373 - Mean Loss 0.444 - Mean Q Value 8.007 - Time Delta 2.471 - Time 2025-04-26T20:12:29\n",
            "Episode 90 - Steps this episode 33063 - Epsilon 0.001 - Learning Rate 0.0002497134393398663 - Cummulative Reward 146.912 - Max Length 373 - Mean Loss 0.444 - Mean Q Value 8.046 - Time Delta 2.218 - Time 2025-04-26T20:12:31\n",
            "Episode 91 - Steps this episode 33317 - Epsilon 0.001 - Learning Rate 0.000249710274241805 - Cummulative Reward 146.935 - Max Length 373 - Mean Loss 0.445 - Mean Q Value 8.085 - Time Delta 2.206 - Time 2025-04-26T20:12:34\n",
            "Episode 92 - Steps this episode 33570 - Epsilon 0.001 - Learning Rate 0.00024970710918394015 - Cummulative Reward 146.957 - Max Length 373 - Mean Loss 0.446 - Mean Q Value 8.123 - Time Delta 2.221 - Time 2025-04-26T20:12:36\n",
            "Episode 93 - Steps this episode 33827 - Epsilon 0.001 - Learning Rate 0.0002497039254383562 - Cummulative Reward 146.979 - Max Length 373 - Mean Loss 0.447 - Mean Q Value 8.16 - Time Delta 2.25 - Time 2025-04-26T20:12:38\n",
            "Episode 94 - Steps this episode 34081 - Epsilon 0.001 - Learning Rate 0.0002497007417333648 - Cummulative Reward 147.0 - Max Length 373 - Mean Loss 0.448 - Mean Q Value 8.196 - Time Delta 2.215 - Time 2025-04-26T20:12:40\n",
            "Episode 95 - Steps this episode 34340 - Epsilon 0.001 - Learning Rate 0.0002496975393416878 - Cummulative Reward 147.021 - Max Length 373 - Mean Loss 0.449 - Mean Q Value 8.235 - Time Delta 2.248 - Time 2025-04-26T20:12:43\n",
            "Episode 96 - Steps this episode 34601 - Epsilon 0.001 - Learning Rate 0.00024969429953693113 - Cummulative Reward 146.99 - Max Length 373 - Mean Loss 0.45 - Mean Q Value 8.271 - Time Delta 2.256 - Time 2025-04-26T20:12:45\n",
            "Episode 97 - Steps this episode 34858 - Epsilon 0.001 - Learning Rate 0.00024969105977412973 - Cummulative Reward 147.01 - Max Length 373 - Mean Loss 0.45 - Mean Q Value 8.307 - Time Delta 2.288 - Time 2025-04-26T20:12:47\n",
            "Episode 98 - Steps this episode 35116 - Epsilon 0.001 - Learning Rate 0.000249687838779993 - Cummulative Reward 147.03 - Max Length 373 - Mean Loss 0.451 - Mean Q Value 8.344 - Time Delta 2.295 - Time 2025-04-26T20:12:49\n",
            "Episode 99 - Steps this episode 35370 - Epsilon 0.001 - Learning Rate 0.00024968463655371525 - Cummulative Reward 147.05 - Max Length 373 - Mean Loss 0.453 - Mean Q Value 8.381 - Time Delta 2.235 - Time 2025-04-26T20:12:52\n",
            "Episode 100 - Steps this episode 35624 - Epsilon 0.001 - Learning Rate 0.00024968147182072704 - Cummulative Reward 148.94 - Max Length 373 - Mean Loss 0.456 - Mean Q Value 8.501 - Time Delta 2.241 - Time 2025-04-26T20:12:54\n",
            "Episode 101 - Steps this episode 35878 - Epsilon 0.001 - Learning Rate 0.00024967830712793076 - Cummulative Reward 148.94 - Max Length 373 - Mean Loss 0.458 - Mean Q Value 8.622 - Time Delta 2.229 - Time 2025-04-26T20:12:56\n",
            "Episode 102 - Steps this episode 36143 - Epsilon 0.001 - Learning Rate 0.00024967506757279153 - Cummulative Reward 148.91 - Max Length 373 - Mean Loss 0.462 - Mean Q Value 8.742 - Time Delta 2.339 - Time 2025-04-26T20:12:59\n",
            "Episode 103 - Steps this episode 38439 - Epsilon 0.001 - Learning Rate 0.0002496590765311604 - Cummulative Reward 150.06 - Max Length 691 - Mean Loss 0.465 - Mean Q Value 8.864 - Time Delta 19.487 - Time 2025-04-26T20:13:18\n",
            "Episode 104 - Steps this episode 38693 - Epsilon 0.001 - Learning Rate 0.0002496431611354716 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.468 - Mean Q Value 8.983 - Time Delta 2.221 - Time 2025-04-26T20:13:20\n",
            "Episode 105 - Steps this episode 38947 - Epsilon 0.001 - Learning Rate 0.00024963999692826017 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.471 - Mean Q Value 9.096 - Time Delta 2.22 - Time 2025-04-26T20:13:22\n",
            "Episode 106 - Steps this episode 39201 - Epsilon 0.001 - Learning Rate 0.00024963681403835205 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.472 - Mean Q Value 9.213 - Time Delta 2.255 - Time 2025-04-26T20:13:25\n",
            "Episode 107 - Steps this episode 39457 - Epsilon 0.001 - Learning Rate 0.0002496336311890255 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.475 - Mean Q Value 9.329 - Time Delta 2.222 - Time 2025-04-26T20:13:27\n",
            "Episode 108 - Steps this episode 39711 - Epsilon 0.001 - Learning Rate 0.0002496304483802801 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.476 - Mean Q Value 9.439 - Time Delta 2.228 - Time 2025-04-26T20:13:29\n",
            "Episode 109 - Steps this episode 39967 - Epsilon 0.001 - Learning Rate 0.0002496272656121152 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.478 - Mean Q Value 9.542 - Time Delta 2.224 - Time 2025-04-26T20:13:31\n",
            "Episode 110 - Steps this episode 40221 - Epsilon 0.001 - Learning Rate 0.0002496240828845304 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.48 - Mean Q Value 9.645 - Time Delta 2.216 - Time 2025-04-26T20:13:34\n",
            "Episode 111 - Steps this episode 40477 - Epsilon 0.001 - Learning Rate 0.00024962090019752507 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.481 - Mean Q Value 9.746 - Time Delta 2.248 - Time 2025-04-26T20:13:36\n",
            "Episode 112 - Steps this episode 40730 - Epsilon 0.001 - Learning Rate 0.00024961773627239027 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.482 - Mean Q Value 9.84 - Time Delta 2.248 - Time 2025-04-26T20:13:38\n",
            "Episode 113 - Steps this episode 40983 - Epsilon 0.001 - Learning Rate 0.00024961457238743687 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.483 - Mean Q Value 9.928 - Time Delta 2.219 - Time 2025-04-26T20:13:40\n",
            "Episode 114 - Steps this episode 41237 - Epsilon 0.001 - Learning Rate 0.0002496114085425065 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.484 - Mean Q Value 10.014 - Time Delta 2.222 - Time 2025-04-26T20:13:43\n",
            "Episode 115 - Steps this episode 41490 - Epsilon 0.001 - Learning Rate 0.0002496082447377565 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.485 - Mean Q Value 10.102 - Time Delta 2.216 - Time 2025-04-26T20:13:45\n",
            "Episode 116 - Steps this episode 41747 - Epsilon 0.001 - Learning Rate 0.00024960506225268637 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.486 - Mean Q Value 10.184 - Time Delta 2.25 - Time 2025-04-26T20:13:47\n",
            "Episode 117 - Steps this episode 42004 - Epsilon 0.001 - Learning Rate 0.0002496018610880908 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.487 - Mean Q Value 10.262 - Time Delta 2.29 - Time 2025-04-26T20:13:49\n",
            "Episode 118 - Steps this episode 42261 - Epsilon 0.001 - Learning Rate 0.00024959864124460984 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.488 - Mean Q Value 10.34 - Time Delta 2.224 - Time 2025-04-26T20:13:52\n",
            "Episode 119 - Steps this episode 42520 - Epsilon 0.001 - Learning Rate 0.0002495954214426646 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.488 - Mean Q Value 10.417 - Time Delta 2.574 - Time 2025-04-26T20:13:54\n",
            "Episode 120 - Steps this episode 42777 - Epsilon 0.001 - Learning Rate 0.0002495922016822545 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.489 - Mean Q Value 10.487 - Time Delta 2.285 - Time 2025-04-26T20:13:56\n",
            "Episode 121 - Steps this episode 43032 - Epsilon 0.001 - Learning Rate 0.00024958900068251474 - Cummulative Reward 150.07 - Max Length 373 - Mean Loss 0.49 - Mean Q Value 10.553 - Time Delta 2.245 - Time 2025-04-26T20:13:59\n",
            "Episode 122 - Steps this episode 43299 - Epsilon 0.001 - Learning Rate 0.0002495857435672277 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.491 - Mean Q Value 10.62 - Time Delta 2.391 - Time 2025-04-26T20:14:01\n",
            "Episode 123 - Steps this episode 43564 - Epsilon 0.001 - Learning Rate 0.00024958243033818407 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.492 - Mean Q Value 10.683 - Time Delta 2.369 - Time 2025-04-26T20:14:03\n",
            "Episode 124 - Steps this episode 43818 - Epsilon 0.001 - Learning Rate 0.0002495791920267951 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.493 - Mean Q Value 10.741 - Time Delta 2.224 - Time 2025-04-26T20:14:06\n",
            "Episode 125 - Steps this episode 44074 - Epsilon 0.001 - Learning Rate 0.00024957600991214467 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.494 - Mean Q Value 10.798 - Time Delta 2.26 - Time 2025-04-26T20:14:08\n",
            "Episode 126 - Steps this episode 44333 - Epsilon 0.001 - Learning Rate 0.0002495728091201431 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.495 - Mean Q Value 10.853 - Time Delta 2.275 - Time 2025-04-26T20:14:10\n",
            "Episode 127 - Steps this episode 44588 - Epsilon 0.001 - Learning Rate 0.00024956960836911143 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.495 - Mean Q Value 10.909 - Time Delta 2.268 - Time 2025-04-26T20:14:12\n",
            "Episode 128 - Steps this episode 44842 - Epsilon 0.001 - Learning Rate 0.0002495664263766518 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.496 - Mean Q Value 10.956 - Time Delta 2.264 - Time 2025-04-26T20:14:15\n",
            "Episode 129 - Steps this episode 45099 - Epsilon 0.001 - Learning Rate 0.0002495632257075584 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.496 - Mean Q Value 11.005 - Time Delta 2.252 - Time 2025-04-26T20:14:17\n",
            "Episode 130 - Steps this episode 45355 - Epsilon 0.001 - Learning Rate 0.00024956002507943323 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.496 - Mean Q Value 11.052 - Time Delta 2.266 - Time 2025-04-26T20:14:19\n",
            "Episode 131 - Steps this episode 45611 - Epsilon 0.001 - Learning Rate 0.00024955684320915984 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.498 - Mean Q Value 11.097 - Time Delta 2.263 - Time 2025-04-26T20:14:21\n",
            "Episode 132 - Steps this episode 45869 - Epsilon 0.001 - Learning Rate 0.00024955364266296957 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.499 - Mean Q Value 11.141 - Time Delta 2.275 - Time 2025-04-26T20:14:24\n",
            "Episode 133 - Steps this episode 46125 - Epsilon 0.001 - Learning Rate 0.00024955042344150237 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.499 - Mean Q Value 11.185 - Time Delta 2.29 - Time 2025-04-26T20:14:26\n",
            "Episode 134 - Steps this episode 46382 - Epsilon 0.001 - Learning Rate 0.0002495472229775652 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.501 - Mean Q Value 11.229 - Time Delta 2.243 - Time 2025-04-26T20:14:28\n",
            "Episode 135 - Steps this episode 46638 - Epsilon 0.001 - Learning Rate 0.0002495440225547538 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.501 - Mean Q Value 11.271 - Time Delta 2.553 - Time 2025-04-26T20:14:31\n",
            "Episode 136 - Steps this episode 46892 - Epsilon 0.001 - Learning Rate 0.0002495408408884317 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.502 - Mean Q Value 11.307 - Time Delta 2.238 - Time 2025-04-26T20:14:33\n",
            "Episode 137 - Steps this episode 47151 - Epsilon 0.001 - Learning Rate 0.0002495376405475499 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.503 - Mean Q Value 11.345 - Time Delta 2.266 - Time 2025-04-26T20:14:35\n",
            "Episode 138 - Steps this episode 47410 - Epsilon 0.001 - Learning Rate 0.0002495344028173858 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.503 - Mean Q Value 11.382 - Time Delta 2.317 - Time 2025-04-26T20:14:38\n",
            "Episode 139 - Steps this episode 47666 - Epsilon 0.001 - Learning Rate 0.0002495312025589118 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.506 - Mean Q Value 11.417 - Time Delta 2.233 - Time 2025-04-26T20:14:40\n",
            "Episode 140 - Steps this episode 47920 - Epsilon 0.001 - Learning Rate 0.00024952802105612326 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.507 - Mean Q Value 11.445 - Time Delta 2.251 - Time 2025-04-26T20:14:42\n",
            "Episode 141 - Steps this episode 48174 - Epsilon 0.001 - Learning Rate 0.0002495248395938986 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.507 - Mean Q Value 11.475 - Time Delta 2.241 - Time 2025-04-26T20:14:44\n",
            "Episode 142 - Steps this episode 48430 - Epsilon 0.001 - Learning Rate 0.00024952165817223725 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.507 - Mean Q Value 11.505 - Time Delta 2.235 - Time 2025-04-26T20:14:47\n",
            "Episode 143 - Steps this episode 48687 - Epsilon 0.001 - Learning Rate 0.00024951845807729225 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.507 - Mean Q Value 11.534 - Time Delta 2.276 - Time 2025-04-26T20:14:49\n",
            "Episode 144 - Steps this episode 48946 - Epsilon 0.001 - Learning Rate 0.0002495152393097033 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.509 - Mean Q Value 11.558 - Time Delta 2.299 - Time 2025-04-26T20:14:51\n",
            "Episode 145 - Steps this episode 49203 - Epsilon 0.001 - Learning Rate 0.00024951202058363616 - Cummulative Reward 150.06 - Max Length 373 - Mean Loss 0.509 - Mean Q Value 11.584 - Time Delta 2.261 - Time 2025-04-26T20:14:53\n",
            "Episode 146 - Steps this episode 49462 - Epsilon 0.001 - Learning Rate 0.0002495088018990903 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.51 - Mean Q Value 11.609 - Time Delta 2.28 - Time 2025-04-26T20:14:56\n",
            "Episode 147 - Steps this episode 49716 - Epsilon 0.001 - Learning Rate 0.00024950560196894606 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.511 - Mean Q Value 11.633 - Time Delta 2.226 - Time 2025-04-26T20:14:58\n",
            "Episode 148 - Steps this episode 49981 - Epsilon 0.001 - Learning Rate 0.00024950236465464174 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.511 - Mean Q Value 11.652 - Time Delta 2.328 - Time 2025-04-26T20:15:00\n",
            "Episode 149 - Steps this episode 50237 - Epsilon 0.001 - Learning Rate 0.00024949912738209834 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.512 - Mean Q Value 11.671 - Time Delta 2.303 - Time 2025-04-26T20:15:03\n",
            "Episode 150 - Steps this episode 50502 - Epsilon 0.001 - Learning Rate 0.00024949587143965017 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.514 - Mean Q Value 11.69 - Time Delta 2.336 - Time 2025-04-26T20:15:05\n",
            "Episode 151 - Steps this episode 50772 - Epsilon 0.001 - Learning Rate 0.0002494925219798506 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.515 - Mean Q Value 11.708 - Time Delta 2.693 - Time 2025-04-26T20:15:08\n",
            "Episode 152 - Steps this episode 51026 - Epsilon 0.001 - Learning Rate 0.0002494892661231954 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.515 - Mean Q Value 11.723 - Time Delta 2.236 - Time 2025-04-26T20:15:10\n",
            "Episode 153 - Steps this episode 51291 - Epsilon 0.001 - Learning Rate 0.0002494860290209283 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.516 - Mean Q Value 11.738 - Time Delta 2.359 - Time 2025-04-26T20:15:12\n",
            "Episode 154 - Steps this episode 51556 - Epsilon 0.001 - Learning Rate 0.00024948271711558657 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.517 - Mean Q Value 11.751 - Time Delta 2.414 - Time 2025-04-26T20:15:15\n",
            "Episode 155 - Steps this episode 51809 - Epsilon 0.001 - Learning Rate 0.00024947949880889213 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.517 - Mean Q Value 11.765 - Time Delta 2.23 - Time 2025-04-26T20:15:17\n",
            "Episode 156 - Steps this episode 52062 - Epsilon 0.001 - Learning Rate 0.0002494763366760876 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.519 - Mean Q Value 11.777 - Time Delta 2.255 - Time 2025-04-26T20:15:19\n",
            "Episode 157 - Steps this episode 52315 - Epsilon 0.001 - Learning Rate 0.00024947317458328376 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.519 - Mean Q Value 11.79 - Time Delta 2.248 - Time 2025-04-26T20:15:21\n",
            "Episode 158 - Steps this episode 52568 - Epsilon 0.001 - Learning Rate 0.00024947003124085193 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.519 - Mean Q Value 11.804 - Time Delta 2.26 - Time 2025-04-26T20:15:24\n",
            "Episode 159 - Steps this episode 52821 - Epsilon 0.001 - Learning Rate 0.00024946686922804815 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.52 - Mean Q Value 11.814 - Time Delta 2.297 - Time 2025-04-26T20:15:26\n",
            "Episode 160 - Steps this episode 53074 - Epsilon 0.001 - Learning Rate 0.0002494637072552435 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.521 - Mean Q Value 11.824 - Time Delta 2.256 - Time 2025-04-26T20:15:28\n",
            "Episode 161 - Steps this episode 53327 - Epsilon 0.001 - Learning Rate 0.0002494605640320992 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.521 - Mean Q Value 11.833 - Time Delta 2.245 - Time 2025-04-26T20:15:30\n",
            "Episode 162 - Steps this episode 53580 - Epsilon 0.001 - Learning Rate 0.0002494574021392914 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.523 - Mean Q Value 11.843 - Time Delta 2.244 - Time 2025-04-26T20:15:33\n",
            "Episode 163 - Steps this episode 53833 - Epsilon 0.001 - Learning Rate 0.0002494542402864815 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.523 - Mean Q Value 11.85 - Time Delta 2.27 - Time 2025-04-26T20:15:35\n",
            "Episode 164 - Steps this episode 54086 - Epsilon 0.001 - Learning Rate 0.0002494510971826202 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.524 - Mean Q Value 11.856 - Time Delta 2.296 - Time 2025-04-26T20:15:37\n",
            "Episode 165 - Steps this episode 54339 - Epsilon 0.001 - Learning Rate 0.0002494479354098041 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.525 - Mean Q Value 11.865 - Time Delta 2.264 - Time 2025-04-26T20:15:39\n",
            "Episode 166 - Steps this episode 54592 - Epsilon 0.001 - Learning Rate 0.0002494447736769841 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.525 - Mean Q Value 11.873 - Time Delta 2.225 - Time 2025-04-26T20:15:42\n",
            "Episode 167 - Steps this episode 54845 - Epsilon 0.001 - Learning Rate 0.0002494416306924014 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.526 - Mean Q Value 11.882 - Time Delta 2.228 - Time 2025-04-26T20:15:44\n",
            "Episode 168 - Steps this episode 55098 - Epsilon 0.001 - Learning Rate 0.0002494384690395723 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.527 - Mean Q Value 11.889 - Time Delta 2.546 - Time 2025-04-26T20:15:46\n",
            "Episode 169 - Steps this episode 55351 - Epsilon 0.001 - Learning Rate 0.0002494353074267379 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.528 - Mean Q Value 11.897 - Time Delta 2.238 - Time 2025-04-26T20:15:49\n",
            "Episode 170 - Steps this episode 55604 - Epsilon 0.001 - Learning Rate 0.0002494321645614291 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.529 - Mean Q Value 11.902 - Time Delta 2.279 - Time 2025-04-26T20:15:51\n",
            "Episode 171 - Steps this episode 55857 - Epsilon 0.001 - Learning Rate 0.0002494290030285824 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.909 - Time Delta 2.254 - Time 2025-04-26T20:15:53\n",
            "Episode 172 - Steps this episode 56110 - Epsilon 0.001 - Learning Rate 0.0002494258415357289 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.915 - Time Delta 2.243 - Time 2025-04-26T20:15:55\n",
            "Episode 173 - Steps this episode 56363 - Epsilon 0.001 - Learning Rate 0.00024942269878968975 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.919 - Time Delta 2.237 - Time 2025-04-26T20:15:58\n",
            "Episode 174 - Steps this episode 56618 - Epsilon 0.001 - Learning Rate 0.0002494195373768209 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.924 - Time Delta 2.254 - Time 2025-04-26T20:16:00\n",
            "Episode 175 - Steps this episode 56871 - Epsilon 0.001 - Learning Rate 0.00024941635729775445 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.926 - Time Delta 2.308 - Time 2025-04-26T20:16:02\n",
            "Episode 176 - Steps this episode 57124 - Epsilon 0.001 - Learning Rate 0.00024941319596518454 - Cummulative Reward 150.05 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.929 - Time Delta 2.273 - Time 2025-04-26T20:16:05\n",
            "Episode 177 - Steps this episode 57379 - Epsilon 0.001 - Learning Rate 0.0002494100346727633 - Cummulative Reward 149.86 - Max Length 373 - Mean Loss 0.531 - Mean Q Value 11.935 - Time Delta 2.274 - Time 2025-04-26T20:16:07\n",
            "Episode 178 - Steps this episode 57632 - Epsilon 0.001 - Learning Rate 0.00024940687342033224 - Cummulative Reward 149.86 - Max Length 373 - Mean Loss 0.531 - Mean Q Value 11.939 - Time Delta 2.258 - Time 2025-04-26T20:16:09\n",
            "Episode 179 - Steps this episode 57885 - Epsilon 0.001 - Learning Rate 0.00024940371220804876 - Cummulative Reward 149.86 - Max Length 373 - Mean Loss 0.531 - Mean Q Value 11.941 - Time Delta 2.253 - Time 2025-04-26T20:16:11\n",
            "Episode 180 - Steps this episode 58138 - Epsilon 0.001 - Learning Rate 0.00024940055103575434 - Cummulative Reward 149.86 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.945 - Time Delta 2.279 - Time 2025-04-26T20:16:14\n",
            "Episode 181 - Steps this episode 58391 - Epsilon 0.001 - Learning Rate 0.0002493974086083734 - Cummulative Reward 149.86 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.951 - Time Delta 2.297 - Time 2025-04-26T20:16:16\n",
            "Episode 182 - Steps this episode 62629 - Epsilon 0.001 - Learning Rate 0.00024936940954919533 - Cummulative Reward 149.85 - Max Length 691 - Mean Loss 0.53 - Mean Q Value 11.955 - Time Delta 35.566 - Time 2025-04-26T20:16:51\n",
            "Episode 183 - Steps this episode 62902 - Epsilon 0.001 - Learning Rate 0.00024934128179932485 - Cummulative Reward 149.84 - Max Length 373 - Mean Loss 0.53 - Mean Q Value 11.959 - Time Delta 2.749 - Time 2025-04-26T20:16:54\n",
            "Episode 184 - Steps this episode 63263 - Epsilon 0.001 - Learning Rate 0.0002493373360058966 - Cummulative Reward 149.82 - Max Length 691 - Mean Loss 0.53 - Mean Q Value 11.963 - Time Delta 3.196 - Time 2025-04-26T20:16:57\n",
            "Episode 185 - Steps this episode 63518 - Epsilon 0.001 - Learning Rate 0.0002493335024718618 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.531 - Mean Q Value 11.967 - Time Delta 2.276 - Time 2025-04-26T20:17:00\n",
            "Episode 186 - Steps this episode 63774 - Epsilon 0.001 - Learning Rate 0.00024933030478999844 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.531 - Mean Q Value 11.972 - Time Delta 2.298 - Time 2025-04-26T20:17:02\n",
            "Episode 187 - Steps this episode 64027 - Epsilon 0.001 - Learning Rate 0.0002493271258485607 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.531 - Mean Q Value 11.979 - Time Delta 2.287 - Time 2025-04-26T20:17:04\n",
            "Episode 188 - Steps this episode 64280 - Epsilon 0.001 - Learning Rate 0.0002493239843463314 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.531 - Mean Q Value 11.984 - Time Delta 2.246 - Time 2025-04-26T20:17:07\n",
            "Episode 189 - Steps this episode 64533 - Epsilon 0.001 - Learning Rate 0.00024932082418466033 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.531 - Mean Q Value 11.99 - Time Delta 2.279 - Time 2025-04-26T20:17:09\n",
            "Episode 190 - Steps this episode 64786 - Epsilon 0.001 - Learning Rate 0.0002493176640629651 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.532 - Mean Q Value 11.996 - Time Delta 2.263 - Time 2025-04-26T20:17:11\n",
            "Episode 191 - Steps this episode 65039 - Epsilon 0.001 - Learning Rate 0.0002493145226799535 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.532 - Mean Q Value 12.001 - Time Delta 2.265 - Time 2025-04-26T20:17:13\n",
            "Episode 192 - Steps this episode 65292 - Epsilon 0.001 - Learning Rate 0.0002493113626382083 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.532 - Mean Q Value 12.007 - Time Delta 2.32 - Time 2025-04-26T20:17:16\n",
            "Episode 193 - Steps this episode 65545 - Epsilon 0.001 - Learning Rate 0.0002493082026364375 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.532 - Mean Q Value 12.013 - Time Delta 2.299 - Time 2025-04-26T20:17:18\n",
            "Episode 194 - Steps this episode 65798 - Epsilon 0.001 - Learning Rate 0.0002493050613726392 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.532 - Mean Q Value 12.02 - Time Delta 2.285 - Time 2025-04-26T20:17:20\n",
            "Episode 195 - Steps this episode 66056 - Epsilon 0.001 - Learning Rate 0.000249301882753212 - Cummulative Reward 149.82 - Max Length 373 - Mean Loss 0.532 - Mean Q Value 12.022 - Time Delta 2.334 - Time 2025-04-26T20:17:23\n",
            "Episode 196 - Steps this episode 66634 - Epsilon 0.001 - Learning Rate 0.0002492966661724808 - Cummulative Reward 153.07 - Max Length 703 - Mean Loss 0.533 - Mean Q Value 12.027 - Time Delta 5.201 - Time 2025-04-26T20:17:28\n",
            "Episode 197 - Steps this episode 67084 - Epsilon 0.001 - Learning Rate 0.0002492902530943051 - Cummulative Reward 156.35 - Max Length 709 - Mean Loss 0.534 - Mean Q Value 12.032 - Time Delta 4.026 - Time 2025-04-26T20:17:32\n",
            "Episode 198 - Steps this episode 68077 - Epsilon 0.001 - Learning Rate 0.0002492812601303099 - Cummulative Reward 159.29 - Max Length 703 - Mean Loss 0.534 - Mean Q Value 12.039 - Time Delta 8.673 - Time 2025-04-26T20:17:40\n",
            "Episode 199 - Steps this episode 68779 - Epsilon 0.001 - Learning Rate 0.0002492706970471205 - Cummulative Reward 162.49 - Max Length 709 - Mean Loss 0.534 - Mean Q Value 12.047 - Time Delta 6.097 - Time 2025-04-26T20:17:47\n",
            "Episode 200 - Steps this episode 69346 - Epsilon 0.001 - Learning Rate 0.0002492627890546578 - Cummulative Reward 165.76 - Max Length 709 - Mean Loss 0.534 - Mean Q Value 12.057 - Time Delta 5.403 - Time 2025-04-26T20:17:52\n",
            "Episode 201 - Steps this episode 69909 - Epsilon 0.001 - Learning Rate 0.0002492557412483206 - Cummulative Reward 168.88 - Max Length 709 - Mean Loss 0.536 - Mean Q Value 12.067 - Time Delta 4.992 - Time 2025-04-26T20:17:57\n",
            "Episode 202 - Steps this episode 70461 - Epsilon 0.001 - Learning Rate 0.00024924878710928236 - Cummulative Reward 172.18 - Max Length 709 - Mean Loss 0.536 - Mean Q Value 12.078 - Time Delta 4.927 - Time 2025-04-26T20:18:02\n",
            "Episode 203 - Steps this episode 71006 - Epsilon 0.001 - Learning Rate 0.00024924196401636026 - Cummulative Reward 174.3 - Max Length 709 - Mean Loss 0.537 - Mean Q Value 12.087 - Time Delta 4.927 - Time 2025-04-26T20:18:07\n",
            "Episode 204 - Steps this episode 71591 - Epsilon 0.001 - Learning Rate 0.0002492349354927816 - Cummulative Reward 177.53 - Max Length 709 - Mean Loss 0.538 - Mean Q Value 12.096 - Time Delta 5.203 - Time 2025-04-26T20:18:12\n",
            "Episode 205 - Steps this episode 72131 - Epsilon 0.001 - Learning Rate 0.0002492279258569554 - Cummulative Reward 180.8 - Max Length 709 - Mean Loss 0.539 - Mean Q Value 12.107 - Time Delta 4.853 - Time 2025-04-26T20:18:17\n",
            "Episode 206 - Steps this episode 72683 - Epsilon 0.001 - Learning Rate 0.0002492211220272832 - Cummulative Reward 184.07 - Max Length 709 - Mean Loss 0.541 - Mean Q Value 12.116 - Time Delta 4.865 - Time 2025-04-26T20:18:22\n",
            "Episode 207 - Steps this episode 73301 - Epsilon 0.001 - Learning Rate 0.000249213832417534 - Cummulative Reward 189.71 - Max Length 942 - Mean Loss 0.542 - Mean Q Value 12.125 - Time Delta 5.577 - Time 2025-04-26T20:18:27\n",
            "Episode 208 - Steps this episode 73922 - Epsilon 0.001 - Learning Rate 0.0002492061131381466 - Cummulative Reward 192.9 - Max Length 709 - Mean Loss 0.543 - Mean Q Value 12.139 - Time Delta 5.516 - Time 2025-04-26T20:18:33\n",
            "Episode 209 - Steps this episode 74510 - Epsilon 0.001 - Learning Rate 0.0002491985809956077 - Cummulative Reward 196.13 - Max Length 709 - Mean Loss 0.545 - Mean Q Value 12.155 - Time Delta 5.173 - Time 2025-04-26T20:18:38\n",
            "Episode 210 - Steps this episode 75678 - Epsilon 0.001 - Learning Rate 0.0002491876289843842 - Cummulative Reward 199.2 - Max Length 709 - Mean Loss 0.546 - Mean Q Value 12.172 - Time Delta 10.119 - Time 2025-04-26T20:18:48\n",
            "Episode 211 - Steps this episode 76221 - Epsilon 0.001 - Learning Rate 0.00024917695772399575 - Cummulative Reward 202.47 - Max Length 709 - Mean Loss 0.548 - Mean Q Value 12.191 - Time Delta 4.886 - Time 2025-04-26T20:18:53\n",
            "Episode 212 - Steps this episode 76888 - Epsilon 0.001 - Learning Rate 0.00024916942646756134 - Cummulative Reward 205.64 - Max Length 709 - Mean Loss 0.55 - Mean Q Value 12.211 - Time Delta 5.912 - Time 2025-04-26T20:18:59\n",
            "Episode 213 - Steps this episode 77638 - Epsilon 0.001 - Learning Rate 0.00024916060602841414 - Cummulative Reward 209.95 - Max Length 826 - Mean Loss 0.552 - Mean Q Value 12.231 - Time Delta 6.728 - Time 2025-04-26T20:19:06\n",
            "Episode 214 - Steps this episode 78335 - Epsilon 0.001 - Learning Rate 0.00024915159903260783 - Cummulative Reward 213.0 - Max Length 816 - Mean Loss 0.555 - Mean Q Value 12.252 - Time Delta 6.255 - Time 2025-04-26T20:19:12\n",
            "Episode 215 - Steps this episode 78968 - Epsilon 0.001 - Learning Rate 0.00024914332110545533 - Cummulative Reward 216.27 - Max Length 827 - Mean Loss 0.557 - Mean Q Value 12.275 - Time Delta 5.729 - Time 2025-04-26T20:19:18\n",
            "Episode 216 - Steps this episode 79569 - Epsilon 0.001 - Learning Rate 0.00024913562269423574 - Cummulative Reward 220.66 - Max Length 827 - Mean Loss 0.56 - Mean Q Value 12.299 - Time Delta 5.366 - Time 2025-04-26T20:19:23\n",
            "Episode 217 - Steps this episode 80125 - Epsilon 0.001 - Learning Rate 0.00024912841032037614 - Cummulative Reward 223.93 - Max Length 709 - Mean Loss 0.561 - Mean Q Value 12.326 - Time Delta 5.262 - Time 2025-04-26T20:19:28\n",
            "Episode 218 - Steps this episode 80693 - Epsilon 0.001 - Learning Rate 0.0002491214223662998 - Cummulative Reward 227.19 - Max Length 709 - Mean Loss 0.564 - Mean Q Value 12.355 - Time Delta 5.055 - Time 2025-04-26T20:19:33\n",
            "Episode 219 - Steps this episode 81241 - Epsilon 0.001 - Learning Rate 0.00024911447197453274 - Cummulative Reward 230.41 - Max Length 709 - Mean Loss 0.567 - Mean Q Value 12.384 - Time Delta 4.845 - Time 2025-04-26T20:19:38\n",
            "Episode 220 - Steps this episode 81786 - Epsilon 0.001 - Learning Rate 0.000249107652558608 - Cummulative Reward 233.68 - Max Length 709 - Mean Loss 0.569 - Mean Q Value 12.415 - Time Delta 4.922 - Time 2025-04-26T20:19:43\n",
            "Episode 221 - Steps this episode 82327 - Epsilon 0.001 - Learning Rate 0.0002491008893769764 - Cummulative Reward 236.95 - Max Length 709 - Mean Loss 0.571 - Mean Q Value 12.448 - Time Delta 4.808 - Time 2025-04-26T20:19:48\n",
            "Episode 222 - Steps this episode 82865 - Epsilon 0.001 - Learning Rate 0.0002490941824252369 - Cummulative Reward 240.23 - Max Length 709 - Mean Loss 0.573 - Mean Q Value 12.482 - Time Delta 4.813 - Time 2025-04-26T20:19:53\n",
            "Episode 223 - Steps this episode 83416 - Epsilon 0.001 - Learning Rate 0.00024908740092835025 - Cummulative Reward 243.5 - Max Length 709 - Mean Loss 0.575 - Mean Q Value 12.518 - Time Delta 4.957 - Time 2025-04-26T20:19:58\n",
            "Episode 224 - Steps this episode 83973 - Epsilon 0.001 - Learning Rate 0.00024908048884853554 - Cummulative Reward 246.77 - Max Length 709 - Mean Loss 0.578 - Mean Q Value 12.552 - Time Delta 5.014 - Time 2025-04-26T20:20:03\n",
            "Episode 225 - Steps this episode 84519 - Epsilon 0.001 - Learning Rate 0.00024907361432105403 - Cummulative Reward 250.04 - Max Length 709 - Mean Loss 0.581 - Mean Q Value 12.587 - Time Delta 4.905 - Time 2025-04-26T20:20:08\n",
            "Episode 226 - Steps this episode 85061 - Epsilon 0.001 - Learning Rate 0.00024906685206354796 - Cummulative Reward 253.31 - Max Length 709 - Mean Loss 0.584 - Mean Q Value 12.625 - Time Delta 4.807 - Time 2025-04-26T20:20:12\n",
            "Episode 227 - Steps this episode 85597 - Epsilon 0.001 - Learning Rate 0.0002490601460282507 - Cummulative Reward 256.58 - Max Length 709 - Mean Loss 0.587 - Mean Q Value 12.666 - Time Delta 4.811 - Time 2025-04-26T20:20:17\n",
            "Episode 228 - Steps this episode 86125 - Epsilon 0.001 - Learning Rate 0.0002490535148893952 - Cummulative Reward 259.85 - Max Length 709 - Mean Loss 0.59 - Mean Q Value 12.707 - Time Delta 4.711 - Time 2025-04-26T20:20:22\n",
            "Episode 229 - Steps this episode 86971 - Epsilon 0.001 - Learning Rate 0.0002490449600587837 - Cummulative Reward 262.82 - Max Length 709 - Mean Loss 0.593 - Mean Q Value 12.748 - Time Delta 7.376 - Time 2025-04-26T20:20:29\n",
            "Episode 230 - Steps this episode 87502 - Epsilon 0.001 - Learning Rate 0.0002490363868217073 - Cummulative Reward 266.1 - Max Length 709 - Mean Loss 0.596 - Mean Q Value 12.792 - Time Delta 4.755 - Time 2025-04-26T20:20:34\n",
            "Episode 231 - Steps this episode 88042 - Epsilon 0.001 - Learning Rate 0.00024902971896146757 - Cummulative Reward 269.37 - Max Length 709 - Mean Loss 0.598 - Mean Q Value 12.838 - Time Delta 4.798 - Time 2025-04-26T20:20:39\n",
            "Episode 232 - Steps this episode 88680 - Epsilon 0.001 - Learning Rate 0.000249022378921154 - Cummulative Reward 272.44 - Max Length 709 - Mean Loss 0.601 - Mean Q Value 12.882 - Time Delta 5.68 - Time 2025-04-26T20:20:45\n",
            "Episode 233 - Steps this episode 89214 - Epsilon 0.001 - Learning Rate 0.0002490150764432238 - Cummulative Reward 275.71 - Max Length 709 - Mean Loss 0.604 - Mean Q Value 12.928 - Time Delta 4.754 - Time 2025-04-26T20:20:49\n",
            "Episode 234 - Steps this episode 89767 - Epsilon 0.001 - Learning Rate 0.00024900831577567595 - Cummulative Reward 278.99 - Max Length 709 - Mean Loss 0.607 - Mean Q Value 12.976 - Time Delta 4.958 - Time 2025-04-26T20:20:54\n",
            "Episode 235 - Steps this episode 90316 - Epsilon 0.001 - Learning Rate 0.00024900146191551235 - Cummulative Reward 282.23 - Max Length 709 - Mean Loss 0.61 - Mean Q Value 13.025 - Time Delta 4.883 - Time 2025-04-26T20:20:59\n",
            "Episode 236 - Steps this episode 90858 - Epsilon 0.001 - Learning Rate 0.00024899466426771174 - Cummulative Reward 285.5 - Max Length 709 - Mean Loss 0.613 - Mean Q Value 13.076 - Time Delta 5.221 - Time 2025-04-26T20:21:04\n",
            "Episode 237 - Steps this episode 91398 - Epsilon 0.001 - Learning Rate 0.00024898792282785053 - Cummulative Reward 288.77 - Max Length 709 - Mean Loss 0.616 - Mean Q Value 13.124 - Time Delta 4.869 - Time 2025-04-26T20:21:09\n",
            "Episode 238 - Steps this episode 91933 - Epsilon 0.001 - Learning Rate 0.00024898123759120475 - Cummulative Reward 292.04 - Max Length 709 - Mean Loss 0.62 - Mean Q Value 13.173 - Time Delta 4.787 - Time 2025-04-26T20:21:14\n",
            "Episode 239 - Steps this episode 92478 - Epsilon 0.001 - Learning Rate 0.0002489745151883757 - Cummulative Reward 295.3 - Max Length 709 - Mean Loss 0.622 - Mean Q Value 13.225 - Time Delta 4.904 - Time 2025-04-26T20:21:19\n",
            "Episode 240 - Steps this episode 93023 - Epsilon 0.001 - Learning Rate 0.0002489677369488769 - Cummulative Reward 298.38 - Max Length 709 - Mean Loss 0.625 - Mean Q Value 13.28 - Time Delta 4.904 - Time 2025-04-26T20:21:24\n",
            "Episode 241 - Steps this episode 93563 - Epsilon 0.001 - Learning Rate 0.00024896099623806367 - Cummulative Reward 301.65 - Max Length 709 - Mean Loss 0.627 - Mean Q Value 13.334 - Time Delta 4.84 - Time 2025-04-26T20:21:29\n",
            "Episode 242 - Steps this episode 94094 - Epsilon 0.001 - Learning Rate 0.0002489543303958799 - Cummulative Reward 304.92 - Max Length 709 - Mean Loss 0.631 - Mean Q Value 13.39 - Time Delta 4.843 - Time 2025-04-26T20:21:33\n",
            "Episode 243 - Steps this episode 94638 - Epsilon 0.001 - Learning Rate 0.0002489476273906909 - Cummulative Reward 308.19 - Max Length 709 - Mean Loss 0.634 - Mean Q Value 13.448 - Time Delta 4.869 - Time 2025-04-26T20:21:38\n",
            "Episode 244 - Steps this episode 95180 - Epsilon 0.001 - Learning Rate 0.00024894086855368396 - Cummulative Reward 311.46 - Max Length 709 - Mean Loss 0.638 - Mean Q Value 13.507 - Time Delta 4.918 - Time 2025-04-26T20:21:43\n",
            "Episode 245 - Steps this episode 95853 - Epsilon 0.001 - Learning Rate 0.0002489333070933293 - Cummulative Reward 314.59 - Max Length 709 - Mean Loss 0.641 - Mean Q Value 13.567 - Time Delta 5.98 - Time 2025-04-26T20:21:49\n",
            "Episode 246 - Steps this episode 99685 - Epsilon 0.001 - Learning Rate 0.00024890526670232727 - Cummulative Reward 317.87 - Max Length 709 - Mean Loss 0.645 - Mean Q Value 13.632 - Time Delta 33.053 - Time 2025-04-26T20:22:22\n",
            "Episode 247 - Steps this episode 100227 - Epsilon 0.001 - Learning Rate 0.000248878050024612 - Cummulative Reward 321.13 - Max Length 709 - Mean Loss 0.648 - Mean Q Value 13.699 - Time Delta 4.897 - Time 2025-04-26T20:22:27\n",
            "Episode 248 - Steps this episode 101014 - Epsilon 0.001 - Learning Rate 0.00024886978119651994 - Cummulative Reward 324.15 - Max Length 709 - Mean Loss 0.653 - Mean Q Value 13.769 - Time Delta 7.044 - Time 2025-04-26T20:22:34\n",
            "Episode 249 - Steps this episode 101544 - Epsilon 0.001 - Learning Rate 0.00024886158728454783 - Cummulative Reward 327.42 - Max Length 709 - Mean Loss 0.656 - Mean Q Value 13.841 - Time Delta 4.771 - Time 2025-04-26T20:22:39\n",
            "Episode 250 - Steps this episode 102077 - Epsilon 0.001 - Learning Rate 0.0002488549800966217 - Cummulative Reward 330.69 - Max Length 709 - Mean Loss 0.658 - Mean Q Value 13.912 - Time Delta 4.852 - Time 2025-04-26T20:22:44\n",
            "Episode 251 - Steps this episode 102661 - Epsilon 0.001 - Learning Rate 0.00024884803714057433 - Cummulative Reward 333.96 - Max Length 827 - Mean Loss 0.661 - Mean Q Value 13.985 - Time Delta 5.283 - Time 2025-04-26T20:22:49\n",
            "Episode 252 - Steps this episode 103226 - Epsilon 0.001 - Learning Rate 0.00024884088908221156 - Cummulative Reward 337.24 - Max Length 827 - Mean Loss 0.663 - Mean Q Value 14.062 - Time Delta 5.134 - Time 2025-04-26T20:22:54\n",
            "Episode 253 - Steps this episode 103845 - Epsilon 0.001 - Learning Rate 0.000248833517281267 - Cummulative Reward 341.24 - Max Length 800 - Mean Loss 0.668 - Mean Q Value 14.14 - Time Delta 6.143 - Time 2025-04-26T20:23:00\n",
            "Episode 254 - Steps this episode 104453 - Epsilon 0.001 - Learning Rate 0.00024882588442914547 - Cummulative Reward 345.64 - Max Length 827 - Mean Loss 0.671 - Mean Q Value 14.219 - Time Delta 5.547 - Time 2025-04-26T20:23:06\n",
            "Episode 255 - Steps this episode 105103 - Epsilon 0.001 - Learning Rate 0.0002488180651994685 - Cummulative Reward 348.84 - Max Length 827 - Mean Loss 0.675 - Mean Q Value 14.298 - Time Delta 6.004 - Time 2025-04-26T20:23:12\n",
            "Episode 256 - Steps this episode 105671 - Epsilon 0.001 - Learning Rate 0.0002488104888015157 - Cummulative Reward 352.11 - Max Length 827 - Mean Loss 0.678 - Mean Q Value 14.38 - Time Delta 5.2 - Time 2025-04-26T20:23:17\n",
            "Episode 257 - Steps this episode 106260 - Epsilon 0.001 - Learning Rate 0.0002488032858423094 - Cummulative Reward 355.31 - Max Length 827 - Mean Loss 0.684 - Mean Q Value 14.463 - Time Delta 5.457 - Time 2025-04-26T20:23:23\n",
            "Episode 258 - Steps this episode 106791 - Epsilon 0.001 - Learning Rate 0.00024879630700575314 - Cummulative Reward 358.58 - Max Length 709 - Mean Loss 0.689 - Mean Q Value 14.546 - Time Delta 4.838 - Time 2025-04-26T20:23:27\n",
            "Episode 259 - Steps this episode 107433 - Epsilon 0.001 - Learning Rate 0.0002487890111638542 - Cummulative Reward 362.97 - Max Length 827 - Mean Loss 0.693 - Mean Q Value 14.631 - Time Delta 5.933 - Time 2025-04-26T20:23:33\n",
            "Episode 260 - Steps this episode 108019 - Epsilon 0.001 - Learning Rate 0.00024878137967560167 - Cummulative Reward 366.19 - Max Length 827 - Mean Loss 0.696 - Mean Q Value 14.715 - Time Delta 5.346 - Time 2025-04-26T20:23:39\n",
            "Episode 261 - Steps this episode 108692 - Epsilon 0.001 - Learning Rate 0.0002487735618458325 - Cummulative Reward 370.61 - Max Length 827 - Mean Loss 0.7 - Mean Q Value 14.801 - Time Delta 6.236 - Time 2025-04-26T20:23:45\n",
            "Episode 262 - Steps this episode 109245 - Epsilon 0.001 - Learning Rate 0.00024876593082957306 - Cummulative Reward 373.87 - Max Length 709 - Mean Loss 0.703 - Mean Q Value 14.885 - Time Delta 5.054 - Time 2025-04-26T20:23:50\n",
            "Episode 263 - Steps this episode 109798 - Epsilon 0.001 - Learning Rate 0.000248759046327101 - Cummulative Reward 377.05 - Max Length 709 - Mean Loss 0.707 - Mean Q Value 14.973 - Time Delta 5.12 - Time 2025-04-26T20:23:55\n",
            "Episode 264 - Steps this episode 110353 - Epsilon 0.001 - Learning Rate 0.00024875216201532675 - Cummulative Reward 380.25 - Max Length 704 - Mean Loss 0.71 - Mean Q Value 15.059 - Time Delta 5.174 - Time 2025-04-26T20:24:00\n",
            "Episode 265 - Steps this episode 111008 - Epsilon 0.001 - Learning Rate 0.0002487446435973911 - Cummulative Reward 384.66 - Max Length 827 - Mean Loss 0.714 - Mean Q Value 15.143 - Time Delta 6.087 - Time 2025-04-26T20:24:06\n",
            "Episode 266 - Steps this episode 111609 - Epsilon 0.001 - Learning Rate 0.00024873682691754025 - Cummulative Reward 389.08 - Max Length 827 - Mean Loss 0.718 - Mean Q Value 15.229 - Time Delta 5.574 - Time 2025-04-26T20:24:12\n",
            "Episode 267 - Steps this episode 112206 - Epsilon 0.001 - Learning Rate 0.00024872936492391807 - Cummulative Reward 393.5 - Max Length 827 - Mean Loss 0.721 - Mean Q Value 15.315 - Time Delta 5.502 - Time 2025-04-26T20:24:18\n",
            "Episode 268 - Steps this episode 112817 - Epsilon 0.001 - Learning Rate 0.00024872186584642844 - Cummulative Reward 396.78 - Max Length 829 - Mean Loss 0.725 - Mean Q Value 15.402 - Time Delta 5.676 - Time 2025-04-26T20:24:23\n",
            "Episode 269 - Steps this episode 113390 - Epsilon 0.001 - Learning Rate 0.00024871451622223144 - Cummulative Reward 401.2 - Max Length 828 - Mean Loss 0.73 - Mean Q Value 15.488 - Time Delta 5.279 - Time 2025-04-26T20:24:28\n",
            "Episode 270 - Steps this episode 116524 - Epsilon 0.001 - Learning Rate 0.0002486914616995555 - Cummulative Reward 414.63 - Max Length 1749 - Mean Loss 0.735 - Mean Q Value 15.584 - Time Delta 28.013 - Time 2025-04-26T20:24:56\n",
            "Episode 271 - Steps this episode 117169 - Epsilon 0.001 - Learning Rate 0.00024866796122126604 - Cummulative Reward 419.04 - Max Length 827 - Mean Loss 0.741 - Mean Q Value 15.682 - Time Delta 6.041 - Time 2025-04-26T20:25:03\n",
            "Episode 272 - Steps this episode 117771 - Epsilon 0.001 - Learning Rate 0.0002486602028999681 - Cummulative Reward 422.24 - Max Length 827 - Mean Loss 0.746 - Mean Q Value 15.78 - Time Delta 6.05 - Time 2025-04-26T20:25:09\n",
            "Episode 273 - Steps this episode 118362 - Epsilon 0.001 - Learning Rate 0.0002486527805027647 - Cummulative Reward 426.64 - Max Length 827 - Mean Loss 0.752 - Mean Q Value 15.881 - Time Delta 5.477 - Time 2025-04-26T20:25:14\n",
            "Episode 274 - Steps this episode 119025 - Epsilon 0.001 - Learning Rate 0.0002486449853620405 - Cummulative Reward 429.7 - Max Length 827 - Mean Loss 0.757 - Mean Q Value 15.98 - Time Delta 6.114 - Time 2025-04-26T20:25:20\n",
            "Episode 275 - Steps this episode 119587 - Epsilon 0.001 - Learning Rate 0.0002486373769380949 - Cummulative Reward 434.13 - Max Length 827 - Mean Loss 0.763 - Mean Q Value 16.081 - Time Delta 5.192 - Time 2025-04-26T20:25:25\n",
            "Episode 276 - Steps this episode 120148 - Epsilon 0.001 - Learning Rate 0.00024863040275696315 - Cummulative Reward 438.56 - Max Length 827 - Mean Loss 0.769 - Mean Q Value 16.18 - Time Delta 5.196 - Time 2025-04-26T20:25:31\n",
            "Episode 277 - Steps this episode 120783 - Epsilon 0.001 - Learning Rate 0.0002486229626052527 - Cummulative Reward 443.18 - Max Length 827 - Mean Loss 0.772 - Mean Q Value 16.277 - Time Delta 5.95 - Time 2025-04-26T20:25:36\n",
            "Episode 278 - Steps this episode 121417 - Epsilon 0.001 - Learning Rate 0.0002486150751661903 - Cummulative Reward 447.6 - Max Length 827 - Mean Loss 0.777 - Mean Q Value 16.376 - Time Delta 5.905 - Time 2025-04-26T20:25:42\n",
            "Episode 279 - Steps this episode 121982 - Epsilon 0.001 - Learning Rate 0.0002486076354686872 - Cummulative Reward 450.8 - Max Length 827 - Mean Loss 0.782 - Mean Q Value 16.476 - Time Delta 5.271 - Time 2025-04-26T20:25:48\n",
            "Episode 280 - Steps this episode 122578 - Epsilon 0.001 - Learning Rate 0.0002486004197372387 - Cummulative Reward 455.22 - Max Length 827 - Mean Loss 0.788 - Mean Q Value 16.573 - Time Delta 5.519 - Time 2025-04-26T20:25:53\n",
            "Episode 281 - Steps this episode 123174 - Epsilon 0.001 - Learning Rate 0.0002485929991249072 - Cummulative Reward 459.64 - Max Length 827 - Mean Loss 0.793 - Mean Q Value 16.67 - Time Delta 5.597 - Time 2025-04-26T20:25:59\n",
            "Episode 282 - Steps this episode 123809 - Epsilon 0.001 - Learning Rate 0.00024858535500828753 - Cummulative Reward 464.07 - Max Length 827 - Mean Loss 0.798 - Mean Q Value 16.769 - Time Delta 5.951 - Time 2025-04-26T20:26:05\n",
            "Episode 283 - Steps this episode 124403 - Epsilon 0.001 - Learning Rate 0.0002485777297676656 - Cummulative Reward 468.5 - Max Length 827 - Mean Loss 0.802 - Mean Q Value 16.868 - Time Delta 5.595 - Time 2025-04-26T20:26:10\n",
            "Episode 284 - Steps this episode 124968 - Epsilon 0.001 - Learning Rate 0.00024857051490241377 - Cummulative Reward 472.95 - Max Length 827 - Mean Loss 0.808 - Mean Q Value 16.964 - Time Delta 5.244 - Time 2025-04-26T20:26:16\n",
            "Episode 285 - Steps this episode 125594 - Epsilon 0.001 - Learning Rate 0.00024856311382672044 - Cummulative Reward 477.38 - Max Length 827 - Mean Loss 0.812 - Mean Q Value 17.062 - Time Delta 5.867 - Time 2025-04-26T20:26:21\n",
            "Episode 286 - Steps this episode 126222 - Epsilon 0.001 - Learning Rate 0.000248555321494859 - Cummulative Reward 481.8 - Max Length 827 - Mean Loss 0.816 - Mean Q Value 17.159 - Time Delta 5.91 - Time 2025-04-26T20:26:27\n",
            "Episode 287 - Steps this episode 126853 - Epsilon 0.001 - Learning Rate 0.00024854749212495917 - Cummulative Reward 486.22 - Max Length 827 - Mean Loss 0.821 - Mean Q Value 17.252 - Time Delta 5.944 - Time 2025-04-26T20:26:33\n",
            "Episode 288 - Steps this episode 127482 - Epsilon 0.001 - Learning Rate 0.0002485396630016806 - Cummulative Reward 490.65 - Max Length 827 - Mean Loss 0.826 - Mean Q Value 17.35 - Time Delta 5.935 - Time 2025-04-26T20:26:39\n",
            "Episode 289 - Steps this episode 128106 - Epsilon 0.001 - Learning Rate 0.0002485318714046015 - Cummulative Reward 495.08 - Max Length 827 - Mean Loss 0.832 - Mean Q Value 17.448 - Time Delta 5.844 - Time 2025-04-26T20:26:45\n",
            "Episode 290 - Steps this episode 128730 - Epsilon 0.001 - Learning Rate 0.0002485241173305975 - Cummulative Reward 499.5 - Max Length 827 - Mean Loss 0.838 - Mean Q Value 17.546 - Time Delta 5.897 - Time 2025-04-26T20:26:51\n",
            "Episode 291 - Steps this episode 129357 - Epsilon 0.001 - Learning Rate 0.0002485163448598861 - Cummulative Reward 503.92 - Max Length 827 - Mean Loss 0.842 - Mean Q Value 17.647 - Time Delta 5.922 - Time 2025-04-26T20:26:57\n",
            "Episode 292 - Steps this episode 129982 - Epsilon 0.001 - Learning Rate 0.00024850857263206057 - Cummulative Reward 508.35 - Max Length 827 - Mean Loss 0.847 - Mean Q Value 17.748 - Time Delta 5.906 - Time 2025-04-26T20:27:03\n",
            "Episode 293 - Steps this episode 130613 - Epsilon 0.001 - Learning Rate 0.00024850078201003905 - Cummulative Reward 512.77 - Max Length 827 - Mean Loss 0.852 - Mean Q Value 17.851 - Time Delta 5.968 - Time 2025-04-26T20:27:09\n",
            "Episode 294 - Steps this episode 131242 - Epsilon 0.001 - Learning Rate 0.000248492954358106 - Cummulative Reward 517.19 - Max Length 827 - Mean Loss 0.859 - Mean Q Value 17.953 - Time Delta 5.96 - Time 2025-04-26T20:27:15\n",
            "Episode 295 - Steps this episode 131876 - Epsilon 0.001 - Learning Rate 0.000248485108316453 - Cummulative Reward 521.6 - Max Length 827 - Mean Loss 0.864 - Mean Q Value 18.059 - Time Delta 6.453 - Time 2025-04-26T20:27:21\n",
            "Episode 296 - Steps this episode 132481 - Epsilon 0.001 - Learning Rate 0.00024847741160798434 - Cummulative Reward 522.82 - Max Length 827 - Mean Loss 0.869 - Mean Q Value 18.165 - Time Delta 5.705 - Time 2025-04-26T20:27:27\n",
            "Episode 297 - Steps this episode 133327 - Epsilon 0.001 - Learning Rate 0.00024846839204999333 - Cummulative Reward 523.96 - Max Length 827 - Mean Loss 0.875 - Mean Q Value 18.267 - Time Delta 7.983 - Time 2025-04-26T20:27:35\n",
            "Episode 298 - Steps this episode 133951 - Epsilon 0.001 - Learning Rate 0.00024845926099523993 - Cummulative Reward 525.45 - Max Length 827 - Mean Loss 0.879 - Mean Q Value 18.367 - Time Delta 6.022 - Time 2025-04-26T20:27:41\n",
            "Episode 299 - Steps this episode 134551 - Epsilon 0.001 - Learning Rate 0.00024845165825684666 - Cummulative Reward 526.68 - Max Length 827 - Mean Loss 0.885 - Mean Q Value 18.468 - Time Delta 5.71 - Time 2025-04-26T20:27:47\n",
            "Episode 300 - Steps this episode 135177 - Epsilon 0.001 - Learning Rate 0.0002484440371194064 - Cummulative Reward 527.84 - Max Length 827 - Mean Loss 0.889 - Mean Q Value 18.565 - Time Delta 5.951 - Time 2025-04-26T20:27:53\n",
            "Episode 301 - Steps this episode 135818 - Epsilon 0.001 - Learning Rate 0.00024843617398987084 - Cummulative Reward 529.15 - Max Length 828 - Mean Loss 0.893 - Mean Q Value 18.662 - Time Delta 6.162 - Time 2025-04-26T20:27:59\n",
            "Episode 302 - Steps this episode 136446 - Epsilon 0.001 - Learning Rate 0.0002484282924763868 - Cummulative Reward 530.3 - Max Length 827 - Mean Loss 0.898 - Mean Q Value 18.758 - Time Delta 6.014 - Time 2025-04-26T20:28:05\n",
            "Episode 303 - Steps this episode 137081 - Epsilon 0.001 - Learning Rate 0.0002484204484764006 - Cummulative Reward 531.46 - Max Length 827 - Mean Loss 0.903 - Mean Q Value 18.852 - Time Delta 6.064 - Time 2025-04-26T20:28:11\n",
            "Episode 304 - Steps this episode 137717 - Epsilon 0.001 - Learning Rate 0.0002484125674621946 - Cummulative Reward 532.64 - Max Length 827 - Mean Loss 0.908 - Mean Q Value 18.945 - Time Delta 6.042 - Time 2025-04-26T20:28:17\n",
            "Episode 305 - Steps this episode 138323 - Epsilon 0.001 - Learning Rate 0.0002484048543701798 - Cummulative Reward 533.79 - Max Length 827 - Mean Loss 0.913 - Mean Q Value 19.039 - Time Delta 5.783 - Time 2025-04-26T20:28:23\n",
            "Episode 306 - Steps this episode 138926 - Epsilon 0.001 - Learning Rate 0.0002483973464462649 - Cummulative Reward 533.6 - Max Length 827 - Mean Loss 0.917 - Mean Q Value 19.129 - Time Delta 5.751 - Time 2025-04-26T20:28:28\n",
            "Episode 307 - Steps this episode 139557 - Epsilon 0.001 - Learning Rate 0.0002483896710872297 - Cummulative Reward 532.38 - Max Length 827 - Mean Loss 0.92 - Mean Q Value 19.219 - Time Delta 6.076 - Time 2025-04-26T20:28:34\n",
            "Episode 308 - Steps this episode 140182 - Epsilon 0.001 - Learning Rate 0.00024838186556358385 - Cummulative Reward 533.62 - Max Length 827 - Mean Loss 0.924 - Mean Q Value 19.308 - Time Delta 6.013 - Time 2025-04-26T20:28:40\n",
            "Episode 309 - Steps this episode 140802 - Epsilon 0.001 - Learning Rate 0.0002483741347976537 - Cummulative Reward 534.82 - Max Length 827 - Mean Loss 0.928 - Mean Q Value 19.396 - Time Delta 5.918 - Time 2025-04-26T20:28:46\n",
            "Episode 310 - Steps this episode 141429 - Epsilon 0.001 - Learning Rate 0.0002483663856451492 - Cummulative Reward 536.17 - Max Length 827 - Mean Loss 0.933 - Mean Q Value 19.485 - Time Delta 5.982 - Time 2025-04-26T20:28:52\n",
            "Episode 311 - Steps this episode 142055 - Epsilon 0.001 - Learning Rate 0.0002483586181072252 - Cummulative Reward 537.33 - Max Length 827 - Mean Loss 0.939 - Mean Q Value 19.572 - Time Delta 5.973 - Time 2025-04-26T20:28:58\n",
            "Episode 312 - Steps this episode 142681 - Epsilon 0.001 - Learning Rate 0.0002483508508124214 - Cummulative Reward 538.59 - Max Length 827 - Mean Loss 0.943 - Mean Q Value 19.662 - Time Delta 6.005 - Time 2025-04-26T20:29:04\n",
            "Episode 313 - Steps this episode 143323 - Epsilon 0.001 - Learning Rate 0.0002483429720065603 - Cummulative Reward 538.71 - Max Length 827 - Mean Loss 0.948 - Mean Q Value 19.753 - Time Delta 6.151 - Time 2025-04-26T20:29:10\n",
            "Episode 314 - Steps this episode 143961 - Epsilon 0.001 - Learning Rate 0.0002483350189495361 - Cummulative Reward 540.07 - Max Length 827 - Mean Loss 0.952 - Mean Q Value 19.843 - Time Delta 6.153 - Time 2025-04-26T20:29:17\n",
            "Episode 315 - Steps this episode 144588 - Epsilon 0.001 - Learning Rate 0.00024832715926958516 - Cummulative Reward 541.23 - Max Length 827 - Mean Loss 0.956 - Mean Q Value 19.93 - Time Delta 6.032 - Time 2025-04-26T20:29:23\n",
            "Episode 316 - Steps this episode 145212 - Epsilon 0.001 - Learning Rate 0.00024831939295844697 - Cummulative Reward 541.27 - Max Length 827 - Mean Loss 0.959 - Mean Q Value 20.018 - Time Delta 5.957 - Time 2025-04-26T20:29:29\n",
            "Episode 317 - Steps this episode 145838 - Epsilon 0.001 - Learning Rate 0.0002483116455136674 - Cummulative Reward 542.42 - Max Length 827 - Mean Loss 0.964 - Mean Q Value 20.105 - Time Delta 6.059 - Time 2025-04-26T20:29:35\n",
            "Episode 318 - Steps this episode 146463 - Epsilon 0.001 - Learning Rate 0.0002483038796879085 - Cummulative Reward 543.59 - Max Length 827 - Mean Loss 0.969 - Mean Q Value 20.188 - Time Delta 6.068 - Time 2025-04-26T20:29:41\n",
            "Episode 319 - Steps this episode 147086 - Epsilon 0.001 - Learning Rate 0.000248296132726942 - Cummulative Reward 544.8 - Max Length 827 - Mean Loss 0.972 - Mean Q Value 20.27 - Time Delta 6.582 - Time 2025-04-26T20:29:47\n",
            "Episode 320 - Steps this episode 147728 - Epsilon 0.001 - Learning Rate 0.0002482882929004224 - Cummulative Reward 545.96 - Max Length 827 - Mean Loss 0.976 - Mean Q Value 20.353 - Time Delta 6.25 - Time 2025-04-26T20:29:54\n",
            "Episode 321 - Steps this episode 148345 - Epsilon 0.001 - Learning Rate 0.0002482804719410093 - Cummulative Reward 547.12 - Max Length 827 - Mean Loss 0.979 - Mean Q Value 20.433 - Time Delta 5.952 - Time 2025-04-26T20:30:00\n",
            "Episode 322 - Steps this episode 148720 - Epsilon 0.001 - Learning Rate 0.0002482743084480963 - Cummulative Reward 543.85 - Max Length 827 - Mean Loss 0.981 - Mean Q Value 20.513 - Time Delta 3.652 - Time 2025-04-26T20:30:03\n",
            "Episode 323 - Steps this episode 149337 - Epsilon 0.001 - Learning Rate 0.0002482681451206708 - Cummulative Reward 545.01 - Max Length 827 - Mean Loss 0.986 - Mean Q Value 20.593 - Time Delta 5.945 - Time 2025-04-26T20:30:09\n",
            "Episode 324 - Steps this episode 149957 - Epsilon 0.001 - Learning Rate 0.0002482604737529357 - Cummulative Reward 546.17 - Max Length 827 - Mean Loss 0.988 - Mean Q Value 20.673 - Time Delta 5.957 - Time 2025-04-26T20:30:15\n",
            "Episode 325 - Steps this episode 150575 - Epsilon 0.001 - Learning Rate 0.0002482528026222422 - Cummulative Reward 547.33 - Max Length 827 - Mean Loss 0.991 - Mean Q Value 20.753 - Time Delta 5.904 - Time 2025-04-26T20:30:21\n",
            "Episode 326 - Steps this episode 151197 - Epsilon 0.001 - Learning Rate 0.0002482450944920059 - Cummulative Reward 548.49 - Max Length 827 - Mean Loss 0.994 - Mean Q Value 20.832 - Time Delta 6.004 - Time 2025-04-26T20:30:27\n",
            "Episode 327 - Steps this episode 151825 - Epsilon 0.001 - Learning Rate 0.00024823733074759777 - Cummulative Reward 549.76 - Max Length 839 - Mean Loss 0.997 - Mean Q Value 20.909 - Time Delta 6.046 - Time 2025-04-26T20:30:33\n",
            "Episode 328 - Steps this episode 152491 - Epsilon 0.001 - Learning Rate 0.00024822930660627567 - Cummulative Reward 550.87 - Max Length 827 - Mean Loss 1.001 - Mean Q Value 20.986 - Time Delta 6.467 - Time 2025-04-26T20:30:40\n",
            "Episode 329 - Steps this episode 153111 - Epsilon 0.001 - Learning Rate 0.00024822131995472636 - Cummulative Reward 552.33 - Max Length 827 - Mean Loss 1.005 - Mean Q Value 21.063 - Time Delta 6.011 - Time 2025-04-26T20:30:46\n",
            "Episode 330 - Steps this episode 153932 - Epsilon 0.001 - Learning Rate 0.00024821238415475666 - Cummulative Reward 553.46 - Max Length 827 - Mean Loss 1.007 - Mean Q Value 21.135 - Time Delta 7.838 - Time 2025-04-26T20:30:53\n",
            "Episode 331 - Steps this episode 154578 - Epsilon 0.001 - Learning Rate 0.00024820328112532843 - Cummulative Reward 554.61 - Max Length 827 - Mean Loss 1.011 - Mean Q Value 21.208 - Time Delta 6.246 - Time 2025-04-26T20:31:00\n",
            "Episode 332 - Steps this episode 155349 - Epsilon 0.001 - Learning Rate 0.0002481944762739609 - Cummulative Reward 555.97 - Max Length 827 - Mean Loss 1.015 - Mean Q Value 21.279 - Time Delta 7.399 - Time 2025-04-26T20:31:07\n",
            "Episode 333 - Steps this episode 156387 - Epsilon 0.001 - Learning Rate 0.00024818325194423047 - Cummulative Reward 557.13 - Max Length 827 - Mean Loss 1.02 - Mean Q Value 21.35 - Time Delta 9.848 - Time 2025-04-26T20:31:17\n",
            "Episode 334 - Steps this episode 157012 - Epsilon 0.001 - Learning Rate 0.00024817294012578214 - Cummulative Reward 558.27 - Max Length 827 - Mean Loss 1.022 - Mean Q Value 21.419 - Time Delta 6.089 - Time 2025-04-26T20:31:23\n",
            "Episode 335 - Steps this episode 157638 - Epsilon 0.001 - Learning Rate 0.00024816517863796527 - Cummulative Reward 559.45 - Max Length 827 - Mean Loss 1.025 - Mean Q Value 21.487 - Time Delta 6.11 - Time 2025-04-26T20:31:29\n",
            "Episode 336 - Steps this episode 158263 - Epsilon 0.001 - Learning Rate 0.00024815741739268816 - Cummulative Reward 560.61 - Max Length 827 - Mean Loss 1.027 - Mean Q Value 21.554 - Time Delta 6.11 - Time 2025-04-26T20:31:35\n",
            "Episode 337 - Steps this episode 158886 - Epsilon 0.001 - Learning Rate 0.000248149675001467 - Cummulative Reward 561.77 - Max Length 827 - Mean Loss 1.03 - Mean Q Value 21.622 - Time Delta 6.114 - Time 2025-04-26T20:31:41\n",
            "Episode 338 - Steps this episode 159511 - Epsilon 0.001 - Learning Rate 0.00024814193285180574 - Cummulative Reward 562.93 - Max Length 827 - Mean Loss 1.032 - Mean Q Value 21.687 - Time Delta 6.078 - Time 2025-04-26T20:31:47\n",
            "Episode 339 - Steps this episode 160135 - Epsilon 0.001 - Learning Rate 0.0002481341909436957 - Cummulative Reward 564.1 - Max Length 827 - Mean Loss 1.035 - Mean Q Value 21.75 - Time Delta 6.086 - Time 2025-04-26T20:31:53\n",
            "Episode 340 - Steps this episode 160760 - Epsilon 0.001 - Learning Rate 0.0002481264492771295 - Cummulative Reward 565.45 - Max Length 827 - Mean Loss 1.039 - Mean Q Value 21.812 - Time Delta 6.057 - Time 2025-04-26T20:31:59\n",
            "Episode 341 - Steps this episode 161384 - Epsilon 0.001 - Learning Rate 0.0002481187078520995 - Cummulative Reward 566.61 - Max Length 827 - Mean Loss 1.042 - Mean Q Value 21.872 - Time Delta 6.111 - Time 2025-04-26T20:32:06\n",
            "Episode 342 - Steps this episode 162004 - Epsilon 0.001 - Learning Rate 0.0002481109852768263 - Cummulative Reward 567.77 - Max Length 827 - Mean Loss 1.046 - Mean Q Value 21.93 - Time Delta 6.035 - Time 2025-04-26T20:32:12\n",
            "Episode 343 - Steps this episode 162630 - Epsilon 0.001 - Learning Rate 0.00024810324433445914 - Cummulative Reward 568.92 - Max Length 827 - Mean Loss 1.049 - Mean Q Value 21.986 - Time Delta 6.1 - Time 2025-04-26T20:32:18\n",
            "Episode 344 - Steps this episode 163248 - Epsilon 0.001 - Learning Rate 0.0002480955222402875 - Cummulative Reward 570.08 - Max Length 827 - Mean Loss 1.052 - Mean Q Value 22.039 - Time Delta 6.608 - Time 2025-04-26T20:32:24\n",
            "Episode 345 - Steps this episode 163869 - Epsilon 0.001 - Learning Rate 0.00024808783760002355 - Cummulative Reward 571.38 - Max Length 827 - Mean Loss 1.055 - Mean Q Value 22.094 - Time Delta 6.054 - Time 2025-04-26T20:32:30\n",
            "Episode 346 - Steps this episode 164492 - Epsilon 0.001 - Learning Rate 0.00024808013459167935 - Cummulative Reward 572.54 - Max Length 827 - Mean Loss 1.058 - Mean Q Value 22.148 - Time Delta 6.068 - Time 2025-04-26T20:32:36\n",
            "Episode 347 - Steps this episode 165113 - Epsilon 0.001 - Learning Rate 0.0002480724318225098 - Cummulative Reward 573.71 - Max Length 827 - Mean Loss 1.062 - Mean Q Value 22.196 - Time Delta 6.094 - Time 2025-04-26T20:32:43\n",
            "Episode 348 - Steps this episode 165757 - Epsilon 0.001 - Learning Rate 0.0002480645804544886 - Cummulative Reward 575.11 - Max Length 827 - Mean Loss 1.064 - Mean Q Value 22.242 - Time Delta 6.312 - Time 2025-04-26T20:32:49\n",
            "Episode 349 - Steps this episode 166377 - Epsilon 0.001 - Learning Rate 0.0002480567293333891 - Cummulative Reward 576.27 - Max Length 827 - Mean Loss 1.066 - Mean Q Value 22.288 - Time Delta 6.101 - Time 2025-04-26T20:32:55\n",
            "Episode 350 - Steps this episode 167000 - Epsilon 0.001 - Learning Rate 0.0002480490272909418 - Cummulative Reward 577.43 - Max Length 827 - Mean Loss 1.068 - Mean Q Value 22.334 - Time Delta 6.163 - Time 2025-04-26T20:33:01\n",
            "Episode 351 - Steps this episode 167632 - Epsilon 0.001 - Learning Rate 0.00024804125107563577 - Cummulative Reward 578.58 - Max Length 827 - Mean Loss 1.073 - Mean Q Value 22.376 - Time Delta 6.251 - Time 2025-04-26T20:33:07\n",
            "Episode 352 - Steps this episode 168251 - Epsilon 0.001 - Learning Rate 0.00024803349370574945 - Cummulative Reward 579.73 - Max Length 827 - Mean Loss 1.077 - Mean Q Value 22.419 - Time Delta 6.09 - Time 2025-04-26T20:33:13\n",
            "Episode 353 - Steps this episode 168878 - Epsilon 0.001 - Learning Rate 0.0002480257737831115 - Cummulative Reward 580.15 - Max Length 827 - Mean Loss 1.08 - Mean Q Value 22.459 - Time Delta 6.172 - Time 2025-04-26T20:33:20\n",
            "Episode 354 - Steps this episode 169500 - Epsilon 0.001 - Learning Rate 0.00024801801689765783 - Cummulative Reward 580.18 - Max Length 827 - Mean Loss 1.082 - Mean Q Value 22.498 - Time Delta 6.124 - Time 2025-04-26T20:33:26\n",
            "Episode 355 - Steps this episode 170122 - Epsilon 0.001 - Learning Rate 0.0002480102974563421 - Cummulative Reward 581.41 - Max Length 827 - Mean Loss 1.083 - Mean Q Value 22.533 - Time Delta 6.156 - Time 2025-04-26T20:33:32\n",
            "Episode 356 - Steps this episode 170741 - Epsilon 0.001 - Learning Rate 0.00024800261545568304 - Cummulative Reward 582.57 - Max Length 827 - Mean Loss 1.086 - Mean Q Value 22.565 - Time Delta 6.145 - Time 2025-04-26T20:33:38\n",
            "Episode 357 - Steps this episode 171358 - Epsilon 0.001 - Learning Rate 0.00024799495229268836 - Cummulative Reward 583.8 - Max Length 827 - Mean Loss 1.088 - Mean Q Value 22.598 - Time Delta 5.989 - Time 2025-04-26T20:33:44\n",
            "Episode 358 - Steps this episode 171980 - Epsilon 0.001 - Learning Rate 0.00024798727076753044 - Cummulative Reward 584.96 - Max Length 827 - Mean Loss 1.089 - Mean Q Value 22.629 - Time Delta 6.083 - Time 2025-04-26T20:33:50\n",
            "Episode 359 - Steps this episode 172579 - Epsilon 0.001 - Learning Rate 0.00024797970107039434 - Cummulative Reward 584.99 - Max Length 827 - Mean Loss 1.092 - Mean Q Value 22.659 - Time Delta 5.933 - Time 2025-04-26T20:33:56\n",
            "Episode 360 - Steps this episode 173201 - Epsilon 0.001 - Learning Rate 0.00024797213160564446 - Cummulative Reward 586.2 - Max Length 827 - Mean Loss 1.096 - Mean Q Value 22.687 - Time Delta 6.143 - Time 2025-04-26T20:34:02\n",
            "Episode 361 - Steps this episode 173820 - Epsilon 0.001 - Learning Rate 0.0002479644321899159 - Cummulative Reward 586.21 - Max Length 827 - Mean Loss 1.099 - Mean Q Value 22.715 - Time Delta 6.033 - Time 2025-04-26T20:34:08\n",
            "Episode 362 - Steps this episode 174442 - Epsilon 0.001 - Learning Rate 0.0002479567330132506 - Cummulative Reward 587.38 - Max Length 827 - Mean Loss 1.099 - Mean Q Value 22.744 - Time Delta 6.076 - Time 2025-04-26T20:34:14\n",
            "Episode 363 - Steps this episode 175063 - Epsilon 0.001 - Learning Rate 0.00024794903407564093 - Cummulative Reward 588.63 - Max Length 827 - Mean Loss 1.103 - Mean Q Value 22.77 - Time Delta 6.045 - Time 2025-04-26T20:34:20\n",
            "Episode 364 - Steps this episode 175688 - Epsilon 0.001 - Learning Rate 0.0002479413167815752 - Cummulative Reward 589.85 - Max Length 827 - Mean Loss 1.107 - Mean Q Value 22.797 - Time Delta 6.065 - Time 2025-04-26T20:34:26\n",
            "Episode 365 - Steps this episode 176308 - Epsilon 0.001 - Learning Rate 0.00024793359972751357 - Cummulative Reward 589.87 - Max Length 827 - Mean Loss 1.109 - Mean Q Value 22.825 - Time Delta 6.08 - Time 2025-04-26T20:34:33\n",
            "Episode 366 - Steps this episode 176812 - Epsilon 0.001 - Learning Rate 0.00024792662668915883 - Cummulative Reward 589.88 - Max Length 827 - Mean Loss 1.111 - Mean Q Value 22.849 - Time Delta 4.909 - Time 2025-04-26T20:34:37\n",
            "Episode 367 - Steps this episode 177434 - Epsilon 0.001 - Learning Rate 0.0002479196538537166 - Cummulative Reward 589.89 - Max Length 827 - Mean Loss 1.112 - Mean Q Value 22.873 - Time Delta 6.052 - Time 2025-04-26T20:34:43\n",
            "Episode 368 - Steps this episode 178056 - Epsilon 0.001 - Learning Rate 0.0002479119374740962 - Cummulative Reward 591.04 - Max Length 827 - Mean Loss 1.115 - Mean Q Value 22.894 - Time Delta 6.072 - Time 2025-04-26T20:34:50\n",
            "Episode 369 - Steps this episode 178673 - Epsilon 0.001 - Learning Rate 0.0002479042585198987 - Cummulative Reward 591.05 - Max Length 827 - Mean Loss 1.117 - Mean Q Value 22.919 - Time Delta 6.052 - Time 2025-04-26T20:34:56\n",
            "Episode 370 - Steps this episode 179296 - Epsilon 0.001 - Learning Rate 0.000247896579804129 - Cummulative Reward 582.05 - Max Length 827 - Mean Loss 1.118 - Mean Q Value 22.935 - Time Delta 6.077 - Time 2025-04-26T20:35:02\n",
            "Episode 371 - Steps this episode 179923 - Epsilon 0.001 - Learning Rate 0.00024788882695934804 - Cummulative Reward 582.07 - Max Length 827 - Mean Loss 1.12 - Mean Q Value 22.947 - Time Delta 6.785 - Time 2025-04-26T20:35:08\n",
            "Episode 372 - Steps this episode 180543 - Epsilon 0.001 - Learning Rate 0.00024788109294782596 - Cummulative Reward 583.3 - Max Length 827 - Mean Loss 1.122 - Mean Q Value 22.961 - Time Delta 6.06 - Time 2025-04-26T20:35:15\n",
            "Episode 373 - Steps this episode 181160 - Epsilon 0.001 - Learning Rate 0.0002478734335396276 - Cummulative Reward 583.33 - Max Length 827 - Mean Loss 1.123 - Mean Q Value 22.974 - Time Delta 6.025 - Time 2025-04-26T20:35:21\n",
            "Episode 374 - Steps this episode 181781 - Epsilon 0.001 - Learning Rate 0.00024786577436848416 - Cummulative Reward 584.7 - Max Length 827 - Mean Loss 1.125 - Mean Q Value 22.987 - Time Delta 6.102 - Time 2025-04-26T20:35:27\n",
            "Episode 375 - Steps this episode 182401 - Epsilon 0.001 - Learning Rate 0.00024785807825509663 - Cummulative Reward 584.7 - Max Length 827 - Mean Loss 1.126 - Mean Q Value 23.0 - Time Delta 6.133 - Time 2025-04-26T20:35:33\n",
            "Episode 376 - Steps this episode 183020 - Epsilon 0.001 - Learning Rate 0.0002478504009693545 - Cummulative Reward 584.7 - Max Length 827 - Mean Loss 1.127 - Mean Q Value 23.015 - Time Delta 6.141 - Time 2025-04-26T20:35:39\n",
            "Episode 377 - Steps this episode 183639 - Epsilon 0.001 - Learning Rate 0.00024784272392160475 - Cummulative Reward 584.7 - Max Length 827 - Mean Loss 1.129 - Mean Q Value 23.029 - Time Delta 6.122 - Time 2025-04-26T20:35:45\n",
            "Episode 378 - Steps this episode 184259 - Epsilon 0.001 - Learning Rate 0.000247835047111456 - Cummulative Reward 584.71 - Max Length 827 - Mean Loss 1.131 - Mean Q Value 23.041 - Time Delta 6.108 - Time 2025-04-26T20:35:51\n",
            "Episode 379 - Steps this episode 184755 - Epsilon 0.001 - Learning Rate 0.00024782813260612466 - Cummulative Reward 585.94 - Max Length 827 - Mean Loss 1.133 - Mean Q Value 23.055 - Time Delta 4.897 - Time 2025-04-26T20:35:56\n",
            "Episode 380 - Steps this episode 185378 - Epsilon 0.001 - Learning Rate 0.0002478211997141235 - Cummulative Reward 585.95 - Max Length 827 - Mean Loss 1.133 - Mean Q Value 23.071 - Time Delta 6.15 - Time 2025-04-26T20:36:02\n",
            "Episode 381 - Steps this episode 186000 - Epsilon 0.001 - Learning Rate 0.00024781348639884074 - Cummulative Reward 585.96 - Max Length 827 - Mean Loss 1.136 - Mean Q Value 23.087 - Time Delta 6.179 - Time 2025-04-26T20:36:08\n",
            "Episode 382 - Steps this episode 186626 - Epsilon 0.001 - Learning Rate 0.000247805754738101 - Cummulative Reward 585.96 - Max Length 827 - Mean Loss 1.14 - Mean Q Value 23.099 - Time Delta 6.232 - Time 2025-04-26T20:36:15\n",
            "Episode 383 - Steps this episode 187249 - Epsilon 0.001 - Learning Rate 0.00024779802331858537 - Cummulative Reward 585.97 - Max Length 827 - Mean Loss 1.142 - Mean Q Value 23.114 - Time Delta 6.204 - Time 2025-04-26T20:36:21\n",
            "Episode 384 - Steps this episode 187870 - Epsilon 0.001 - Learning Rate 0.00024779031072446375 - Cummulative Reward 585.96 - Max Length 827 - Mean Loss 1.144 - Mean Q Value 23.13 - Time Delta 6.149 - Time 2025-04-26T20:36:27\n",
            "Episode 385 - Steps this episode 188490 - Epsilon 0.001 - Learning Rate 0.00024778261695418635 - Cummulative Reward 585.96 - Max Length 827 - Mean Loss 1.147 - Mean Q Value 23.145 - Time Delta 6.199 - Time 2025-04-26T20:36:33\n",
            "Episode 386 - Steps this episode 189112 - Epsilon 0.001 - Learning Rate 0.0002477749234227968 - Cummulative Reward 585.97 - Max Length 827 - Mean Loss 1.148 - Mean Q Value 23.161 - Time Delta 6.197 - Time 2025-04-26T20:36:39\n",
            "Episode 387 - Steps this episode 189766 - Epsilon 0.001 - Learning Rate 0.00024776702572347785 - Cummulative Reward 585.97 - Max Length 827 - Mean Loss 1.151 - Mean Q Value 23.177 - Time Delta 6.492 - Time 2025-04-26T20:36:46\n",
            "Episode 388 - Steps this episode 190264 - Epsilon 0.001 - Learning Rate 0.00024775989013071773 - Cummulative Reward 585.97 - Max Length 827 - Mean Loss 1.151 - Mean Q Value 23.192 - Time Delta 4.957 - Time 2025-04-26T20:36:51\n",
            "Episode 389 - Steps this episode 190884 - Epsilon 0.001 - Learning Rate 0.0002477529591477722 - Cummulative Reward 585.97 - Max Length 827 - Mean Loss 1.153 - Mean Q Value 23.205 - Time Delta 6.169 - Time 2025-04-26T20:36:57\n",
            "Episode 390 - Steps this episode 191516 - Epsilon 0.001 - Learning Rate 0.000247745210794851 - Cummulative Reward 585.98 - Max Length 827 - Mean Loss 1.153 - Mean Q Value 23.221 - Time Delta 6.312 - Time 2025-04-26T20:37:03\n",
            "Episode 391 - Steps this episode 192013 - Epsilon 0.001 - Learning Rate 0.0002477382244740489 - Cummulative Reward 585.99 - Max Length 827 - Mean Loss 1.155 - Mean Q Value 23.232 - Time Delta 5.028 - Time 2025-04-26T20:37:08\n",
            "Episode 392 - Steps this episode 192511 - Epsilon 0.001 - Learning Rate 0.00024773205586859726 - Cummulative Reward 585.99 - Max Length 827 - Mean Loss 1.158 - Mean Q Value 23.243 - Time Delta 4.981 - Time 2025-04-26T20:37:13\n",
            "Episode 393 - Steps this episode 193132 - Epsilon 0.001 - Learning Rate 0.00024772512566430423 - Cummulative Reward 586.0 - Max Length 827 - Mean Loss 1.16 - Mean Q Value 23.253 - Time Delta 6.238 - Time 2025-04-26T20:37:20\n",
            "Episode 394 - Steps this episode 193610 - Epsilon 0.001 - Learning Rate 0.00024771832569834586 - Cummulative Reward 587.24 - Max Length 941 - Mean Loss 1.162 - Mean Q Value 23.264 - Time Delta 4.849 - Time 2025-04-26T20:37:24\n",
            "Episode 395 - Steps this episode 194227 - Epsilon 0.001 - Learning Rate 0.00024771154450547425 - Cummulative Reward 587.26 - Max Length 827 - Mean Loss 1.165 - Mean Q Value 23.272 - Time Delta 6.185 - Time 2025-04-26T20:37:31\n",
            "Episode 396 - Steps this episode 194846 - Epsilon 0.001 - Learning Rate 0.0002477038903364337 - Cummulative Reward 587.27 - Max Length 827 - Mean Loss 1.167 - Mean Q Value 23.282 - Time Delta 6.135 - Time 2025-04-26T20:37:37\n",
            "Episode 397 - Steps this episode 195482 - Epsilon 0.001 - Learning Rate 0.00024769612494119595 - Cummulative Reward 587.28 - Max Length 827 - Mean Loss 1.166 - Mean Q Value 23.292 - Time Delta 6.361 - Time 2025-04-26T20:37:43\n",
            "Episode 398 - Steps this episode 196106 - Epsilon 0.001 - Learning Rate 0.00024768832263517317 - Cummulative Reward 587.28 - Max Length 827 - Mean Loss 1.167 - Mean Q Value 23.302 - Time Delta 6.265 - Time 2025-04-26T20:37:49\n",
            "Episode 399 - Steps this episode 196726 - Epsilon 0.001 - Learning Rate 0.00024768061345543235 - Cummulative Reward 587.28 - Max Length 827 - Mean Loss 1.167 - Mean Q Value 23.31 - Time Delta 6.254 - Time 2025-04-26T20:37:56\n",
            "MarioNet saved to checkpoints/Super_Mario_Land/2025-04-26T20-08-06/mario_net_00.chkpt at step 196726\n",
            "MarioNet saved to checkpoints/Super_Mario_Land/2025-04-26T20-08-06-boss/mario_net_00.chkpt at step 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hzro71ndoER-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}