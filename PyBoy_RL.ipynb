{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacbilsel/PyBoy-RL/blob/Baseline_DDQN/PyBoy_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMTBtVkbwI_v",
        "outputId": "332f17d5-e788-4d46-ed75-b58e475ade72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J64vmJA4gR0w",
        "outputId": "8c0fc548-d966-4713-a147-874cfe57293f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PyBoy-RL' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/isaacbilsel/PyBoy-RL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PyBoy-RL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_ArUsACgkJ_",
        "outputId": "550b082f-6607-48cb-f2da-501e63bdde69"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'PyBoy-RL'\n",
            "/content/PyBoy-RL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install libsdl2-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lDkUUYNig2D5",
        "outputId": "c7457bbc-ac55-42c2-cfb6-c6831c722032"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsdl2-dev is already the newest version (2.0.20+dfsg-2ubuntu1.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==65.5.0 \"wheel<0.40.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5WnvXnImyY4",
        "outputId": "741c8ea8-cc7f-40fa-e763-3d5546ee9711",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools==65.5.0 in /usr/local/lib/python3.11/dist-packages (65.5.0)\n",
            "Requirement already satisfied: wheel<0.40.0 in /usr/local/lib/python3.11/dist-packages (0.38.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install gym==0.22.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "16lHb_pPkxWA",
        "outputId": "b4045759-f9fc-44bc-d66d-be13541ddb90"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.22.0\n",
            "  Using cached gym-0.22.0.tar.gz (631 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.22.0) (1.21.5)\n",
            "Collecting cloudpickle>=1.2.0 (from gym==0.22.0)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gym_notices>=0.0.4 (from gym==0.22.0)\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.22.0-py3-none-any.whl size=708480 sha256=e3320e8f8a992358f0249bd4e5ed220dd08bfb1c8905300e01a669d64e5d65a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/e8/e8/6dfbc92a1dcd76c1a5e2bb982750fd6b7e792239f46039e6b1\n",
            "Successfully built gym\n",
            "Installing collected packages: gym_notices, cloudpickle, gym\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [gym]\n",
            "\u001b[1A\u001b[2KSuccessfully installed cloudpickle-3.1.1 gym-0.22.0 gym_notices-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downgrade python version. Most of these library versions used for this code need <python3.11\n",
        "# Select python 3.10 here (type 1 in user input box)\n",
        "!apt-get update -y\n",
        "!apt-get install python3.10 python3.10-distutils\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!update-alternatives --config python3\n",
        "!apt-get install python3-pip\n",
        "!python3 -m pip install --upgrade pip --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z5KIM8D2F_-C",
        "outputId": "f06e35d7-c7b2-4998-d914-166ef34c6012"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,607 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,868 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [47.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,154 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,543 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,704 kB]\n",
            "Fetched 18.3 MB in 4s (4,592 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.9).\n",
            "python3.10 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "update-alternatives: error: alternative path /usr/bin/python3.8 doesn't exist\n",
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.11   2         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.11   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 1\n",
            "update-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in manual mode\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-pip is already the newest version (22.0.2+dfsg-1ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed pip-25.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "j5pqbVqwNnru",
        "outputId": "48f9e629-2e0d-4f01-997c-cbd95b14203b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install matplotlib==3.5.1\n",
        "!pip3 install scikit-image==0.19.2\n",
        "!pip install matplotlib-inline\n",
        "!pip install ipython\n",
        "!pip3 install opencv-python==4.5.5.64\n",
        "!pip3 install numpy==1.21.5\n",
        "!pip install torch==2.4\n",
        "!pip install torchvision==0.19"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ll_BHhaBl2c4",
        "outputId": "4e683ef9-3e79-4ac3-a655-d0f6571433fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.5.1)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.5.1)\n",
            "  Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.5.1)\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting numpy>=1.17 (from matplotlib==3.5.1)\n",
            "  Downloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib==3.5.1)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pillow>=6.2.0 (from matplotlib==3.5.1)\n",
            "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib==3.5.1) (2.4.7)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib==3.5.1)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1) (1.16.0)\n",
            "Downloading matplotlib-3.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m134.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m185.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m130.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Installing collected packages: python-dateutil, pillow, packaging, numpy, kiwisolver, fonttools, cycler, matplotlib\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [matplotlib]\n",
            "\u001b[1A\u001b[2KSuccessfully installed cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.5.1 numpy-2.2.5 packaging-25.0 pillow-11.2.1 python-dateutil-2.9.0.post0\n",
            "Collecting scikit-image==0.19.2\n",
            "  Downloading scikit_image-0.19.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.2) (2.2.5)\n",
            "Collecting scipy>=1.4.1 (from scikit-image==0.19.2)\n",
            "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting networkx>=2.2 (from scikit-image==0.19.2)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.2) (11.2.1)\n",
            "Collecting imageio>=2.4.1 (from scikit-image==0.19.2)\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting tifffile>=2019.7.26 (from scikit-image==0.19.2)\n",
            "  Downloading tifffile-2025.3.30-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting PyWavelets>=1.1.1 (from scikit-image==0.19.2)\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.19.2) (25.0)\n",
            "Downloading scikit_image-0.19.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tifffile-2025.3.30-py3-none-any.whl (226 kB)\n",
            "Installing collected packages: tifffile, scipy, PyWavelets, networkx, imageio, scikit-image\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [scikit-image]\n",
            "\u001b[1A\u001b[2KSuccessfully installed PyWavelets-1.8.0 imageio-2.37.0 networkx-3.4.2 scikit-image-0.19.2 scipy-1.15.2 tifffile-2025.3.30\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting traitlets (from matplotlib-inline)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Installing collected packages: traitlets, matplotlib-inline\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [matplotlib-inline]\n",
            "\u001b[1A\u001b[2KSuccessfully installed matplotlib-inline-0.1.7 traitlets-5.14.3\n",
            "Collecting ipython\n",
            "  Downloading ipython-8.36.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting decorator (from ipython)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting exceptiongroup (from ipython)\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\n",
            "Collecting pexpect>4.3 (from ipython)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython)\n",
            "  Downloading prompt_toolkit-3.0.51-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack_data (from ipython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.14.3)\n",
            "Collecting typing_extensions>=4.6 (from ipython)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting executing>=1.2.0 (from stack_data->ipython)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->ipython)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->ipython)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading ipython-8.36.0-py3-none-any.whl (831 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.1/831.1 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prompt_toolkit-3.0.51-py3-none-any.whl (387 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, typing_extensions, pygments, prompt_toolkit, pexpect, parso, executing, exceptiongroup, decorator, asttokens, stack_data, jedi, ipython\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [ipython]\n",
            "\u001b[1A\u001b[2KSuccessfully installed asttokens-3.0.0 decorator-5.2.1 exceptiongroup-1.2.2 executing-2.2.0 ipython-8.36.0 jedi-0.19.2 parso-0.8.4 pexpect-4.9.0 prompt_toolkit-3.0.51 ptyprocess-0.7.0 pure-eval-0.2.3 pygments-2.19.1 stack_data-0.6.3 typing_extensions-4.13.2 wcwidth-0.2.13\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m154.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "Successfully installed numpy-1.23.5\n",
            "Collecting opencv-python==4.5.5.64\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.5.5.64) (1.23.5)\n",
            "Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.5.5.64\n",
            "Collecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Downloading numpy-1.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pywavelets 1.8.0 requires numpy<3,>=1.23, but you have numpy 1.21.5 which is incompatible.\n",
            "scipy 1.15.2 requires numpy<2.5,>=1.23.5, but you have numpy 1.21.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.21.5\n",
            "Collecting torch==2.4\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting filelock (from torch==2.4)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (4.13.2)\n",
            "Collecting sympy (from torch==2.4)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4) (3.4.2)\n",
            "Collecting jinja2 (from torch==2.4)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.4)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.4) (2.0.1)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m209.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m224.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m161.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m165.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m152.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m167.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m147.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m172.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jinja2, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [torch]\n",
            "\u001b[1A\u001b[2KSuccessfully installed filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.0 triton-3.0.0\n",
            "Collecting torchvision==0.19\n",
            "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (1.21.5)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (2.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->torchvision==0.19) (12.8.93)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.4.0->torchvision==0.19) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision==0.19) (1.3.0)\n",
            "Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "Successfully installed torchvision-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyboy==1.4.7"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ViMwVEmNWOa4",
        "outputId": "1f67a595-48b1-4998-8a20-c42b717b8443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyboy==1.4.7\n",
            "  Downloading pyboy-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pyboy==1.4.7) (11.2.1)\n",
            "Collecting pysdl2 (from pyboy==1.4.7)\n",
            "  Downloading PySDL2-0.9.17-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting cython>=0.29.16 (from pyboy==1.4.7)\n",
            "  Downloading Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyboy==1.4.7) (1.21.5)\n",
            "Downloading pyboy-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.9/25.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m133.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PySDL2-0.9.17-py3-none-any.whl (583 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.1/583.1 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pysdl2, cython, pyboy\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pyboy]\n",
            "\u001b[1A\u001b[2KSuccessfully installed cython-3.0.12 pyboy-1.4.7 pysdl2-0.9.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "5UZnZmROYIIl",
        "outputId": "c1c15be0-039a-434f-e0c2-5040e8103b47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "Successfully installed numpy-1.23.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUyIpNyIjXp5",
        "outputId": "28fdee68-c270-4064-ee33-3e78e407498c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Avaliable games:  ['games/Kirby_Dream_Land.gb', 'games/Super_Mario_Land.gb']\n",
            "[1] games/Kirby_Dream_Land.gb\n",
            "[2] games/Super_Mario_Land.gb\n",
            "Select game[1-2]: 2\n",
            "[1] Evaluate (HEADLESS)\n",
            "[2] Evaluate (UI)\n",
            "[3] Train (HEADLESS)\n",
            "[4] Train (UI)\n",
            "[5] Playtest (UI)\n",
            "Select mode[1-5]: 4\n",
            "Possible actions:  [['PRESS_ARROW_RIGHT'], ['PRESS_BUTTON_A'], ['PRESS_ARROW_LEFT'], ['PRESS_ARROW_RIGHT', 'PRESS_BUTTON_A'], ['PRESS_BUTTON_A', 'PRESS_ARROW_LEFT']]\n",
            "Training mode\n",
            "Total Episodes:  400\n",
            "Episode 0 - Steps this episode 10110 - Epsilon 0.001 - Learning Rate 0.0002499992875012826 - Cummulative Reward -41.0 - Max Length 373 - Mean Loss 0.312 - Mean Q Value -0.121 - Time Delta 57.017 - Time 2025-04-27T03:54:53\n",
            "Episode 1 - Steps this episode 10518 - Epsilon 0.001 - Learning Rate 0.00024999604378534226 - Cummulative Reward 54.0 - Max Length 691 - Mean Loss 0.28 - Mean Q Value -0.102 - Time Delta 3.216 - Time 2025-04-27T03:54:56\n",
            "Episode 2 - Steps this episode 10772 - Epsilon 0.001 - Learning Rate 0.0002499919188816604 - Cummulative Reward 85.667 - Max Length 373 - Mean Loss 0.267 - Mean Q Value -0.082 - Time Delta 2.014 - Time 2025-04-27T03:54:58\n",
            "Episode 3 - Steps this episode 11026 - Epsilon 0.001 - Learning Rate 0.0002499887502539722 - Cummulative Reward 101.5 - Max Length 373 - Mean Loss 0.259 - Mean Q Value -0.054 - Time Delta 2.198 - Time 2025-04-27T03:55:00\n",
            "Episode 4 - Steps this episode 11280 - Epsilon 0.001 - Learning Rate 0.00024998556291748724 - Cummulative Reward 111.0 - Max Length 373 - Mean Loss 0.253 - Mean Q Value 0.108 - Time Delta 2.049 - Time 2025-04-27T03:55:02\n",
            "Episode 5 - Steps this episode 11534 - Epsilon 0.001 - Learning Rate 0.00024998239437028127 - Cummulative Reward 117.333 - Max Length 373 - Mean Loss 0.257 - Mean Q Value 0.224 - Time Delta 2.032 - Time 2025-04-27T03:55:04\n",
            "Episode 6 - Steps this episode 11788 - Epsilon 0.001 - Learning Rate 0.0002499792258633155 - Cummulative Reward 121.857 - Max Length 373 - Mean Loss 0.262 - Mean Q Value 0.31 - Time Delta 2.026 - Time 2025-04-27T03:55:06\n",
            "Episode 7 - Steps this episode 12045 - Epsilon 0.001 - Learning Rate 0.0002499760199001022 - Cummulative Reward 125.25 - Max Length 373 - Mean Loss 0.274 - Mean Q Value 0.4 - Time Delta 2.055 - Time 2025-04-27T03:55:08\n",
            "Episode 8 - Steps this episode 12299 - Epsilon 0.001 - Learning Rate 0.0002499728327258486 - Cummulative Reward 127.889 - Max Length 373 - Mean Loss 0.285 - Mean Q Value 0.562 - Time Delta 2.025 - Time 2025-04-27T03:55:10\n",
            "Episode 9 - Steps this episode 12556 - Epsilon 0.001 - Learning Rate 0.0002499696455923902 - Cummulative Reward 130.0 - Max Length 373 - Mean Loss 0.293 - Mean Q Value 0.695 - Time Delta 2.069 - Time 2025-04-27T03:55:12\n",
            "Episode 10 - Steps this episode 12813 - Epsilon 0.001 - Learning Rate 0.0002499664210045189 - Cummulative Reward 131.727 - Max Length 373 - Mean Loss 0.301 - Mean Q Value 0.81 - Time Delta 2.035 - Time 2025-04-27T03:55:15\n",
            "Episode 11 - Steps this episode 13067 - Epsilon 0.001 - Learning Rate 0.00024996323395265035 - Cummulative Reward 133.167 - Max Length 373 - Mean Loss 0.307 - Mean Q Value 0.926 - Time Delta 1.999 - Time 2025-04-27T03:55:17\n",
            "Episode 12 - Steps this episode 13321 - Epsilon 0.001 - Learning Rate 0.00024996006568854144 - Cummulative Reward 134.385 - Max Length 373 - Mean Loss 0.316 - Mean Q Value 1.076 - Time Delta 2.021 - Time 2025-04-27T03:55:19\n",
            "Episode 13 - Steps this episode 13578 - Epsilon 0.001 - Learning Rate 0.0002499568599710558 - Cummulative Reward 135.429 - Max Length 373 - Mean Loss 0.315 - Mean Q Value 1.208 - Time Delta 2.059 - Time 2025-04-27T03:55:21\n",
            "Episode 14 - Steps this episode 13832 - Epsilon 0.001 - Learning Rate 0.00024995367304108974 - Cummulative Reward 136.333 - Max Length 373 - Mean Loss 0.318 - Mean Q Value 1.323 - Time Delta 2.185 - Time 2025-04-27T03:55:23\n",
            "Episode 15 - Steps this episode 14089 - Epsilon 0.001 - Learning Rate 0.000249950486151916 - Cummulative Reward 137.125 - Max Length 373 - Mean Loss 0.334 - Mean Q Value 1.447 - Time Delta 2.052 - Time 2025-04-27T03:55:25\n",
            "Episode 16 - Steps this episode 14346 - Epsilon 0.001 - Learning Rate 0.00024994726181120047 - Cummulative Reward 137.824 - Max Length 373 - Mean Loss 0.339 - Mean Q Value 1.598 - Time Delta 2.057 - Time 2025-04-27T03:55:27\n",
            "Episode 17 - Steps this episode 14600 - Epsilon 0.001 - Learning Rate 0.0002499440750036101 - Cummulative Reward 138.444 - Max Length 373 - Mean Loss 0.344 - Mean Q Value 1.728 - Time Delta 2.037 - Time 2025-04-27T03:55:29\n",
            "Episode 18 - Steps this episode 14857 - Epsilon 0.001 - Learning Rate 0.0002499408882368107 - Cummulative Reward 139.0 - Max Length 373 - Mean Loss 0.348 - Mean Q Value 1.849 - Time Delta 2.058 - Time 2025-04-27T03:55:31\n",
            "Episode 19 - Steps this episode 15111 - Epsilon 0.001 - Learning Rate 0.00024993768276519425 - Cummulative Reward 139.5 - Max Length 373 - Mean Loss 0.354 - Mean Q Value 1.978 - Time Delta 2.049 - Time 2025-04-27T03:55:33\n",
            "Episode 20 - Steps this episode 15368 - Epsilon 0.001 - Learning Rate 0.0002499344960798155 - Cummulative Reward 139.952 - Max Length 373 - Mean Loss 0.355 - Mean Q Value 2.115 - Time Delta 2.048 - Time 2025-04-27T03:55:35\n",
            "Episode 21 - Steps this episode 15625 - Epsilon 0.001 - Learning Rate 0.00024993129069025805 - Cummulative Reward 140.364 - Max Length 373 - Mean Loss 0.358 - Mean Q Value 2.245 - Time Delta 2.081 - Time 2025-04-27T03:55:37\n",
            "Episode 22 - Steps this episode 15882 - Epsilon 0.001 - Learning Rate 0.00024992806659716237 - Cummulative Reward 140.739 - Max Length 373 - Mean Loss 0.359 - Mean Q Value 2.361 - Time Delta 2.055 - Time 2025-04-27T03:55:39\n",
            "Episode 23 - Steps this episode 16136 - Epsilon 0.001 - Learning Rate 0.00024992488003430953 - Cummulative Reward 141.083 - Max Length 373 - Mean Loss 0.365 - Mean Q Value 2.489 - Time Delta 1.996 - Time 2025-04-27T03:55:41\n",
            "Episode 24 - Steps this episode 16390 - Epsilon 0.001 - Learning Rate 0.00024992171225633335 - Cummulative Reward 141.4 - Max Length 373 - Mean Loss 0.369 - Mean Q Value 2.625 - Time Delta 2.006 - Time 2025-04-27T03:55:43\n",
            "Episode 25 - Steps this episode 16647 - Epsilon 0.001 - Learning Rate 0.00024991850703072737 - Cummulative Reward 141.692 - Max Length 373 - Mean Loss 0.371 - Mean Q Value 2.751 - Time Delta 2.224 - Time 2025-04-27T03:55:45\n",
            "Episode 26 - Steps this episode 16901 - Epsilon 0.001 - Learning Rate 0.00024991532058975816 - Cummulative Reward 141.963 - Max Length 373 - Mean Loss 0.375 - Mean Q Value 2.868 - Time Delta 2.005 - Time 2025-04-27T03:55:47\n",
            "Episode 27 - Steps this episode 17160 - Epsilon 0.001 - Learning Rate 0.0002499121154462048 - Cummulative Reward 142.214 - Max Length 373 - Mean Loss 0.38 - Mean Q Value 2.994 - Time Delta 2.116 - Time 2025-04-27T03:55:50\n",
            "Episode 28 - Steps this episode 17414 - Epsilon 0.001 - Learning Rate 0.00024990891034351684 - Cummulative Reward 142.448 - Max Length 373 - Mean Loss 0.38 - Mean Q Value 3.121 - Time Delta 2.025 - Time 2025-04-27T03:55:52\n",
            "Episode 29 - Steps this episode 17668 - Epsilon 0.001 - Learning Rate 0.00024990574276795535 - Cummulative Reward 142.667 - Max Length 373 - Mean Loss 0.383 - Mean Q Value 3.239 - Time Delta 2.028 - Time 2025-04-27T03:55:54\n",
            "Episode 30 - Steps this episode 17925 - Epsilon 0.001 - Learning Rate 0.00024990253774715673 - Cummulative Reward 142.871 - Max Length 373 - Mean Loss 0.383 - Mean Q Value 3.355 - Time Delta 2.055 - Time 2025-04-27T03:55:56\n",
            "Episode 31 - Steps this episode 18182 - Epsilon 0.001 - Learning Rate 0.0002498993327673822 - Cummulative Reward 143.062 - Max Length 373 - Mean Loss 0.387 - Mean Q Value 3.475 - Time Delta 2.084 - Time 2025-04-27T03:55:58\n",
            "Episode 32 - Steps this episode 18436 - Epsilon 0.001 - Learning Rate 0.00024989614657096304 - Cummulative Reward 143.242 - Max Length 373 - Mean Loss 0.389 - Mean Q Value 3.596 - Time Delta 2.047 - Time 2025-04-27T03:56:00\n",
            "Episode 33 - Steps this episode 18690 - Epsilon 0.001 - Learning Rate 0.0002498929604151676 - Cummulative Reward 143.412 - Max Length 373 - Mean Loss 0.392 - Mean Q Value 3.71 - Time Delta 2.077 - Time 2025-04-27T03:56:02\n",
            "Episode 34 - Steps this episode 18944 - Epsilon 0.001 - Learning Rate 0.0002498897930416909 - Cummulative Reward 143.571 - Max Length 373 - Mean Loss 0.393 - Mean Q Value 3.818 - Time Delta 2.039 - Time 2025-04-27T03:56:04\n",
            "Episode 35 - Steps this episode 19198 - Epsilon 0.001 - Learning Rate 0.0002498866257084396 - Cummulative Reward 143.722 - Max Length 373 - Mean Loss 0.397 - Mean Q Value 3.936 - Time Delta 2.059 - Time 2025-04-27T03:56:06\n",
            "Episode 36 - Steps this episode 19455 - Epsilon 0.001 - Learning Rate 0.0002498834209328158 - Cummulative Reward 143.865 - Max Length 373 - Mean Loss 0.401 - Mean Q Value 4.053 - Time Delta 2.083 - Time 2025-04-27T03:56:08\n",
            "Episode 37 - Steps this episode 19709 - Epsilon 0.001 - Learning Rate 0.0002498802349391917 - Cummulative Reward 144.0 - Max Length 373 - Mean Loss 0.403 - Mean Q Value 4.162 - Time Delta 2.073 - Time 2025-04-27T03:56:10\n",
            "Episode 38 - Steps this episode 19966 - Epsilon 0.001 - Learning Rate 0.0002498770489863479 - Cummulative Reward 144.128 - Max Length 373 - Mean Loss 0.405 - Mean Q Value 4.265 - Time Delta 2.26 - Time 2025-04-27T03:56:12\n",
            "Episode 39 - Steps this episode 20223 - Epsilon 0.001 - Learning Rate 0.00024987382559296564 - Cummulative Reward 144.25 - Max Length 373 - Mean Loss 0.405 - Mean Q Value 4.379 - Time Delta 2.108 - Time 2025-04-27T03:56:14\n",
            "Episode 40 - Steps this episode 20477 - Epsilon 0.001 - Learning Rate 0.00024987063972168125 - Cummulative Reward 144.366 - Max Length 373 - Mean Loss 0.407 - Mean Q Value 4.488 - Time Delta 2.064 - Time 2025-04-27T03:56:17\n",
            "Episode 41 - Steps this episode 20731 - Epsilon 0.001 - Learning Rate 0.00024986747263119685 - Cummulative Reward 144.476 - Max Length 373 - Mean Loss 0.406 - Mean Q Value 4.592 - Time Delta 2.032 - Time 2025-04-27T03:56:19\n",
            "Episode 42 - Steps this episode 20988 - Epsilon 0.001 - Learning Rate 0.0002498642681012096 - Cummulative Reward 144.581 - Max Length 373 - Mean Loss 0.408 - Mean Q Value 4.689 - Time Delta 2.02 - Time 2025-04-27T03:56:21\n",
            "Episode 43 - Steps this episode 21552 - Epsilon 0.001 - Learning Rate 0.0002498591334494212 - Cummulative Reward 144.682 - Max Length 827 - Mean Loss 0.411 - Mean Q Value 4.804 - Time Delta 4.485 - Time 2025-04-27T03:56:25\n",
            "Episode 44 - Steps this episode 21898 - Epsilon 0.001 - Learning Rate 0.0002498534554595239 - Cummulative Reward 144.778 - Max Length 709 - Mean Loss 0.415 - Mean Q Value 4.922 - Time Delta 2.757 - Time 2025-04-27T03:56:28\n",
            "Episode 45 - Steps this episode 22336 - Epsilon 0.001 - Learning Rate 0.00024984856462753163 - Cummulative Reward 151.978 - Max Length 709 - Mean Loss 0.417 - Mean Q Value 5.043 - Time Delta 3.444 - Time 2025-04-27T03:56:31\n",
            "Episode 46 - Steps this episode 22768 - Epsilon 0.001 - Learning Rate 0.0002498431304798051 - Cummulative Reward 151.915 - Max Length 709 - Mean Loss 0.421 - Mean Q Value 5.167 - Time Delta 3.408 - Time 2025-04-27T03:56:35\n",
            "Episode 47 - Steps this episode 23330 - Epsilon 0.001 - Learning Rate 0.0002498369282039465 - Cummulative Reward 158.688 - Max Length 827 - Mean Loss 0.425 - Mean Q Value 5.297 - Time Delta 4.459 - Time 2025-04-27T03:56:39\n",
            "Episode 48 - Steps this episode 23852 - Epsilon 0.001 - Learning Rate 0.00024983016395908127 - Cummulative Reward 165.184 - Max Length 709 - Mean Loss 0.431 - Mean Q Value 5.429 - Time Delta 4.102 - Time 2025-04-27T03:56:43\n",
            "Episode 49 - Steps this episode 25514 - Epsilon 0.001 - Learning Rate 0.0002498165236682832 - Cummulative Reward 169.14 - Max Length 709 - Mean Loss 0.436 - Mean Q Value 5.575 - Time Delta 12.729 - Time 2025-04-27T03:56:56\n",
            "Episode 50 - Steps this episode 26359 - Epsilon 0.001 - Learning Rate 0.0002498008606088647 - Cummulative Reward 175.176 - Max Length 709 - Mean Loss 0.441 - Mean Q Value 5.724 - Time Delta 6.559 - Time 2025-04-27T03:57:03\n",
            "Episode 51 - Steps this episode 27017 - Epsilon 0.001 - Learning Rate 0.0002497914745097759 - Cummulative Reward 180.981 - Max Length 709 - Mean Loss 0.445 - Mean Q Value 5.875 - Time Delta 5.101 - Time 2025-04-27T03:57:08\n",
            "Episode 52 - Steps this episode 27801 - Epsilon 0.001 - Learning Rate 0.00024978246344904 - Cummulative Reward 186.547 - Max Length 709 - Mean Loss 0.45 - Mean Q Value 6.026 - Time Delta 6.104 - Time 2025-04-27T03:57:14\n",
            "Episode 53 - Steps this episode 28371 - Epsilon 0.001 - Learning Rate 0.00024977399595879933 - Cummulative Reward 191.852 - Max Length 709 - Mean Loss 0.455 - Mean Q Value 6.175 - Time Delta 4.519 - Time 2025-04-27T03:57:18\n",
            "Episode 54 - Steps this episode 29031 - Epsilon 0.001 - Learning Rate 0.0002497663155288164 - Cummulative Reward 199.091 - Max Length 827 - Mean Loss 0.459 - Mean Q Value 6.323 - Time Delta 5.182 - Time 2025-04-27T03:57:23\n",
            "Episode 55 - Steps this episode 29661 - Epsilon 0.001 - Learning Rate 0.00024975826069341585 - Cummulative Reward 204.0 - Max Length 709 - Mean Loss 0.462 - Mean Q Value 6.473 - Time Delta 4.943 - Time 2025-04-27T03:57:28\n",
            "Episode 56 - Steps this episode 30231 - Epsilon 0.001 - Learning Rate 0.0002497507680555512 - Cummulative Reward 208.772 - Max Length 709 - Mean Loss 0.468 - Mean Q Value 6.622 - Time Delta 4.444 - Time 2025-04-27T03:57:33\n",
            "Episode 57 - Steps this episode 30878 - Epsilon 0.001 - Learning Rate 0.0002497431819929883 - Cummulative Reward 215.345 - Max Length 827 - Mean Loss 0.472 - Mean Q Value 6.772 - Time Delta 5.061 - Time 2025-04-27T03:57:38\n",
            "Episode 58 - Steps this episode 31399 - Epsilon 0.001 - Learning Rate 0.0002497358958376615 - Cummulative Reward 219.78 - Max Length 709 - Mean Loss 0.477 - Mean Q Value 6.921 - Time Delta 4.306 - Time 2025-04-27T03:57:42\n",
            "Episode 59 - Steps this episode 31990 - Epsilon 0.001 - Learning Rate 0.00024972894703451326 - Cummulative Reward 225.95 - Max Length 827 - Mean Loss 0.482 - Mean Q Value 7.068 - Time Delta 4.665 - Time 2025-04-27T03:57:47\n",
            "Episode 60 - Steps this episode 32637 - Epsilon 0.001 - Learning Rate 0.000249721211801437 - Cummulative Reward 229.738 - Max Length 827 - Mean Loss 0.488 - Mean Q Value 7.213 - Time Delta 5.156 - Time 2025-04-27T03:57:52\n",
            "Episode 61 - Steps this episode 33250 - Epsilon 0.001 - Learning Rate 0.0002497133457053882 - Cummulative Reward 233.403 - Max Length 827 - Mean Loss 0.495 - Mean Q Value 7.358 - Time Delta 4.864 - Time 2025-04-27T03:57:57\n",
            "Episode 62 - Steps this episode 33838 - Epsilon 0.001 - Learning Rate 0.00024970585441607703 - Cummulative Reward 239.079 - Max Length 827 - Mean Loss 0.5 - Mean Q Value 7.501 - Time Delta 4.697 - Time 2025-04-27T03:58:02\n",
            "Episode 63 - Steps this episode 34429 - Epsilon 0.001 - Learning Rate 0.00024969849444402735 - Cummulative Reward 242.484 - Max Length 691 - Mean Loss 0.506 - Mean Q Value 7.643 - Time Delta 4.724 - Time 2025-04-27T03:58:06\n",
            "Episode 64 - Steps this episode 34987 - Epsilon 0.001 - Learning Rate 0.00024969132195626684 - Cummulative Reward 245.785 - Max Length 695 - Mean Loss 0.512 - Mean Q Value 7.782 - Time Delta 4.44 - Time 2025-04-27T03:58:11\n",
            "Episode 65 - Steps this episode 35532 - Epsilon 0.001 - Learning Rate 0.0002496844305700221 - Cummulative Reward 249.288 - Max Length 709 - Mean Loss 0.518 - Mean Q Value 7.92 - Time Delta 4.387 - Time 2025-04-27T03:58:15\n",
            "Episode 66 - Steps this episode 36153 - Epsilon 0.001 - Learning Rate 0.0002496771461347537 - Cummulative Reward 252.687 - Max Length 827 - Mean Loss 0.526 - Mean Q Value 8.055 - Time Delta 4.983 - Time 2025-04-27T03:58:20\n",
            "Episode 67 - Steps this episode 36786 - Epsilon 0.001 - Learning Rate 0.0002496693188787208 - Cummulative Reward 257.632 - Max Length 827 - Mean Loss 0.533 - Mean Q Value 8.187 - Time Delta 5.031 - Time 2025-04-27T03:58:25\n",
            "Episode 68 - Steps this episode 37371 - Epsilon 0.001 - Learning Rate 0.0002496617165616174 - Cummulative Reward 262.449 - Max Length 827 - Mean Loss 0.541 - Mean Q Value 8.319 - Time Delta 4.652 - Time 2025-04-27T03:58:30\n",
            "Episode 69 - Steps this episode 38033 - Epsilon 0.001 - Learning Rate 0.0002496539459634667 - Cummulative Reward 267.129 - Max Length 827 - Mean Loss 0.55 - Mean Q Value 8.449 - Time Delta 5.512 - Time 2025-04-27T03:58:35\n",
            "Episode 70 - Steps this episode 38561 - Epsilon 0.001 - Learning Rate 0.00024964653134674624 - Cummulative Reward 271.676 - Max Length 827 - Mean Loss 0.555 - Mean Q Value 8.577 - Time Delta 4.254 - Time 2025-04-27T03:58:40\n",
            "Episode 71 - Steps this episode 39262 - Epsilon 0.001 - Learning Rate 0.0002496388548389253 - Cummulative Reward 274.528 - Max Length 827 - Mean Loss 0.56 - Mean Q Value 8.702 - Time Delta 5.531 - Time 2025-04-27T03:58:45\n",
            "Episode 72 - Steps this episode 39860 - Epsilon 0.001 - Learning Rate 0.00024963074794459724 - Cummulative Reward 277.301 - Max Length 827 - Mean Loss 0.568 - Mean Q Value 8.827 - Time Delta 4.837 - Time 2025-04-27T03:58:50\n",
            "Episode 73 - Steps this episode 40449 - Epsilon 0.001 - Learning Rate 0.0002496233340207404 - Cummulative Reward 280.0 - Max Length 827 - Mean Loss 0.575 - Mean Q Value 8.948 - Time Delta 4.725 - Time 2025-04-27T03:58:55\n",
            "Episode 74 - Steps this episode 40969 - Epsilon 0.001 - Learning Rate 0.00024961640706673674 - Cummulative Reward 282.627 - Max Length 709 - Mean Loss 0.583 - Mean Q Value 9.067 - Time Delta 4.141 - Time 2025-04-27T03:58:59\n",
            "Episode 75 - Steps this episode 41545 - Epsilon 0.001 - Learning Rate 0.00024960957391223395 - Cummulative Reward 286.658 - Max Length 827 - Mean Loss 0.589 - Mean Q Value 9.184 - Time Delta 4.722 - Time 2025-04-27T03:59:04\n",
            "Episode 76 - Steps this episode 42141 - Epsilon 0.001 - Learning Rate 0.00024960225421889715 - Cummulative Reward 289.104 - Max Length 827 - Mean Loss 0.595 - Mean Q Value 9.298 - Time Delta 4.796 - Time 2025-04-27T03:59:08\n",
            "Episode 77 - Steps this episode 42740 - Epsilon 0.001 - Learning Rate 0.0002495948037022506 - Cummulative Reward 292.859 - Max Length 832 - Mean Loss 0.601 - Mean Q Value 9.414 - Time Delta 4.837 - Time 2025-04-27T03:59:13\n",
            "Episode 78 - Steps this episode 43259 - Epsilon 0.001 - Learning Rate 0.0002495878401015856 - Cummulative Reward 295.19 - Max Length 709 - Mean Loss 0.609 - Mean Q Value 9.528 - Time Delta 4.193 - Time 2025-04-27T03:59:17\n",
            "Episode 79 - Steps this episode 43821 - Epsilon 0.001 - Learning Rate 0.00024958108260305614 - Cummulative Reward 298.988 - Max Length 835 - Mean Loss 0.613 - Mean Q Value 9.639 - Time Delta 4.49 - Time 2025-04-27T03:59:22\n",
            "Episode 80 - Steps this episode 44388 - Epsilon 0.001 - Learning Rate 0.0002495740257972716 - Cummulative Reward 301.185 - Max Length 827 - Mean Loss 0.619 - Mean Q Value 9.749 - Time Delta 4.58 - Time 2025-04-27T03:59:26\n",
            "Episode 81 - Steps this episode 44909 - Epsilon 0.001 - Learning Rate 0.00024956724995259147 - Cummulative Reward 303.317 - Max Length 709 - Mean Loss 0.625 - Mean Q Value 9.857 - Time Delta 4.174 - Time 2025-04-27T03:59:31\n",
            "Episode 82 - Steps this episode 45432 - Epsilon 0.001 - Learning Rate 0.00024956073633204613 - Cummulative Reward 305.398 - Max Length 709 - Mean Loss 0.631 - Mean Q Value 9.963 - Time Delta 4.399 - Time 2025-04-27T03:59:35\n",
            "Episode 83 - Steps this episode 45949 - Epsilon 0.001 - Learning Rate 0.0002495542415976666 - Cummulative Reward 307.44 - Max Length 709 - Mean Loss 0.634 - Mean Q Value 10.068 - Time Delta 4.124 - Time 2025-04-27T03:59:39\n",
            "Episode 84 - Steps this episode 46465 - Epsilon 0.001 - Learning Rate 0.0002495478031808075 - Cummulative Reward 309.435 - Max Length 709 - Mean Loss 0.64 - Mean Q Value 10.169 - Time Delta 4.098 - Time 2025-04-27T03:59:43\n",
            "Episode 85 - Steps this episode 46988 - Epsilon 0.001 - Learning Rate 0.0002495413274990145 - Cummulative Reward 311.372 - Max Length 709 - Mean Loss 0.645 - Mean Q Value 10.271 - Time Delta 4.142 - Time 2025-04-27T03:59:47\n",
            "Episode 86 - Steps this episode 47606 - Epsilon 0.001 - Learning Rate 0.0002495342156748371 - Cummulative Reward 314.563 - Max Length 827 - Mean Loss 0.649 - Mean Q Value 10.371 - Time Delta 5.024 - Time 2025-04-27T03:59:52\n",
            "Episode 87 - Steps this episode 49355 - Epsilon 0.001 - Learning Rate 0.00024951944999298696 - Cummulative Reward 319.068 - Max Length 939 - Mean Loss 0.655 - Mean Q Value 10.469 - Time Delta 13.414 - Time 2025-04-27T04:00:06\n",
            "Episode 88 - Steps this episode 49986 - Epsilon 0.001 - Learning Rate 0.0002495045914819526 - Cummulative Reward 322.157 - Max Length 839 - Mean Loss 0.66 - Mean Q Value 10.563 - Time Delta 5.034 - Time 2025-04-27T04:00:11\n",
            "Episode 89 - Steps this episode 50679 - Epsilon 0.001 - Learning Rate 0.0002494963205432851 - Cummulative Reward 325.133 - Max Length 827 - Mean Loss 0.665 - Mean Q Value 10.659 - Time Delta 5.611 - Time 2025-04-27T04:00:16\n",
            "Episode 90 - Steps this episode 51308 - Epsilon 0.001 - Learning Rate 0.00024948808729767616 - Cummulative Reward 328.077 - Max Length 829 - Mean Loss 0.67 - Mean Q Value 10.754 - Time Delta 5.015 - Time 2025-04-27T04:00:21\n",
            "Episode 91 - Steps this episode 51949 - Epsilon 0.001 - Learning Rate 0.0002494801724135595 - Cummulative Reward 330.924 - Max Length 827 - Mean Loss 0.674 - Mean Q Value 10.848 - Time Delta 5.1 - Time 2025-04-27T04:00:27\n",
            "Episode 92 - Steps this episode 52577 - Epsilon 0.001 - Learning Rate 0.0002494722577795491 - Cummulative Reward 333.828 - Max Length 837 - Mean Loss 0.679 - Mean Q Value 10.945 - Time Delta 5.037 - Time 2025-04-27T04:00:32\n",
            "Episode 93 - Steps this episode 53269 - Epsilon 0.001 - Learning Rate 0.00024946402533252636 - Cummulative Reward 336.606 - Max Length 837 - Mean Loss 0.684 - Mean Q Value 11.04 - Time Delta 5.481 - Time 2025-04-27T04:00:37\n",
            "Episode 94 - Steps this episode 53897 - Epsilon 0.001 - Learning Rate 0.0002494557931526421 - Cummulative Reward 339.295 - Max Length 828 - Mean Loss 0.688 - Mean Q Value 11.133 - Time Delta 5.058 - Time 2025-04-27T04:00:42\n",
            "Episode 95 - Steps this episode 54554 - Epsilon 0.001 - Learning Rate 0.00024944778575060296 - Cummulative Reward 341.896 - Max Length 827 - Mean Loss 0.694 - Mean Q Value 11.226 - Time Delta 5.478 - Time 2025-04-27T04:00:48\n",
            "Episode 96 - Steps this episode 55178 - Epsilon 0.001 - Learning Rate 0.00024943979731148355 - Cummulative Reward 344.464 - Max Length 827 - Mean Loss 0.698 - Mean Q Value 11.318 - Time Delta 5.056 - Time 2025-04-27T04:00:53\n",
            "Episode 97 - Steps this episode 55823 - Epsilon 0.001 - Learning Rate 0.0002494318839595402 - Cummulative Reward 346.98 - Max Length 835 - Mean Loss 0.703 - Mean Q Value 11.409 - Time Delta 5.19 - Time 2025-04-27T04:00:58\n",
            "Episode 98 - Steps this episode 57611 - Epsilon 0.001 - Learning Rate 0.0002494167127977135 - Cummulative Reward 349.444 - Max Length 837 - Mean Loss 0.707 - Mean Q Value 11.499 - Time Delta 13.769 - Time 2025-04-27T04:01:12\n",
            "Episode 99 - Steps this episode 58382 - Epsilon 0.001 - Learning Rate 0.0002494007568051025 - Cummulative Reward 351.92 - Max Length 837 - Mean Loss 0.712 - Mean Q Value 11.589 - Time Delta 6.168 - Time 2025-04-27T04:01:18\n",
            "Episode 100 - Steps this episode 59082 - Epsilon 0.001 - Learning Rate 0.0002493915727880072 - Cummulative Reward 358.25 - Max Length 837 - Mean Loss 0.72 - Mean Q Value 11.796 - Time Delta 5.61 - Time 2025-04-27T04:01:23\n",
            "Episode 101 - Steps this episode 59741 - Epsilon 0.001 - Learning Rate 0.0002493830998510337 - Cummulative Reward 362.67 - Max Length 829 - Mean Loss 0.728 - Mean Q Value 12.004 - Time Delta 5.329 - Time 2025-04-27T04:01:29\n",
            "Episode 102 - Steps this episode 60439 - Epsilon 0.001 - Learning Rate 0.00024937464590809065 - Cummulative Reward 367.09 - Max Length 829 - Mean Loss 0.737 - Mean Q Value 12.211 - Time Delta 5.679 - Time 2025-04-27T04:01:34\n",
            "Episode 103 - Steps this episode 61107 - Epsilon 0.001 - Learning Rate 0.00024936611743933413 - Cummulative Reward 371.58 - Max Length 836 - Mean Loss 0.745 - Mean Q Value 12.417 - Time Delta 5.425 - Time 2025-04-27T04:01:40\n",
            "Episode 104 - Steps this episode 61745 - Epsilon 0.001 - Learning Rate 0.0002493579820007356 - Cummulative Reward 376.09 - Max Length 837 - Mean Loss 0.755 - Mean Q Value 12.617 - Time Delta 5.174 - Time 2025-04-27T04:01:45\n",
            "Episode 105 - Steps this episode 62393 - Epsilon 0.001 - Learning Rate 0.00024934997773778353 - Cummulative Reward 380.51 - Max Length 835 - Mean Loss 0.765 - Mean Q Value 12.817 - Time Delta 5.162 - Time 2025-04-27T04:01:50\n",
            "Episode 106 - Steps this episode 63023 - Epsilon 0.001 - Learning Rate 0.0002493420111320683 - Cummulative Reward 384.91 - Max Length 827 - Mean Loss 0.775 - Mean Q Value 13.016 - Time Delta 5.098 - Time 2025-04-27T04:01:55\n",
            "Episode 107 - Steps this episode 63649 - Epsilon 0.001 - Learning Rate 0.0002493341756817993 - Cummulative Reward 389.34 - Max Length 827 - Mean Loss 0.783 - Mean Q Value 13.217 - Time Delta 5.02 - Time 2025-04-27T04:02:00\n",
            "Episode 108 - Steps this episode 64292 - Epsilon 0.001 - Learning Rate 0.00024932626568045124 - Cummulative Reward 393.77 - Max Length 837 - Mean Loss 0.789 - Mean Q Value 13.408 - Time Delta 5.446 - Time 2025-04-27T04:02:06\n",
            "Episode 109 - Steps this episode 64931 - Epsilon 0.001 - Learning Rate 0.00024931828113394853 - Cummulative Reward 398.29 - Max Length 838 - Mean Loss 0.798 - Mean Q Value 13.601 - Time Delta 5.1 - Time 2025-04-27T04:02:11\n",
            "Episode 110 - Steps this episode 65573 - Epsilon 0.001 - Learning Rate 0.00024931029684334654 - Cummulative Reward 402.82 - Max Length 838 - Mean Loss 0.807 - Mean Q Value 13.796 - Time Delta 5.131 - Time 2025-04-27T04:02:16\n",
            "Episode 111 - Steps this episode 66221 - Epsilon 0.001 - Learning Rate 0.00024930225671552044 - Cummulative Reward 407.23 - Max Length 837 - Mean Loss 0.815 - Mean Q Value 13.989 - Time Delta 5.229 - Time 2025-04-27T04:02:21\n",
            "Episode 112 - Steps this episode 66878 - Epsilon 0.001 - Learning Rate 0.00024929412336176747 - Cummulative Reward 411.73 - Max Length 837 - Mean Loss 0.822 - Mean Q Value 14.177 - Time Delta 5.233 - Time 2025-04-27T04:02:26\n",
            "Episode 113 - Steps this episode 67528 - Epsilon 0.001 - Learning Rate 0.00024928597157640204 - Cummulative Reward 416.06 - Max Length 839 - Mean Loss 0.83 - Mean Q Value 14.365 - Time Delta 5.22 - Time 2025-04-27T04:02:32\n",
            "Episode 114 - Steps this episode 68164 - Epsilon 0.001 - Learning Rate 0.0002492779509281978 - Cummulative Reward 420.58 - Max Length 837 - Mean Loss 0.838 - Mean Q Value 14.554 - Time Delta 5.123 - Time 2025-04-27T04:02:37\n",
            "Episode 115 - Steps this episode 68810 - Epsilon 0.001 - Learning Rate 0.0002492699679293497 - Cummulative Reward 425.1 - Max Length 837 - Mean Loss 0.845 - Mean Q Value 14.741 - Time Delta 5.322 - Time 2025-04-27T04:02:42\n",
            "Episode 116 - Steps this episode 69463 - Epsilon 0.001 - Learning Rate 0.00024926187301828085 - Cummulative Reward 429.62 - Max Length 837 - Mean Loss 0.853 - Mean Q Value 14.922 - Time Delta 5.299 - Time 2025-04-27T04:02:47\n",
            "Episode 117 - Steps this episode 70115 - Epsilon 0.001 - Learning Rate 0.00024925374098161803 - Cummulative Reward 434.14 - Max Length 837 - Mean Loss 0.86 - Mean Q Value 15.103 - Time Delta 5.287 - Time 2025-04-27T04:02:53\n",
            "Episode 118 - Steps this episode 70766 - Epsilon 0.001 - Learning Rate 0.00024924562790378294 - Cummulative Reward 438.66 - Max Length 837 - Mean Loss 0.868 - Mean Q Value 15.284 - Time Delta 5.312 - Time 2025-04-27T04:02:58\n",
            "Episode 119 - Steps this episode 71419 - Epsilon 0.001 - Learning Rate 0.0002492374963973116 - Cummulative Reward 443.18 - Max Length 837 - Mean Loss 0.876 - Mean Q Value 15.462 - Time Delta 5.266 - Time 2025-04-27T04:03:03\n",
            "Episode 120 - Steps this episode 72066 - Epsilon 0.001 - Learning Rate 0.0002492293838480264 - Cummulative Reward 447.7 - Max Length 837 - Mean Loss 0.885 - Mean Q Value 15.635 - Time Delta 5.329 - Time 2025-04-27T04:03:09\n",
            "Episode 121 - Steps this episode 72721 - Epsilon 0.001 - Learning Rate 0.00024922127156320594 - Cummulative Reward 452.2 - Max Length 838 - Mean Loss 0.891 - Mean Q Value 15.806 - Time Delta 5.299 - Time 2025-04-27T04:03:14\n",
            "Episode 122 - Steps this episode 73405 - Epsilon 0.001 - Learning Rate 0.00024921293525151584 - Cummulative Reward 456.69 - Max Length 837 - Mean Loss 0.898 - Mean Q Value 15.977 - Time Delta 5.563 - Time 2025-04-27T04:03:19\n",
            "Episode 123 - Steps this episode 74055 - Epsilon 0.001 - Learning Rate 0.0002492046179068322 - Cummulative Reward 461.22 - Max Length 838 - Mean Loss 0.904 - Mean Q Value 16.145 - Time Delta 5.586 - Time 2025-04-27T04:03:25\n",
            "Episode 124 - Steps this episode 74750 - Epsilon 0.001 - Learning Rate 0.0002491962447731786 - Cummulative Reward 466.88 - Max Length 1445 - Mean Loss 0.913 - Mean Q Value 16.309 - Time Delta 5.568 - Time 2025-04-27T04:03:31\n",
            "Episode 125 - Steps this episode 75400 - Epsilon 0.001 - Learning Rate 0.0002491878719179271 - Cummulative Reward 471.4 - Max Length 838 - Mean Loss 0.921 - Mean Q Value 16.474 - Time Delta 5.26 - Time 2025-04-27T04:03:36\n",
            "Episode 126 - Steps this episode 76050 - Epsilon 0.001 - Learning Rate 0.0002491797609840953 - Cummulative Reward 475.93 - Max Length 838 - Mean Loss 0.928 - Mean Q Value 16.637 - Time Delta 5.317 - Time 2025-04-27T04:03:41\n",
            "Episode 127 - Steps this episode 76710 - Epsilon 0.001 - Learning Rate 0.0002491715942509572 - Cummulative Reward 480.45 - Max Length 838 - Mean Loss 0.936 - Mean Q Value 16.796 - Time Delta 5.366 - Time 2025-04-27T04:03:47\n",
            "Episode 128 - Steps this episode 77358 - Epsilon 0.001 - Learning Rate 0.00024916344647202493 - Cummulative Reward 484.98 - Max Length 838 - Mean Loss 0.943 - Mean Q Value 16.952 - Time Delta 5.228 - Time 2025-04-27T04:03:52\n",
            "Episode 129 - Steps this episode 78014 - Epsilon 0.001 - Learning Rate 0.00024915533633343125 - Cummulative Reward 489.5 - Max Length 837 - Mean Loss 0.951 - Mean Q Value 17.109 - Time Delta 5.352 - Time 2025-04-27T04:03:57\n",
            "Episode 130 - Steps this episode 78670 - Epsilon 0.001 - Learning Rate 0.0002491471704005937 - Cummulative Reward 494.0 - Max Length 836 - Mean Loss 0.96 - Mean Q Value 17.266 - Time Delta 5.314 - Time 2025-04-27T04:04:02\n",
            "Episode 131 - Steps this episode 79414 - Epsilon 0.001 - Learning Rate 0.00024913844417627946 - Cummulative Reward 498.42 - Max Length 836 - Mean Loss 0.967 - Mean Q Value 17.421 - Time Delta 5.95 - Time 2025-04-27T04:04:08\n",
            "Episode 132 - Steps this episode 80135 - Epsilon 0.001 - Learning Rate 0.0002491293258744944 - Cummulative Reward 502.73 - Max Length 836 - Mean Loss 0.974 - Mean Q Value 17.571 - Time Delta 5.819 - Time 2025-04-27T04:04:14\n",
            "Episode 133 - Steps this episode 80806 - Epsilon 0.001 - Learning Rate 0.0002491206563224225 - Cummulative Reward 507.22 - Max Length 836 - Mean Loss 0.982 - Mean Q Value 17.721 - Time Delta 5.476 - Time 2025-04-27T04:04:20\n",
            "Episode 134 - Steps this episode 81460 - Epsilon 0.001 - Learning Rate 0.00024911239810830864 - Cummulative Reward 511.72 - Max Length 835 - Mean Loss 0.988 - Mean Q Value 17.874 - Time Delta 5.34 - Time 2025-04-27T04:04:25\n",
            "Episode 135 - Steps this episode 82116 - Epsilon 0.001 - Learning Rate 0.0002491042335827485 - Cummulative Reward 516.24 - Max Length 837 - Mean Loss 0.995 - Mean Q Value 18.018 - Time Delta 5.424 - Time 2025-04-27T04:04:30\n",
            "Episode 136 - Steps this episode 82767 - Epsilon 0.001 - Learning Rate 0.000249096088006678 - Cummulative Reward 520.74 - Max Length 836 - Mean Loss 1.002 - Mean Q Value 18.163 - Time Delta 5.359 - Time 2025-04-27T04:04:36\n",
            "Episode 137 - Steps this episode 83416 - Epsilon 0.001 - Learning Rate 0.0002490879987418636 - Cummulative Reward 525.26 - Max Length 837 - Mean Loss 1.009 - Mean Q Value 18.308 - Time Delta 5.335 - Time 2025-04-27T04:04:41\n",
            "Episode 138 - Steps this episode 84078 - Epsilon 0.001 - Learning Rate 0.00024907983501638794 - Cummulative Reward 529.78 - Max Length 837 - Mean Loss 1.019 - Mean Q Value 18.453 - Time Delta 5.518 - Time 2025-04-27T04:04:47\n",
            "Episode 139 - Steps this episode 84730 - Epsilon 0.001 - Learning Rate 0.0002490716528771785 - Cummulative Reward 534.28 - Max Length 837 - Mean Loss 1.026 - Mean Q Value 18.593 - Time Delta 5.322 - Time 2025-04-27T04:04:52\n",
            "Episode 140 - Steps this episode 85387 - Epsilon 0.001 - Learning Rate 0.0002490635083668868 - Cummulative Reward 538.78 - Max Length 836 - Mean Loss 1.034 - Mean Q Value 18.734 - Time Delta 5.788 - Time 2025-04-27T04:04:58\n",
            "Episode 141 - Steps this episode 86043 - Epsilon 0.001 - Learning Rate 0.00024905532676440805 - Cummulative Reward 543.29 - Max Length 837 - Mean Loss 1.043 - Mean Q Value 18.872 - Time Delta 5.337 - Time 2025-04-27T04:05:03\n",
            "Episode 142 - Steps this episode 86691 - Epsilon 0.001 - Learning Rate 0.0002490472014660042 - Cummulative Reward 547.72 - Max Length 836 - Mean Loss 1.051 - Mean Q Value 19.013 - Time Delta 5.331 - Time 2025-04-27T04:05:08\n",
            "Episode 143 - Steps this episode 87339 - Epsilon 0.001 - Learning Rate 0.00024903913246679133 - Cummulative Reward 552.24 - Max Length 837 - Mean Loss 1.06 - Mean Q Value 19.144 - Time Delta 5.371 - Time 2025-04-27T04:05:14\n",
            "Episode 144 - Steps this episode 87992 - Epsilon 0.001 - Learning Rate 0.0002490310450517804 - Cummulative Reward 556.76 - Max Length 837 - Mean Loss 1.067 - Mean Q Value 19.272 - Time Delta 5.386 - Time 2025-04-27T04:05:19\n",
            "Episode 145 - Steps this episode 88651 - Epsilon 0.001 - Learning Rate 0.00024902288319272723 - Cummulative Reward 557.99 - Max Length 836 - Mean Loss 1.075 - Mean Q Value 19.398 - Time Delta 5.476 - Time 2025-04-27T04:05:25\n",
            "Episode 146 - Steps this episode 89310 - Epsilon 0.001 - Learning Rate 0.00024901466557255837 - Cummulative Reward 562.49 - Max Length 837 - Mean Loss 1.082 - Mean Q Value 19.52 - Time Delta 5.44 - Time 2025-04-27T04:05:30\n",
            "Episode 147 - Steps this episode 89969 - Epsilon 0.001 - Learning Rate 0.00024900646689894965 - Cummulative Reward 563.73 - Max Length 837 - Mean Loss 1.088 - Mean Q Value 19.635 - Time Delta 5.469 - Time 2025-04-27T04:05:36\n",
            "Episode 148 - Steps this episode 90621 - Epsilon 0.001 - Learning Rate 0.0002489983058450243 - Cummulative Reward 564.97 - Max Length 837 - Mean Loss 1.093 - Mean Q Value 19.747 - Time Delta 5.379 - Time 2025-04-27T04:05:41\n",
            "Episode 149 - Steps this episode 91286 - Epsilon 0.001 - Learning Rate 0.0002489901077104608 - Cummulative Reward 567.33 - Max Length 836 - Mean Loss 1.1 - Mean Q Value 19.85 - Time Delta 5.517 - Time 2025-04-27T04:05:46\n",
            "Episode 150 - Steps this episode 91936 - Epsilon 0.001 - Learning Rate 0.0002489819285187453 - Cummulative Reward 568.56 - Max Length 837 - Mean Loss 1.106 - Mean Q Value 19.948 - Time Delta 5.366 - Time 2025-04-27T04:05:52\n",
            "Episode 151 - Steps this episode 92595 - Epsilon 0.001 - Learning Rate 0.00024897376826946025 - Cummulative Reward 569.77 - Max Length 838 - Mean Loss 1.114 - Mean Q Value 20.044 - Time Delta 5.47 - Time 2025-04-27T04:05:57\n",
            "Episode 152 - Steps this episode 93245 - Epsilon 0.001 - Learning Rate 0.0002489656269593328 - Cummulative Reward 571.03 - Max Length 838 - Mean Loss 1.119 - Mean Q Value 20.135 - Time Delta 5.403 - Time 2025-04-27T04:06:03\n",
            "Episode 153 - Steps this episode 93893 - Epsilon 0.001 - Learning Rate 0.0002489575606030918 - Cummulative Reward 572.32 - Max Length 838 - Mean Loss 1.125 - Mean Q Value 20.227 - Time Delta 5.422 - Time 2025-04-27T04:06:08\n",
            "Episode 154 - Steps this episode 94555 - Epsilon 0.001 - Learning Rate 0.000248949401152656 - Cummulative Reward 572.41 - Max Length 838 - Mean Loss 1.132 - Mean Q Value 20.318 - Time Delta 5.505 - Time 2025-04-27T04:06:14\n",
            "Episode 155 - Steps this episode 96605 - Epsilon 0.001 - Learning Rate 0.0002489325230516402 - Cummulative Reward 573.67 - Max Length 837 - Mean Loss 1.138 - Mean Q Value 20.404 - Time Delta 16.31 - Time 2025-04-27T04:06:30\n",
            "Episode 156 - Steps this episode 97257 - Epsilon 0.001 - Learning Rate 0.00024891570190571465 - Cummulative Reward 574.92 - Max Length 837 - Mean Loss 1.144 - Mean Q Value 20.49 - Time Delta 5.482 - Time 2025-04-27T04:06:35\n",
            "Episode 157 - Steps this episode 97907 - Epsilon 0.001 - Learning Rate 0.00024890759983067074 - Cummulative Reward 575.03 - Max Length 837 - Mean Loss 1.149 - Mean Q Value 20.57 - Time Delta 5.759 - Time 2025-04-27T04:06:41\n",
            "Episode 158 - Steps this episode 98570 - Epsilon 0.001 - Learning Rate 0.0002488994420176724 - Cummulative Reward 576.25 - Max Length 836 - Mean Loss 1.156 - Mean Q Value 20.65 - Time Delta 5.579 - Time 2025-04-27T04:06:47\n",
            "Episode 159 - Steps this episode 99230 - Epsilon 0.001 - Learning Rate 0.00024889120980404957 - Cummulative Reward 576.34 - Max Length 836 - Mean Loss 1.161 - Mean Q Value 20.727 - Time Delta 5.499 - Time 2025-04-27T04:06:52\n",
            "Episode 160 - Steps this episode 99883 - Epsilon 0.001 - Learning Rate 0.00024888303386128187 - Cummulative Reward 577.78 - Max Length 837 - Mean Loss 1.165 - Mean Q Value 20.801 - Time Delta 5.535 - Time 2025-04-27T04:06:58\n",
            "Episode 161 - Steps this episode 100546 - Epsilon 0.001 - Learning Rate 0.000248874839521986 - Cummulative Reward 579.2 - Max Length 836 - Mean Loss 1.17 - Mean Q Value 20.873 - Time Delta 5.539 - Time 2025-04-27T04:07:03\n",
            "Episode 162 - Steps this episode 101213 - Epsilon 0.001 - Learning Rate 0.0002488665707922925 - Cummulative Reward 579.27 - Max Length 837 - Mean Loss 1.173 - Mean Q Value 20.943 - Time Delta 5.614 - Time 2025-04-27T04:07:09\n",
            "Episode 163 - Steps this episode 101900 - Epsilon 0.001 - Learning Rate 0.0002488581530230083 - Cummulative Reward 580.66 - Max Length 836 - Mean Loss 1.179 - Mean Q Value 21.011 - Time Delta 5.729 - Time 2025-04-27T04:07:15\n",
            "Episode 164 - Steps this episode 102543 - Epsilon 0.001 - Learning Rate 0.00024884986618241896 - Cummulative Reward 582.09 - Max Length 836 - Mean Loss 1.183 - Mean Q Value 21.079 - Time Delta 5.441 - Time 2025-04-27T04:07:20\n",
            "Episode 165 - Steps this episode 103184 - Epsilon 0.001 - Learning Rate 0.0002488418782291243 - Cummulative Reward 583.31 - Max Length 836 - Mean Loss 1.186 - Mean Q Value 21.145 - Time Delta 5.36 - Time 2025-04-27T04:07:25\n",
            "Episode 166 - Steps this episode 103835 - Epsilon 0.001 - Learning Rate 0.00024883385320775624 - Cummulative Reward 584.54 - Max Length 836 - Mean Loss 1.19 - Mean Q Value 21.211 - Time Delta 5.429 - Time 2025-04-27T04:07:31\n",
            "Episode 167 - Steps this episode 104490 - Epsilon 0.001 - Learning Rate 0.0002488257164733872 - Cummulative Reward 584.63 - Max Length 836 - Mean Loss 1.195 - Mean Q Value 21.275 - Time Delta 5.525 - Time 2025-04-27T04:07:36\n",
            "Episode 168 - Steps this episode 105135 - Epsilon 0.001 - Learning Rate 0.00024881761732711914 - Cummulative Reward 584.71 - Max Length 836 - Mean Loss 1.199 - Mean Q Value 21.338 - Time Delta 5.444 - Time 2025-04-27T04:07:42\n",
            "Episode 169 - Steps this episode 105814 - Epsilon 0.001 - Learning Rate 0.00024880938782103793 - Cummulative Reward 584.81 - Max Length 836 - Mean Loss 1.202 - Mean Q Value 21.4 - Time Delta 5.723 - Time 2025-04-27T04:07:48\n",
            "Episode 170 - Steps this episode 106972 - Epsilon 0.001 - Learning Rate 0.00024879796775421496 - Cummulative Reward 584.9 - Max Length 836 - Mean Loss 1.207 - Mean Q Value 21.461 - Time Delta 9.526 - Time 2025-04-27T04:07:57\n",
            "Episode 171 - Steps this episode 107624 - Epsilon 0.001 - Learning Rate 0.00024878671609594206 - Cummulative Reward 586.12 - Max Length 836 - Mean Loss 1.212 - Mean Q Value 21.522 - Time Delta 5.46 - Time 2025-04-27T04:08:03\n",
            "Episode 172 - Steps this episode 108271 - Epsilon 0.001 - Learning Rate 0.0002487786368778181 - Cummulative Reward 587.34 - Max Length 836 - Mean Loss 1.216 - Mean Q Value 21.579 - Time Delta 5.468 - Time 2025-04-27T04:08:08\n",
            "Episode 173 - Steps this episode 108938 - Epsilon 0.001 - Learning Rate 0.0002487704646338279 - Cummulative Reward 588.56 - Max Length 836 - Mean Loss 1.221 - Mean Q Value 21.637 - Time Delta 5.587 - Time 2025-04-27T04:08:14\n",
            "Episode 174 - Steps this episode 109595 - Epsilon 0.001 - Learning Rate 0.00024876223668585643 - Cummulative Reward 589.78 - Max Length 836 - Mean Loss 1.223 - Mean Q Value 21.69 - Time Delta 5.498 - Time 2025-04-27T04:08:19\n",
            "Episode 175 - Steps this episode 110272 - Epsilon 0.001 - Learning Rate 0.0002487539343848576 - Cummulative Reward 589.89 - Max Length 836 - Mean Loss 1.225 - Mean Q Value 21.743 - Time Delta 6.022 - Time 2025-04-27T04:08:25\n",
            "Episode 176 - Steps this episode 110922 - Epsilon 0.001 - Learning Rate 0.0002487456696711376 - Cummulative Reward 591.16 - Max Length 838 - Mean Loss 1.231 - Mean Q Value 21.796 - Time Delta 5.391 - Time 2025-04-27T04:08:31\n",
            "Episode 177 - Steps this episode 111575 - Epsilon 0.001 - Learning Rate 0.0002487375731307557 - Cummulative Reward 591.34 - Max Length 836 - Mean Loss 1.234 - Mean Q Value 21.847 - Time Delta 5.487 - Time 2025-04-27T04:08:36\n",
            "Episode 178 - Steps this episode 112227 - Epsilon 0.001 - Learning Rate 0.0002487294581993019 - Cummulative Reward 592.56 - Max Length 836 - Mean Loss 1.236 - Mean Q Value 21.897 - Time Delta 5.479 - Time 2025-04-27T04:08:42\n",
            "Episode 179 - Steps this episode 112892 - Epsilon 0.001 - Learning Rate 0.00024872126891640166 - Cummulative Reward 592.55 - Max Length 838 - Mean Loss 1.241 - Mean Q Value 21.945 - Time Delta 5.604 - Time 2025-04-27T04:08:47\n",
            "Episode 180 - Steps this episode 113595 - Epsilon 0.001 - Learning Rate 0.00024871276279531216 - Cummulative Reward 593.76 - Max Length 837 - Mean Loss 1.244 - Mean Q Value 21.994 - Time Delta 5.854 - Time 2025-04-27T04:08:53\n",
            "Episode 181 - Steps this episode 114267 - Epsilon 0.001 - Learning Rate 0.00024870420100400563 - Cummulative Reward 594.8 - Max Length 838 - Mean Loss 1.246 - Mean Q Value 22.041 - Time Delta 5.624 - Time 2025-04-27T04:08:59\n",
            "Episode 182 - Steps this episode 114920 - Epsilon 0.001 - Learning Rate 0.0002486959752472563 - Cummulative Reward 596.03 - Max Length 838 - Mean Loss 1.249 - Mean Q Value 22.086 - Time Delta 5.444 - Time 2025-04-27T04:09:04\n",
            "Episode 183 - Steps this episode 115643 - Epsilon 0.001 - Learning Rate 0.0002486874326891492 - Cummulative Reward 597.19 - Max Length 838 - Mean Loss 1.254 - Mean Q Value 22.133 - Time Delta 6.061 - Time 2025-04-27T04:09:10\n",
            "Episode 184 - Steps this episode 116337 - Epsilon 0.001 - Learning Rate 0.0002486786106573035 - Cummulative Reward 598.37 - Max Length 836 - Mean Loss 1.256 - Mean Q Value 22.179 - Time Delta 5.772 - Time 2025-04-27T04:09:16\n",
            "Episode 185 - Steps this episode 116993 - Epsilon 0.001 - Learning Rate 0.0002486702178937255 - Cummulative Reward 599.61 - Max Length 836 - Mean Loss 1.259 - Mean Q Value 22.223 - Time Delta 5.481 - Time 2025-04-27T04:09:21\n",
            "Episode 186 - Steps this episode 117652 - Epsilon 0.001 - Learning Rate 0.00024866204921083194 - Cummulative Reward 599.72 - Max Length 838 - Mean Loss 1.263 - Mean Q Value 22.268 - Time Delta 5.526 - Time 2025-04-27T04:09:27\n",
            "Episode 187 - Steps this episode 118304 - Epsilon 0.001 - Learning Rate 0.0002486538994448085 - Cummulative Reward 598.63 - Max Length 838 - Mean Loss 1.266 - Mean Q Value 22.314 - Time Delta 5.482 - Time 2025-04-27T04:09:32\n",
            "Episode 188 - Steps this episode 118961 - Epsilon 0.001 - Learning Rate 0.00024864576859483147 - Cummulative Reward 598.68 - Max Length 837 - Mean Loss 1.268 - Mean Q Value 22.362 - Time Delta 5.52 - Time 2025-04-27T04:09:38\n",
            "Episode 189 - Steps this episode 119611 - Epsilon 0.001 - Learning Rate 0.00024863763801032243 - Cummulative Reward 598.8 - Max Length 838 - Mean Loss 1.272 - Mean Q Value 22.407 - Time Delta 5.454 - Time 2025-04-27T04:09:43\n",
            "Episode 190 - Steps this episode 120262 - Epsilon 0.001 - Learning Rate 0.00024862954498631415 - Cummulative Reward 598.86 - Max Length 838 - Mean Loss 1.274 - Mean Q Value 22.451 - Time Delta 5.473 - Time 2025-04-27T04:09:49\n",
            "Episode 191 - Steps this episode 120983 - Epsilon 0.001 - Learning Rate 0.00024862102335651223 - Cummulative Reward 598.95 - Max Length 838 - Mean Loss 1.277 - Mean Q Value 22.494 - Time Delta 5.996 - Time 2025-04-27T04:09:55\n",
            "Episode 192 - Steps this episode 121654 - Epsilon 0.001 - Learning Rate 0.0002486123714930648 - Cummulative Reward 598.95 - Max Length 838 - Mean Loss 1.279 - Mean Q Value 22.535 - Time Delta 5.655 - Time 2025-04-27T04:10:00\n",
            "Episode 193 - Steps this episode 122324 - Epsilon 0.001 - Learning Rate 0.00024860403690229186 - Cummulative Reward 598.98 - Max Length 836 - Mean Loss 1.284 - Mean Q Value 22.576 - Time Delta 5.63 - Time 2025-04-27T04:10:06\n",
            "Episode 194 - Steps this episode 122976 - Epsilon 0.001 - Learning Rate 0.00024859581445862137 - Cummulative Reward 599.05 - Max Length 836 - Mean Loss 1.286 - Mean Q Value 22.616 - Time Delta 5.486 - Time 2025-04-27T04:10:12\n",
            "Episode 195 - Steps this episode 123626 - Epsilon 0.001 - Learning Rate 0.00024858772279574533 - Cummulative Reward 599.17 - Max Length 838 - Mean Loss 1.287 - Mean Q Value 22.653 - Time Delta 5.455 - Time 2025-04-27T04:10:17\n",
            "Episode 196 - Steps this episode 124304 - Epsilon 0.001 - Learning Rate 0.0002485794822497358 - Cummulative Reward 599.25 - Max Length 837 - Mean Loss 1.289 - Mean Q Value 22.69 - Time Delta 6.129 - Time 2025-04-27T04:10:23\n",
            "Episode 197 - Steps this episode 125024 - Epsilon 0.001 - Learning Rate 0.0002485707945495198 - Cummulative Reward 599.28 - Max Length 837 - Mean Loss 1.294 - Mean Q Value 22.727 - Time Delta 6.03 - Time 2025-04-27T04:10:29\n",
            "Episode 198 - Steps this episode 125672 - Epsilon 0.001 - Learning Rate 0.0002485622935705273 - Cummulative Reward 599.39 - Max Length 838 - Mean Loss 1.296 - Mean Q Value 22.764 - Time Delta 5.483 - Time 2025-04-27T04:10:35\n",
            "Episode 199 - Steps this episode 126323 - Epsilon 0.001 - Learning Rate 0.000248554221640609 - Cummulative Reward 599.43 - Max Length 837 - Mean Loss 1.297 - Mean Q Value 22.799 - Time Delta 5.558 - Time 2025-04-27T04:10:40\n",
            "Episode 200 - Steps this episode 126974 - Epsilon 0.001 - Learning Rate 0.00024854613133175964 - Cummulative Reward 599.51 - Max Length 836 - Mean Loss 1.3 - Mean Q Value 22.834 - Time Delta 5.546 - Time 2025-04-27T04:10:46\n",
            "Episode 201 - Steps this episode 127608 - Epsilon 0.001 - Learning Rate 0.0002485381344875356 - Cummulative Reward 599.49 - Max Length 837 - Mean Loss 1.305 - Mean Q Value 22.869 - Time Delta 5.454 - Time 2025-04-27T04:10:51\n",
            "Episode 202 - Steps this episode 128259 - Epsilon 0.001 - Learning Rate 0.0002485301379016055 - Cummulative Reward 599.57 - Max Length 838 - Mean Loss 1.308 - Mean Q Value 22.903 - Time Delta 5.588 - Time 2025-04-27T04:10:57\n",
            "Episode 203 - Steps this episode 128921 - Epsilon 0.001 - Learning Rate 0.0002485219924595158 - Cummulative Reward 599.58 - Max Length 836 - Mean Loss 1.311 - Mean Q Value 22.936 - Time Delta 5.722 - Time 2025-04-27T04:11:03\n",
            "Episode 204 - Steps this episode 129571 - Epsilon 0.001 - Learning Rate 0.00024851384728377765 - Cummulative Reward 599.6 - Max Length 838 - Mean Loss 1.312 - Mean Q Value 22.969 - Time Delta 5.629 - Time 2025-04-27T04:11:08\n",
            "Episode 205 - Steps this episode 130451 - Epsilon 0.001 - Learning Rate 0.00024850434181923115 - Cummulative Reward 599.67 - Max Length 837 - Mean Loss 1.314 - Mean Q Value 23.001 - Time Delta 7.461 - Time 2025-04-27T04:11:16\n",
            "Episode 206 - Steps this episode 131116 - Epsilon 0.001 - Learning Rate 0.00024849474351515996 - Cummulative Reward 599.79 - Max Length 838 - Mean Loss 1.315 - Mean Q Value 23.034 - Time Delta 5.752 - Time 2025-04-27T04:11:21\n",
            "Episode 207 - Steps this episode 131769 - Epsilon 0.001 - Learning Rate 0.00024848654332290405 - Cummulative Reward 599.86 - Max Length 838 - Mean Loss 1.316 - Mean Q Value 23.063 - Time Delta 5.637 - Time 2025-04-27T04:11:27\n",
            "Episode 208 - Steps this episode 132432 - Epsilon 0.001 - Learning Rate 0.0002484783620378448 - Cummulative Reward 599.94 - Max Length 836 - Mean Loss 1.32 - Mean Q Value 23.094 - Time Delta 5.709 - Time 2025-04-27T04:11:33\n",
            "Episode 209 - Steps this episode 133083 - Epsilon 0.001 - Learning Rate 0.0002484701996567006 - Cummulative Reward 599.93 - Max Length 836 - Mean Loss 1.323 - Mean Q Value 23.124 - Time Delta 5.629 - Time 2025-04-27T04:11:38\n",
            "Episode 210 - Steps this episode 133716 - Epsilon 0.001 - Learning Rate 0.00024846222389010813 - Cummulative Reward 599.93 - Max Length 838 - Mean Loss 1.325 - Mean Q Value 23.15 - Time Delta 5.479 - Time 2025-04-27T04:11:44\n",
            "Episode 211 - Steps this episode 134407 - Epsilon 0.001 - Learning Rate 0.0002484540061392914 - Cummulative Reward 600.04 - Max Length 838 - Mean Loss 1.328 - Mean Q Value 23.177 - Time Delta 5.981 - Time 2025-04-27T04:11:50\n",
            "Episode 212 - Steps this episode 135072 - Epsilon 0.001 - Learning Rate 0.00024844558368977194 - Cummulative Reward 599.86 - Max Length 836 - Mean Loss 1.33 - Mean Q Value 23.201 - Time Delta 5.736 - Time 2025-04-27T04:11:56\n",
            "Episode 213 - Steps this episode 135722 - Epsilon 0.001 - Learning Rate 0.00024843742238517497 - Cummulative Reward 600.06 - Max Length 838 - Mean Loss 1.334 - Mean Q Value 23.227 - Time Delta 5.639 - Time 2025-04-27T04:12:01\n",
            "Episode 214 - Steps this episode 136359 - Epsilon 0.001 - Learning Rate 0.00024842942903880534 - Cummulative Reward 600.07 - Max Length 838 - Mean Loss 1.337 - Mean Q Value 23.252 - Time Delta 5.5 - Time 2025-04-27T04:12:07\n",
            "Episode 215 - Steps this episode 137007 - Epsilon 0.001 - Learning Rate 0.00024842143595021703 - Cummulative Reward 599.95 - Max Length 838 - Mean Loss 1.34 - Mean Q Value 23.273 - Time Delta 5.672 - Time 2025-04-27T04:12:12\n",
            "Episode 216 - Steps this episode 137673 - Epsilon 0.001 - Learning Rate 0.00024841327544008443 - Cummulative Reward 599.75 - Max Length 838 - Mean Loss 1.342 - Mean Q Value 23.293 - Time Delta 5.796 - Time 2025-04-27T04:12:18\n",
            "Episode 217 - Steps this episode 138314 - Epsilon 0.001 - Learning Rate 0.00024840517108765787 - Cummulative Reward 599.76 - Max Length 838 - Mean Loss 1.345 - Mean Q Value 23.314 - Time Delta 5.654 - Time 2025-04-27T04:12:24\n",
            "Episode 218 - Steps this episode 138958 - Epsilon 0.001 - Learning Rate 0.00024839719740924685 - Cummulative Reward 599.66 - Max Length 838 - Mean Loss 1.346 - Mean Q Value 23.336 - Time Delta 5.583 - Time 2025-04-27T04:12:29\n",
            "Episode 219 - Steps this episode 139597 - Epsilon 0.001 - Learning Rate 0.00024838922398638815 - Cummulative Reward 599.67 - Max Length 838 - Mean Loss 1.349 - Mean Q Value 23.356 - Time Delta 6.026 - Time 2025-04-27T04:12:35\n",
            "Episode 220 - Steps this episode 140261 - Epsilon 0.001 - Learning Rate 0.00024838113904893387 - Cummulative Reward 599.68 - Max Length 838 - Mean Loss 1.354 - Mean Q Value 23.376 - Time Delta 5.758 - Time 2025-04-27T04:12:41\n",
            "Episode 221 - Steps this episode 140926 - Epsilon 0.001 - Learning Rate 0.0002483728867221671 - Cummulative Reward 599.7 - Max Length 838 - Mean Loss 1.358 - Mean Q Value 23.399 - Time Delta 5.831 - Time 2025-04-27T04:12:47\n",
            "Episode 222 - Steps this episode 141568 - Epsilon 0.001 - Learning Rate 0.00024836476506014116 - Cummulative Reward 599.74 - Max Length 838 - Mean Loss 1.359 - Mean Q Value 23.42 - Time Delta 5.6 - Time 2025-04-27T04:12:53\n",
            "Episode 223 - Steps this episode 142240 - Epsilon 0.001 - Learning Rate 0.00024835660641202474 - Cummulative Reward 599.7 - Max Length 835 - Mean Loss 1.365 - Mean Q Value 23.44 - Time Delta 5.878 - Time 2025-04-27T04:12:59\n",
            "Episode 224 - Steps this episode 142888 - Epsilon 0.001 - Learning Rate 0.0002483484107778089 - Cummulative Reward 598.46 - Max Length 838 - Mean Loss 1.366 - Mean Q Value 23.459 - Time Delta 5.648 - Time 2025-04-27T04:13:04\n",
            "Episode 225 - Steps this episode 143536 - Epsilon 0.001 - Learning Rate 0.0002483403644190492 - Cummulative Reward 598.41 - Max Length 833 - Mean Loss 1.368 - Mean Q Value 23.48 - Time Delta 5.659 - Time 2025-04-27T04:13:10\n",
            "Episode 226 - Steps this episode 144180 - Epsilon 0.001 - Learning Rate 0.00024833233694581276 - Cummulative Reward 598.38 - Max Length 835 - Mean Loss 1.371 - Mean Q Value 23.502 - Time Delta 5.655 - Time 2025-04-27T04:13:15\n",
            "Episode 227 - Steps this episode 144832 - Epsilon 0.001 - Learning Rate 0.0002483242911080379 - Cummulative Reward 598.37 - Max Length 836 - Mean Loss 1.373 - Mean Q Value 23.524 - Time Delta 5.677 - Time 2025-04-27T04:13:21\n",
            "Episode 228 - Steps this episode 145603 - Epsilon 0.001 - Learning Rate 0.00024831546334015675 - Cummulative Reward 603.15 - Max Length 1333 - Mean Loss 1.375 - Mean Q Value 23.544 - Time Delta 6.804 - Time 2025-04-27T04:13:28\n",
            "Episode 229 - Steps this episode 146259 - Epsilon 0.001 - Learning Rate 0.0002483065986314772 - Cummulative Reward 603.14 - Max Length 838 - Mean Loss 1.376 - Mean Q Value 23.564 - Time Delta 5.735 - Time 2025-04-27T04:13:34\n",
            "Episode 230 - Steps this episode 146896 - Epsilon 0.001 - Learning Rate 0.00024829857224910047 - Cummulative Reward 603.17 - Max Length 838 - Mean Loss 1.38 - Mean Q Value 23.582 - Time Delta 5.635 - Time 2025-04-27T04:13:39\n",
            "Episode 231 - Steps this episode 147562 - Epsilon 0.001 - Learning Rate 0.0002482904902625142 - Cummulative Reward 603.25 - Max Length 836 - Mean Loss 1.382 - Mean Q Value 23.601 - Time Delta 5.817 - Time 2025-04-27T04:13:45\n",
            "Episode 232 - Steps this episode 148219 - Epsilon 0.001 - Learning Rate 0.0002482822781894341 - Cummulative Reward 603.26 - Max Length 838 - Mean Loss 1.386 - Mean Q Value 23.621 - Time Delta 5.763 - Time 2025-04-27T04:13:51\n",
            "Episode 233 - Steps this episode 148872 - Epsilon 0.001 - Learning Rate 0.0002482741408704068 - Cummulative Reward 603.16 - Max Length 829 - Mean Loss 1.387 - Mean Q Value 23.641 - Time Delta 5.64 - Time 2025-04-27T04:13:57\n",
            "Episode 234 - Steps this episode 149527 - Epsilon 0.001 - Learning Rate 0.0002482660224381299 - Cummulative Reward 603.18 - Max Length 837 - Mean Loss 1.391 - Mean Q Value 23.66 - Time Delta 5.731 - Time 2025-04-27T04:14:02\n",
            "Episode 235 - Steps this episode 150147 - Epsilon 0.001 - Learning Rate 0.0002482581090831041 - Cummulative Reward 603.09 - Max Length 828 - Mean Loss 1.395 - Mean Q Value 23.681 - Time Delta 5.361 - Time 2025-04-27T04:14:08\n",
            "Episode 236 - Steps this episode 150788 - Epsilon 0.001 - Learning Rate 0.000248250289075835 - Cummulative Reward 603.12 - Max Length 838 - Mean Loss 1.397 - Mean Q Value 23.698 - Time Delta 5.612 - Time 2025-04-27T04:14:13\n",
            "Episode 237 - Steps this episode 151434 - Epsilon 0.001 - Learning Rate 0.0002482423017509824 - Cummulative Reward 602.93 - Max Length 832 - Mean Loss 1.399 - Mean Q Value 23.716 - Time Delta 5.618 - Time 2025-04-27T04:14:19\n",
            "Episode 238 - Steps this episode 152082 - Epsilon 0.001 - Learning Rate 0.0002482342588300998 - Cummulative Reward 602.88 - Max Length 835 - Mean Loss 1.399 - Mean Q Value 23.736 - Time Delta 5.7 - Time 2025-04-27T04:14:25\n",
            "Episode 239 - Steps this episode 152716 - Epsilon 0.001 - Learning Rate 0.0002482263092541622 - Cummulative Reward 602.81 - Max Length 832 - Mean Loss 1.4 - Mean Q Value 23.752 - Time Delta 5.453 - Time 2025-04-27T04:14:30\n",
            "Episode 240 - Steps this episode 153355 - Epsilon 0.001 - Learning Rate 0.0002482184157826414 - Cummulative Reward 602.76 - Max Length 835 - Mean Loss 1.402 - Mean Q Value 23.77 - Time Delta 5.562 - Time 2025-04-27T04:14:36\n",
            "Episode 241 - Steps this episode 153992 - Epsilon 0.001 - Learning Rate 0.0002482105039460429 - Cummulative Reward 602.7 - Max Length 835 - Mean Loss 1.404 - Mean Q Value 23.789 - Time Delta 5.549 - Time 2025-04-27T04:14:41\n",
            "Episode 242 - Steps this episode 154619 - Epsilon 0.001 - Learning Rate 0.00024820266682222953 - Cummulative Reward 602.67 - Max Length 829 - Mean Loss 1.405 - Mean Q Value 23.81 - Time Delta 5.449 - Time 2025-04-27T04:14:47\n",
            "Episode 243 - Steps this episode 155259 - Epsilon 0.001 - Learning Rate 0.000248194792717431 - Cummulative Reward 602.54 - Max Length 832 - Mean Loss 1.405 - Mean Q Value 23.83 - Time Delta 5.66 - Time 2025-04-27T04:14:52\n",
            "Episode 244 - Steps this episode 155888 - Epsilon 0.001 - Learning Rate 0.0002481869188614503 - Cummulative Reward 602.47 - Max Length 832 - Mean Loss 1.406 - Mean Q Value 23.851 - Time Delta 5.596 - Time 2025-04-27T04:14:58\n",
            "Episode 245 - Steps this episode 156516 - Epsilon 0.001 - Learning Rate 0.00024817911970958373 - Cummulative Reward 602.4 - Max Length 835 - Mean Loss 1.408 - Mean Q Value 23.871 - Time Delta 6.105 - Time 2025-04-27T04:15:04\n",
            "Episode 246 - Steps this episode 157146 - Epsilon 0.001 - Learning Rate 0.0002481713021898545 - Cummulative Reward 602.34 - Max Length 829 - Mean Loss 1.411 - Mean Q Value 23.888 - Time Delta 5.571 - Time 2025-04-27T04:15:10\n",
            "Episode 247 - Steps this episode 157806 - Epsilon 0.001 - Learning Rate 0.0002481632987948132 - Cummulative Reward 602.14 - Max Length 832 - Mean Loss 1.415 - Mean Q Value 23.909 - Time Delta 5.905 - Time 2025-04-27T04:15:15\n",
            "Episode 248 - Steps this episode 158460 - Epsilon 0.001 - Learning Rate 0.0002481551467635275 - Cummulative Reward 601.95 - Max Length 838 - Mean Loss 1.417 - Mean Q Value 23.928 - Time Delta 5.796 - Time 2025-04-27T04:15:21\n",
            "Episode 249 - Steps this episode 159120 - Epsilon 0.001 - Learning Rate 0.00024814699500044345 - Cummulative Reward 601.77 - Max Length 836 - Mean Loss 1.419 - Mean Q Value 23.946 - Time Delta 5.894 - Time 2025-04-27T04:15:27\n",
            "Episode 250 - Steps this episode 159760 - Epsilon 0.001 - Learning Rate 0.0002481389365563222 - Cummulative Reward 601.79 - Max Length 838 - Mean Loss 1.418 - Mean Q Value 23.964 - Time Delta 5.639 - Time 2025-04-27T04:15:33\n",
            "Episode 251 - Steps this episode 160413 - Epsilon 0.001 - Learning Rate 0.0002481309155947385 - Cummulative Reward 601.79 - Max Length 838 - Mean Loss 1.419 - Mean Q Value 23.98 - Time Delta 5.759 - Time 2025-04-27T04:15:39\n",
            "Episode 252 - Steps this episode 161048 - Epsilon 0.001 - Learning Rate 0.0002481229321096682 - Cummulative Reward 601.79 - Max Length 838 - Mean Loss 1.421 - Mean Q Value 23.996 - Time Delta 5.585 - Time 2025-04-27T04:15:44\n",
            "Episode 253 - Steps this episode 161692 - Epsilon 0.001 - Learning Rate 0.0002481150047084312 - Cummulative Reward 601.59 - Max Length 836 - Mean Loss 1.424 - Mean Q Value 24.011 - Time Delta 5.738 - Time 2025-04-27T04:15:50\n",
            "Episode 254 - Steps this episode 162322 - Epsilon 0.001 - Learning Rate 0.000248107096167613 - Cummulative Reward 601.54 - Max Length 838 - Mean Loss 1.423 - Mean Q Value 24.024 - Time Delta 5.513 - Time 2025-04-27T04:15:55\n",
            "Episode 255 - Steps this episode 162957 - Epsilon 0.001 - Learning Rate 0.00024809924370189384 - Cummulative Reward 601.46 - Max Length 838 - Mean Loss 1.426 - Mean Q Value 24.038 - Time Delta 5.611 - Time 2025-04-27T04:16:01\n",
            "Episode 256 - Steps this episode 163587 - Epsilon 0.001 - Learning Rate 0.00024809139148430876 - Cummulative Reward 601.45 - Max Length 836 - Mean Loss 1.427 - Mean Q Value 24.051 - Time Delta 5.631 - Time 2025-04-27T04:16:07\n",
            "Episode 257 - Steps this episode 164216 - Epsilon 0.001 - Learning Rate 0.0002480835953341481 - Cummulative Reward 601.36 - Max Length 827 - Mean Loss 1.431 - Mean Q Value 24.067 - Time Delta 5.591 - Time 2025-04-27T04:16:12\n",
            "Episode 258 - Steps this episode 164853 - Epsilon 0.001 - Learning Rate 0.0002480757436124147 - Cummulative Reward 601.36 - Max Length 835 - Mean Loss 1.432 - Mean Q Value 24.08 - Time Delta 5.68 - Time 2025-04-27T04:16:18\n",
            "Episode 259 - Steps this episode 165485 - Epsilon 0.001 - Learning Rate 0.00024806787353340423 - Cummulative Reward 601.38 - Max Length 837 - Mean Loss 1.435 - Mean Q Value 24.095 - Time Delta 5.548 - Time 2025-04-27T04:16:23\n",
            "Episode 260 - Steps this episode 166120 - Epsilon 0.001 - Learning Rate 0.0002480600223090618 - Cummulative Reward 601.26 - Max Length 832 - Mean Loss 1.436 - Mean Q Value 24.11 - Time Delta 5.706 - Time 2025-04-27T04:16:29\n",
            "Episode 261 - Steps this episode 166745 - Epsilon 0.001 - Learning Rate 0.00024805220854045104 - Cummulative Reward 601.16 - Max Length 829 - Mean Loss 1.438 - Mean Q Value 24.127 - Time Delta 5.636 - Time 2025-04-27T04:16:35\n",
            "Episode 262 - Steps this episode 167397 - Epsilon 0.001 - Learning Rate 0.0002480442833993905 - Cummulative Reward 601.11 - Max Length 837 - Mean Loss 1.441 - Mean Q Value 24.142 - Time Delta 5.832 - Time 2025-04-27T04:16:41\n",
            "Episode 263 - Steps this episode 168048 - Epsilon 0.001 - Learning Rate 0.00024803619108594436 - Cummulative Reward 601.14 - Max Length 836 - Mean Loss 1.44 - Mean Q Value 24.159 - Time Delta 5.782 - Time 2025-04-27T04:16:46\n",
            "Episode 264 - Steps this episode 168683 - Epsilon 0.001 - Learning Rate 0.00024802822925080553 - Cummulative Reward 601.08 - Max Length 832 - Mean Loss 1.443 - Mean Q Value 24.174 - Time Delta 5.668 - Time 2025-04-27T04:16:52\n",
            "Episode 265 - Steps this episode 169311 - Epsilon 0.001 - Learning Rate 0.0002480203978824214 - Cummulative Reward 601.03 - Max Length 829 - Mean Loss 1.446 - Mean Q Value 24.189 - Time Delta 5.571 - Time 2025-04-27T04:16:58\n",
            "Episode 266 - Steps this episode 169942 - Epsilon 0.001 - Learning Rate 0.00024801258536235124 - Cummulative Reward 600.97 - Max Length 835 - Mean Loss 1.447 - Mean Q Value 24.203 - Time Delta 5.637 - Time 2025-04-27T04:17:03\n",
            "Episode 267 - Steps this episode 170579 - Epsilon 0.001 - Learning Rate 0.00024800473588785187 - Cummulative Reward 600.88 - Max Length 829 - Mean Loss 1.447 - Mean Q Value 24.219 - Time Delta 5.659 - Time 2025-04-27T04:17:09\n",
            "Episode 268 - Steps this episode 171232 - Epsilon 0.001 - Learning Rate 0.0002479967378640895 - Cummulative Reward 600.83 - Max Length 832 - Mean Loss 1.448 - Mean Q Value 24.235 - Time Delta 5.857 - Time 2025-04-27T04:17:15\n",
            "Episode 269 - Steps this episode 171905 - Epsilon 0.001 - Learning Rate 0.00024798851690849364 - Cummulative Reward 600.78 - Max Length 835 - Mean Loss 1.448 - Mean Q Value 24.251 - Time Delta 6.042 - Time 2025-04-27T04:17:21\n",
            "Episode 270 - Steps this episode 172529 - Epsilon 0.001 - Learning Rate 0.0002479804822085003 - Cummulative Reward 600.68 - Max Length 827 - Mean Loss 1.448 - Mean Q Value 24.265 - Time Delta 5.667 - Time 2025-04-27T04:17:26\n",
            "Episode 271 - Steps this episode 173147 - Epsilon 0.001 - Learning Rate 0.000247972782533297 - Cummulative Reward 600.61 - Max Length 827 - Mean Loss 1.448 - Mean Q Value 24.281 - Time Delta 6.1 - Time 2025-04-27T04:17:33\n",
            "Episode 272 - Steps this episode 173800 - Epsilon 0.001 - Learning Rate 0.00024796489712478374 - Cummulative Reward 600.44 - Max Length 832 - Mean Loss 1.445 - Mean Q Value 24.297 - Time Delta 5.892 - Time 2025-04-27T04:17:38\n",
            "Episode 273 - Steps this episode 174430 - Epsilon 0.001 - Learning Rate 0.0002479569375779458 - Cummulative Reward 600.37 - Max Length 836 - Mean Loss 1.444 - Mean Q Value 24.313 - Time Delta 5.664 - Time 2025-04-27T04:17:44\n",
            "Episode 274 - Steps this episode 175086 - Epsilon 0.001 - Learning Rate 0.00024794895969212466 - Cummulative Reward 600.29 - Max Length 832 - Mean Loss 1.445 - Mean Q Value 24.331 - Time Delta 5.924 - Time 2025-04-27T04:17:50\n",
            "Episode 275 - Steps this episode 175723 - Epsilon 0.001 - Learning Rate 0.00024794094487024166 - Cummulative Reward 600.18 - Max Length 836 - Mean Loss 1.449 - Mean Q Value 24.348 - Time Delta 5.77 - Time 2025-04-27T04:17:56\n",
            "Episode 276 - Steps this episode 176353 - Epsilon 0.001 - Learning Rate 0.0002479330976627357 - Cummulative Reward 600.1 - Max Length 835 - Mean Loss 1.447 - Mean Q Value 24.365 - Time Delta 5.735 - Time 2025-04-27T04:18:02\n",
            "Episode 277 - Steps this episode 176987 - Epsilon 0.001 - Learning Rate 0.0002479252692982798 - Cummulative Reward 600.1 - Max Length 836 - Mean Loss 1.448 - Mean Q Value 24.381 - Time Delta 5.719 - Time 2025-04-27T04:18:07\n",
            "Episode 278 - Steps this episode 177622 - Epsilon 0.001 - Learning Rate 0.0002479174039933852 - Cummulative Reward 600.1 - Max Length 835 - Mean Loss 1.449 - Mean Q Value 24.397 - Time Delta 5.788 - Time 2025-04-27T04:18:13\n",
            "Episode 279 - Steps this episode 178265 - Epsilon 0.001 - Learning Rate 0.00024790948315846884 - Cummulative Reward 600.04 - Max Length 836 - Mean Loss 1.451 - Mean Q Value 24.415 - Time Delta 5.83 - Time 2025-04-27T04:18:19\n",
            "Episode 280 - Steps this episode 178906 - Epsilon 0.001 - Learning Rate 0.00024790152539118674 - Cummulative Reward 599.98 - Max Length 832 - Mean Loss 1.451 - Mean Q Value 24.432 - Time Delta 5.835 - Time 2025-04-27T04:18:25\n",
            "Episode 281 - Steps this episode 179539 - Epsilon 0.001 - Learning Rate 0.0002478936236551118 - Cummulative Reward 600.09 - Max Length 838 - Mean Loss 1.453 - Mean Q Value 24.451 - Time Delta 5.799 - Time 2025-04-27T04:18:31\n",
            "Episode 282 - Steps this episode 180171 - Epsilon 0.001 - Learning Rate 0.00024788577794549496 - Cummulative Reward 600.04 - Max Length 834 - Mean Loss 1.454 - Mean Q Value 24.471 - Time Delta 5.717 - Time 2025-04-27T04:18:36\n",
            "Episode 283 - Steps this episode 181243 - Epsilon 0.001 - Learning Rate 0.0002478752182547586 - Cummulative Reward 605.76 - Max Length 1445 - Mean Loss 1.453 - Mean Q Value 24.49 - Time Delta 9.626 - Time 2025-04-27T04:18:46\n",
            "Episode 284 - Steps this episode 181901 - Epsilon 0.001 - Learning Rate 0.00024786451025735165 - Cummulative Reward 605.83 - Max Length 838 - Mean Loss 1.456 - Mean Q Value 24.51 - Time Delta 6.007 - Time 2025-04-27T04:18:52\n",
            "Episode 285 - Steps this episode 182537 - Epsilon 0.001 - Learning Rate 0.0002478564981652527 - Cummulative Reward 605.77 - Max Length 829 - Mean Loss 1.455 - Mean Q Value 24.53 - Time Delta 5.862 - Time 2025-04-27T04:18:58\n",
            "Episode 286 - Steps this episode 183167 - Epsilon 0.001 - Learning Rate 0.00024784865363044296 - Cummulative Reward 605.59 - Max Length 832 - Mean Loss 1.458 - Mean Q Value 24.548 - Time Delta 5.79 - Time 2025-04-27T04:19:04\n",
            "Episode 287 - Steps this episode 183790 - Epsilon 0.001 - Learning Rate 0.00024784088369617015 - Cummulative Reward 605.49 - Max Length 829 - Mean Loss 1.459 - Mean Q Value 24.564 - Time Delta 5.734 - Time 2025-04-27T04:19:09\n",
            "Episode 288 - Steps this episode 184416 - Epsilon 0.001 - Learning Rate 0.00024783313259325786 - Cummulative Reward 605.44 - Max Length 829 - Mean Loss 1.46 - Mean Q Value 24.581 - Time Delta 5.761 - Time 2025-04-27T04:19:15\n",
            "Episode 289 - Steps this episode 185044 - Epsilon 0.001 - Learning Rate 0.0002478253631457563 - Cummulative Reward 605.36 - Max Length 829 - Mean Loss 1.458 - Mean Q Value 24.595 - Time Delta 5.823 - Time 2025-04-27T04:19:21\n",
            "Episode 290 - Steps this episode 185679 - Epsilon 0.001 - Learning Rate 0.00024781753818316015 - Cummulative Reward 605.18 - Max Length 832 - Mean Loss 1.458 - Mean Q Value 24.609 - Time Delta 5.834 - Time 2025-04-27T04:19:27\n",
            "Episode 291 - Steps this episode 186299 - Epsilon 0.001 - Learning Rate 0.0002478097692239531 - Cummulative Reward 605.13 - Max Length 829 - Mean Loss 1.461 - Mean Q Value 24.624 - Time Delta 5.752 - Time 2025-04-27T04:19:32\n",
            "Episode 292 - Steps this episode 186962 - Epsilon 0.001 - Learning Rate 0.00024780183324406334 - Cummulative Reward 605.04 - Max Length 832 - Mean Loss 1.462 - Mean Q Value 24.637 - Time Delta 6.079 - Time 2025-04-27T04:19:38\n",
            "Episode 293 - Steps this episode 187606 - Epsilon 0.001 - Learning Rate 0.00024779373025538666 - Cummulative Reward 604.88 - Max Length 832 - Mean Loss 1.461 - Mean Q Value 24.652 - Time Delta 5.921 - Time 2025-04-27T04:19:44\n",
            "Episode 294 - Steps this episode 188230 - Epsilon 0.001 - Learning Rate 0.00024778586912271595 - Cummulative Reward 604.82 - Max Length 829 - Mean Loss 1.463 - Mean Q Value 24.666 - Time Delta 5.758 - Time 2025-04-27T04:19:50\n",
            "Episode 295 - Steps this episode 188857 - Epsilon 0.001 - Learning Rate 0.00024777811974035764 - Cummulative Reward 604.74 - Max Length 829 - Mean Loss 1.464 - Mean Q Value 24.678 - Time Delta 5.846 - Time 2025-04-27T04:19:56\n",
            "Episode 296 - Steps this episode 189497 - Epsilon 0.001 - Learning Rate 0.0002477702776867742 - Cummulative Reward 604.68 - Max Length 832 - Mean Loss 1.466 - Mean Q Value 24.691 - Time Delta 5.912 - Time 2025-04-27T04:20:02\n",
            "Episode 297 - Steps this episode 190133 - Epsilon 0.001 - Learning Rate 0.00024776238013435103 - Cummulative Reward 604.65 - Max Length 835 - Mean Loss 1.466 - Mean Q Value 24.704 - Time Delta 5.919 - Time 2025-04-27T04:20:08\n",
            "Episode 298 - Steps this episode 190762 - Epsilon 0.001 - Learning Rate 0.0002477545385783299 - Cummulative Reward 604.54 - Max Length 829 - Mean Loss 1.47 - Mean Q Value 24.713 - Time Delta 5.818 - Time 2025-04-27T04:20:14\n",
            "Episode 299 - Steps this episode 191400 - Epsilon 0.001 - Learning Rate 0.00024774667868997816 - Cummulative Reward 604.44 - Max Length 832 - Mean Loss 1.471 - Mean Q Value 24.724 - Time Delta 5.949 - Time 2025-04-27T04:20:20\n",
            "Episode 300 - Steps this episode 192021 - Epsilon 0.001 - Learning Rate 0.0002477388747913422 - Cummulative Reward 604.35 - Max Length 829 - Mean Loss 1.472 - Mean Q Value 24.737 - Time Delta 6.322 - Time 2025-04-27T04:20:26\n",
            "Episode 301 - Steps this episode 192650 - Epsilon 0.001 - Learning Rate 0.0002477311454586417 - Cummulative Reward 604.35 - Max Length 828 - Mean Loss 1.472 - Mean Q Value 24.747 - Time Delta 5.869 - Time 2025-04-27T04:20:32\n",
            "Episode 302 - Steps this episode 193273 - Epsilon 0.001 - Learning Rate 0.00024772339778754573 - Cummulative Reward 604.3 - Max Length 829 - Mean Loss 1.472 - Mean Q Value 24.759 - Time Delta 5.792 - Time 2025-04-27T04:20:38\n",
            "Episode 303 - Steps this episode 194000 - Epsilon 0.001 - Learning Rate 0.00024771503726688253 - Cummulative Reward 604.15 - Max Length 829 - Mean Loss 1.473 - Mean Q Value 24.771 - Time Delta 6.786 - Time 2025-04-27T04:20:44\n",
            "Episode 304 - Steps this episode 194632 - Epsilon 0.001 - Learning Rate 0.0002477066212875676 - Cummulative Reward 604.02 - Max Length 838 - Mean Loss 1.476 - Mean Q Value 24.786 - Time Delta 5.893 - Time 2025-04-27T04:20:50\n",
            "Episode 305 - Steps this episode 195264 - Epsilon 0.001 - Learning Rate 0.00024769878149648235 - Cummulative Reward 604.05 - Max Length 837 - Mean Loss 1.476 - Mean Q Value 24.801 - Time Delta 5.955 - Time 2025-04-27T04:20:56\n",
            "Episode 306 - Steps this episode 195888 - Epsilon 0.001 - Learning Rate 0.0002476909976837031 - Cummulative Reward 603.98 - Max Length 829 - Mean Loss 1.48 - Mean Q Value 24.815 - Time Delta 5.835 - Time 2025-04-27T04:21:02\n",
            "Episode 307 - Steps this episode 196530 - Epsilon 0.001 - Learning Rate 0.0002476831583876851 - Cummulative Reward 603.96 - Max Length 833 - Mean Loss 1.483 - Mean Q Value 24.83 - Time Delta 6.065 - Time 2025-04-27T04:21:08\n",
            "Episode 308 - Steps this episode 197160 - Epsilon 0.001 - Learning Rate 0.00024767528218749694 - Cummulative Reward 603.89 - Max Length 829 - Mean Loss 1.483 - Mean Q Value 24.844 - Time Delta 5.855 - Time 2025-04-27T04:21:14\n",
            "Episode 309 - Steps this episode 197789 - Epsilon 0.001 - Learning Rate 0.0002476674991133666 - Cummulative Reward 603.78 - Max Length 829 - Mean Loss 1.483 - Mean Q Value 24.857 - Time Delta 5.931 - Time 2025-04-27T04:21:20\n",
            "Episode 310 - Steps this episode 198421 - Epsilon 0.001 - Learning Rate 0.00024765969770962847 - Cummulative Reward 603.65 - Max Length 829 - Mean Loss 1.482 - Mean Q Value 24.872 - Time Delta 5.908 - Time 2025-04-27T04:21:26\n",
            "Episode 311 - Steps this episode 199057 - Epsilon 0.001 - Learning Rate 0.00024765184082985907 - Cummulative Reward 603.58 - Max Length 837 - Mean Loss 1.483 - Mean Q Value 24.886 - Time Delta 5.969 - Time 2025-04-27T04:21:32\n",
            "Episode 312 - Steps this episode 199696 - Epsilon 0.001 - Learning Rate 0.00024764394705274826 - Cummulative Reward 603.77 - Max Length 836 - Mean Loss 1.487 - Mean Q Value 24.902 - Time Delta 5.981 - Time 2025-04-27T04:21:38\n",
            "Episode 313 - Steps this episode 200313 - Epsilon 0.001 - Learning Rate 0.0002476361649627256 - Cummulative Reward 603.69 - Max Length 829 - Mean Loss 1.49 - Mean Q Value 24.918 - Time Delta 5.807 - Time 2025-04-27T04:21:44\n",
            "Episode 314 - Steps this episode 200972 - Epsilon 0.001 - Learning Rate 0.0002476282716864591 - Cummulative Reward 603.57 - Max Length 829 - Mean Loss 1.491 - Mean Q Value 24.933 - Time Delta 6.15 - Time 2025-04-27T04:21:50\n",
            "Episode 315 - Steps this episode 201599 - Epsilon 0.001 - Learning Rate 0.00024762032294492746 - Cummulative Reward 603.61 - Max Length 829 - Mean Loss 1.493 - Mean Q Value 24.949 - Time Delta 5.845 - Time 2025-04-27T04:21:56\n",
            "Episode 316 - Steps this episode 202219 - Epsilon 0.001 - Learning Rate 0.0002476125973106008 - Cummulative Reward 603.74 - Max Length 829 - Mean Loss 1.494 - Mean Q Value 24.965 - Time Delta 5.839 - Time 2025-04-27T04:22:01\n",
            "Episode 317 - Steps this episode 202842 - Epsilon 0.001 - Learning Rate 0.00024760489048796707 - Cummulative Reward 603.66 - Max Length 829 - Mean Loss 1.495 - Mean Q Value 24.979 - Time Delta 5.852 - Time 2025-04-27T04:22:07\n",
            "Episode 318 - Steps this episode 203489 - Epsilon 0.001 - Learning Rate 0.00024759703534751865 - Cummulative Reward 603.69 - Max Length 835 - Mean Loss 1.496 - Mean Q Value 24.994 - Time Delta 6.026 - Time 2025-04-27T04:22:13\n",
            "Episode 319 - Steps this episode 204120 - Epsilon 0.001 - Learning Rate 0.0002475891247476241 - Cummulative Reward 603.6 - Max Length 829 - Mean Loss 1.495 - Mean Q Value 25.01 - Time Delta 5.921 - Time 2025-04-27T04:22:19\n",
            "Episode 320 - Steps this episode 204769 - Epsilon 0.001 - Learning Rate 0.00024758119583276865 - Cummulative Reward 603.51 - Max Length 835 - Mean Loss 1.495 - Mean Q Value 25.024 - Time Delta 6.069 - Time 2025-04-27T04:22:25\n",
            "Episode 321 - Steps this episode 205468 - Epsilon 0.001 - Learning Rate 0.0002475728586775243 - Cummulative Reward 603.43 - Max Length 829 - Mean Loss 1.496 - Mean Q Value 25.038 - Time Delta 6.517 - Time 2025-04-27T04:22:32\n",
            "Episode 322 - Steps this episode 206101 - Epsilon 0.001 - Learning Rate 0.0002475646146357103 - Cummulative Reward 603.41 - Max Length 836 - Mean Loss 1.496 - Mean Q Value 25.054 - Time Delta 5.929 - Time 2025-04-27T04:22:38\n",
            "Episode 323 - Steps this episode 206748 - Epsilon 0.001 - Learning Rate 0.00024755668650577894 - Cummulative Reward 603.37 - Max Length 829 - Mean Loss 1.493 - Mean Q Value 25.068 - Time Delta 6.06 - Time 2025-04-27T04:22:44\n",
            "Episode 324 - Steps this episode 207382 - Epsilon 0.001 - Learning Rate 0.0002475487586287506 - Cummulative Reward 603.4 - Max Length 836 - Mean Loss 1.494 - Mean Q Value 25.082 - Time Delta 5.956 - Time 2025-04-27T04:22:50\n",
            "Episode 325 - Steps this episode 208002 - Epsilon 0.001 - Learning Rate 0.00024754099809584575 - Cummulative Reward 603.34 - Max Length 829 - Mean Loss 1.494 - Mean Q Value 25.094 - Time Delta 5.864 - Time 2025-04-27T04:22:56\n",
            "Episode 326 - Steps this episode 208648 - Epsilon 0.001 - Learning Rate 0.00024753316354743544 - Cummulative Reward 603.28 - Max Length 836 - Mean Loss 1.491 - Mean Q Value 25.105 - Time Delta 6.026 - Time 2025-04-27T04:23:02\n",
            "Episode 327 - Steps this episode 209282 - Epsilon 0.001 - Learning Rate 0.0002475252549882127 - Cummulative Reward 603.21 - Max Length 836 - Mean Loss 1.49 - Mean Q Value 25.115 - Time Delta 5.95 - Time 2025-04-27T04:23:08\n",
            "Episode 328 - Steps this episode 209902 - Epsilon 0.001 - Learning Rate 0.00024751749519213545 - Cummulative Reward 598.35 - Max Length 829 - Mean Loss 1.492 - Mean Q Value 25.127 - Time Delta 5.881 - Time 2025-04-27T04:23:13\n",
            "Episode 329 - Steps this episode 210551 - Epsilon 0.001 - Learning Rate 0.00024750964282445505 - Cummulative Reward 598.34 - Max Length 838 - Mean Loss 1.493 - Mean Q Value 25.14 - Time Delta 6.111 - Time 2025-04-27T04:23:20\n",
            "Episode 330 - Steps this episode 211185 - Epsilon 0.001 - Learning Rate 0.0002475016978914454 - Cummulative Reward 598.23 - Max Length 836 - Mean Loss 1.492 - Mean Q Value 25.154 - Time Delta 5.984 - Time 2025-04-27T04:23:26\n",
            "Episode 331 - Steps this episode 211804 - Epsilon 0.001 - Learning Rate 0.00024749393883367773 - Cummulative Reward 598.17 - Max Length 829 - Mean Loss 1.49 - Mean Q Value 25.165 - Time Delta 6.454 - Time 2025-04-27T04:23:32\n",
            "Episode 332 - Steps this episode 212427 - Epsilon 0.001 - Learning Rate 0.0002474862542657975 - Cummulative Reward 598.3 - Max Length 829 - Mean Loss 1.492 - Mean Q Value 25.176 - Time Delta 5.855 - Time 2025-04-27T04:23:38\n",
            "Episode 333 - Steps this episode 213077 - Epsilon 0.001 - Learning Rate 0.0002474783843282425 - Cummulative Reward 598.41 - Max Length 836 - Mean Loss 1.492 - Mean Q Value 25.186 - Time Delta 6.096 - Time 2025-04-27T04:23:44\n",
            "Episode 334 - Steps this episode 213713 - Epsilon 0.001 - Learning Rate 0.0002474704403986146 - Cummulative Reward 598.34 - Max Length 829 - Mean Loss 1.493 - Mean Q Value 25.197 - Time Delta 5.952 - Time 2025-04-27T04:23:50\n",
            "Episode 335 - Steps this episode 214223 - Epsilon 0.001 - Learning Rate 0.0002474633504678081 - Cummulative Reward 598.35 - Max Length 829 - Mean Loss 1.492 - Mean Q Value 25.207 - Time Delta 4.85 - Time 2025-04-27T04:23:55\n",
            "Episode 336 - Steps this episode 214852 - Epsilon 0.001 - Learning Rate 0.00024745629786581834 - Cummulative Reward 598.27 - Max Length 829 - Mean Loss 1.493 - Mean Q Value 25.217 - Time Delta 5.906 - Time 2025-04-27T04:24:01\n",
            "Episode 337 - Steps this episode 215539 - Epsilon 0.001 - Learning Rate 0.000247448150502663 - Cummulative Reward 598.39 - Max Length 829 - Mean Loss 1.493 - Mean Q Value 25.229 - Time Delta 6.519 - Time 2025-04-27T04:24:07\n",
            "Episode 338 - Steps this episode 216173 - Epsilon 0.001 - Learning Rate 0.00024743998484598207 - Cummulative Reward 598.37 - Max Length 829 - Mean Loss 1.495 - Mean Q Value 25.239 - Time Delta 5.965 - Time 2025-04-27T04:24:13\n",
            "Episode 339 - Steps this episode 216829 - Epsilon 0.001 - Learning Rate 0.0002474320050353467 - Cummulative Reward 598.45 - Max Length 836 - Mean Loss 1.495 - Mean Q Value 25.25 - Time Delta 6.239 - Time 2025-04-27T04:24:19\n",
            "Episode 340 - Steps this episode 217460 - Epsilon 0.001 - Learning Rate 0.00024742404403716643 - Cummulative Reward 598.44 - Max Length 836 - Mean Loss 1.498 - Mean Q Value 25.26 - Time Delta 5.949 - Time 2025-04-27T04:24:25\n",
            "Episode 341 - Steps this episode 218077 - Epsilon 0.001 - Learning Rate 0.00024741632452645376 - Cummulative Reward 598.44 - Max Length 829 - Mean Loss 1.497 - Mean Q Value 25.269 - Time Delta 5.862 - Time 2025-04-27T04:24:31\n",
            "Episode 342 - Steps this episode 218698 - Epsilon 0.001 - Learning Rate 0.00024740866092401437 - Cummulative Reward 598.46 - Max Length 829 - Mean Loss 1.497 - Mean Q Value 25.276 - Time Delta 5.878 - Time 2025-04-27T04:24:37\n",
            "Episode 343 - Steps this episode 219321 - Epsilon 0.001 - Learning Rate 0.00024740096044880225 - Cummulative Reward 598.52 - Max Length 829 - Mean Loss 1.499 - Mean Q Value 25.282 - Time Delta 5.964 - Time 2025-04-27T04:24:43\n",
            "Episode 344 - Steps this episode 219945 - Epsilon 0.001 - Learning Rate 0.0002473932416586723 - Cummulative Reward 598.52 - Max Length 829 - Mean Loss 1.499 - Mean Q Value 25.289 - Time Delta 5.906 - Time 2025-04-27T04:24:49\n",
            "Episode 345 - Steps this episode 220576 - Epsilon 0.001 - Learning Rate 0.0002473854860017302 - Cummulative Reward 598.54 - Max Length 836 - Mean Loss 1.502 - Mean Q Value 25.293 - Time Delta 6.022 - Time 2025-04-27T04:24:55\n",
            "Episode 346 - Steps this episode 221195 - Epsilon 0.001 - Learning Rate 0.00024737776769400956 - Cummulative Reward 598.54 - Max Length 829 - Mean Loss 1.501 - Mean Q Value 25.298 - Time Delta 5.849 - Time 2025-04-27T04:25:01\n",
            "Episode 347 - Steps this episode 221825 - Epsilon 0.001 - Learning Rate 0.00024737004962786823 - Cummulative Reward 598.67 - Max Length 832 - Mean Loss 1.498 - Mean Q Value 25.302 - Time Delta 6.026 - Time 2025-04-27T04:25:07\n",
            "Episode 348 - Steps this episode 222464 - Epsilon 0.001 - Learning Rate 0.00024736220193723543 - Cummulative Reward 598.85 - Max Length 836 - Mean Loss 1.499 - Mean Q Value 25.308 - Time Delta 6.032 - Time 2025-04-27T04:25:13\n",
            "Episode 349 - Steps this episode 223098 - Epsilon 0.001 - Learning Rate 0.00024735431739202106 - Cummulative Reward 598.98 - Max Length 836 - Mean Loss 1.499 - Mean Q Value 25.312 - Time Delta 6.059 - Time 2025-04-27T04:25:19\n",
            "Episode 350 - Steps this episode 223736 - Epsilon 0.001 - Learning Rate 0.0002473464516492053 - Cummulative Reward 598.89 - Max Length 829 - Mean Loss 1.502 - Mean Q Value 25.32 - Time Delta 6.005 - Time 2025-04-27T04:25:25\n",
            "Episode 351 - Steps this episode 224364 - Epsilon 0.001 - Learning Rate 0.00024733862325711405 - Cummulative Reward 598.85 - Max Length 829 - Mean Loss 1.504 - Mean Q Value 25.327 - Time Delta 6.017 - Time 2025-04-27T04:25:31\n",
            "Episode 352 - Steps this episode 225006 - Epsilon 0.001 - Learning Rate 0.00024733075801375705 - Cummulative Reward 598.76 - Max Length 834 - Mean Loss 1.505 - Mean Q Value 25.336 - Time Delta 6.141 - Time 2025-04-27T04:25:37\n",
            "Episode 353 - Steps this episode 225624 - Epsilon 0.001 - Learning Rate 0.00024732296721622314 - Cummulative Reward 598.88 - Max Length 829 - Mean Loss 1.505 - Mean Q Value 25.343 - Time Delta 5.94 - Time 2025-04-27T04:25:43\n",
            "Episode 354 - Steps this episode 226255 - Epsilon 0.001 - Learning Rate 0.00024731525085983 - Cummulative Reward 598.88 - Max Length 843 - Mean Loss 1.506 - Mean Q Value 25.349 - Time Delta 5.967 - Time 2025-04-27T04:25:49\n",
            "Episode 355 - Steps this episode 226887 - Epsilon 0.001 - Learning Rate 0.00024730744200358027 - Cummulative Reward 598.89 - Max Length 836 - Mean Loss 1.505 - Mean Q Value 25.356 - Time Delta 6.053 - Time 2025-04-27T04:25:55\n",
            "Episode 356 - Steps this episode 227538 - Epsilon 0.001 - Learning Rate 0.00024729950356210595 - Cummulative Reward 598.88 - Max Length 837 - Mean Loss 1.504 - Mean Q Value 25.36 - Time Delta 6.186 - Time 2025-04-27T04:26:01\n",
            "Episode 357 - Steps this episode 228162 - Epsilon 0.001 - Learning Rate 0.00024729162101458195 - Cummulative Reward 598.9 - Max Length 829 - Mean Loss 1.502 - Mean Q Value 25.366 - Time Delta 6.014 - Time 2025-04-27T04:26:07\n",
            "Episode 358 - Steps this episode 228779 - Epsilon 0.001 - Learning Rate 0.0002472839612743914 - Cummulative Reward 598.85 - Max Length 829 - Mean Loss 1.5 - Mean Q Value 25.374 - Time Delta 5.879 - Time 2025-04-27T04:26:13\n",
            "Episode 359 - Steps this episode 229407 - Epsilon 0.001 - Learning Rate 0.0002472762646807806 - Cummulative Reward 598.78 - Max Length 829 - Mean Loss 1.501 - Mean Q Value 25.38 - Time Delta 6.038 - Time 2025-04-27T04:26:19\n",
            "Episode 360 - Steps this episode 230032 - Epsilon 0.001 - Learning Rate 0.0002472685126906219 - Cummulative Reward 598.83 - Max Length 829 - Mean Loss 1.501 - Mean Q Value 25.389 - Time Delta 5.956 - Time 2025-04-27T04:26:25\n",
            "Episode 361 - Steps this episode 230662 - Epsilon 0.001 - Learning Rate 0.0002472607609438719 - Cummulative Reward 598.87 - Max Length 829 - Mean Loss 1.5 - Mean Q Value 25.395 - Time Delta 6.043 - Time 2025-04-27T04:26:31\n",
            "Episode 362 - Steps this episode 231153 - Epsilon 0.001 - Learning Rate 0.00024725382537229196 - Cummulative Reward 600.07 - Max Length 942 - Mean Loss 1.5 - Mean Q Value 25.402 - Time Delta 4.803 - Time 2025-04-27T04:26:36\n",
            "Episode 363 - Steps this episode 231771 - Epsilon 0.001 - Learning Rate 0.0002472469641769261 - Cummulative Reward 600.02 - Max Length 829 - Mean Loss 1.501 - Mean Q Value 25.409 - Time Delta 5.944 - Time 2025-04-27T04:26:42\n",
            "Episode 364 - Steps this episode 232400 - Epsilon 0.001 - Learning Rate 0.0002472392687346396 - Cummulative Reward 600.02 - Max Length 832 - Mean Loss 1.501 - Mean Q Value 25.415 - Time Delta 6.059 - Time 2025-04-27T04:26:48\n",
            "Episode 365 - Steps this episode 233023 - Epsilon 0.001 - Learning Rate 0.0002472315364467488 - Cummulative Reward 599.99 - Max Length 829 - Mean Loss 1.501 - Mean Q Value 25.42 - Time Delta 6.679 - Time 2025-04-27T04:26:55\n",
            "Episode 366 - Steps this episode 233643 - Epsilon 0.001 - Learning Rate 0.0002472238414842582 - Cummulative Reward 599.99 - Max Length 829 - Mean Loss 1.501 - Mean Q Value 25.429 - Time Delta 5.955 - Time 2025-04-27T04:27:01\n",
            "Episode 367 - Steps this episode 234267 - Epsilon 0.001 - Learning Rate 0.00024721614676146206 - Cummulative Reward 600.04 - Max Length 829 - Mean Loss 1.501 - Mean Q Value 25.435 - Time Delta 5.992 - Time 2025-04-27T04:27:07\n",
            "Episode 368 - Steps this episode 234884 - Epsilon 0.001 - Learning Rate 0.00024720848935905047 - Cummulative Reward 600.05 - Max Length 829 - Mean Loss 1.5 - Mean Q Value 25.44 - Time Delta 5.933 - Time 2025-04-27T04:27:13\n",
            "Episode 369 - Steps this episode 235513 - Epsilon 0.001 - Learning Rate 0.00024720079511446655 - Cummulative Reward 600.04 - Max Length 829 - Mean Loss 1.503 - Mean Q Value 25.445 - Time Delta 6.034 - Time 2025-04-27T04:27:19\n",
            "Episode 370 - Steps this episode 236163 - Epsilon 0.001 - Learning Rate 0.00024719287863586673 - Cummulative Reward 600.08 - Max Length 835 - Mean Loss 1.504 - Mean Q Value 25.449 - Time Delta 6.251 - Time 2025-04-27T04:27:25\n",
            "Episode 371 - Steps this episode 236783 - Epsilon 0.001 - Learning Rate 0.0002471850365645223 - Cummulative Reward 600.1 - Max Length 829 - Mean Loss 1.504 - Mean Q Value 25.453 - Time Delta 5.96 - Time 2025-04-27T04:27:31\n",
            "Episode 372 - Steps this episode 237433 - Epsilon 0.001 - Learning Rate 0.0002471771947441202 - Cummulative Reward 600.1 - Max Length 832 - Mean Loss 1.505 - Mean Q Value 25.458 - Time Delta 6.271 - Time 2025-04-27T04:27:37\n",
            "Episode 373 - Steps this episode 238053 - Epsilon 0.001 - Learning Rate 0.00024716933463273286 - Cummulative Reward 600.12 - Max Length 829 - Mean Loss 1.506 - Mean Q Value 25.464 - Time Delta 5.958 - Time 2025-04-27T04:27:43\n",
            "Episode 374 - Steps this episode 238673 - Epsilon 0.001 - Learning Rate 0.0002471616786804961 - Cummulative Reward 600.15 - Max Length 829 - Mean Loss 1.509 - Mean Q Value 25.474 - Time Delta 5.943 - Time 2025-04-27T04:27:49\n",
            "Episode 375 - Steps this episode 239290 - Epsilon 0.001 - Learning Rate 0.00024715404150204835 - Cummulative Reward 600.2 - Max Length 829 - Mean Loss 1.51 - Mean Q Value 25.482 - Time Delta 5.946 - Time 2025-04-27T04:27:55\n",
            "Episode 376 - Steps this episode 239918 - Epsilon 0.001 - Learning Rate 0.0002471463489519352 - Cummulative Reward 600.2 - Max Length 829 - Mean Loss 1.511 - Mean Q Value 25.49 - Time Delta 6.07 - Time 2025-04-27T04:28:01\n",
            "Episode 377 - Steps this episode 240560 - Epsilon 0.001 - Learning Rate 0.00024713850835829 - Cummulative Reward 600.14 - Max Length 836 - Mean Loss 1.51 - Mean Q Value 25.496 - Time Delta 6.205 - Time 2025-04-27T04:28:07\n",
            "Episode 378 - Steps this episode 241193 - Epsilon 0.001 - Learning Rate 0.00024713063094299807 - Cummulative Reward 600.15 - Max Length 836 - Mean Loss 1.508 - Mean Q Value 25.502 - Time Delta 6.122 - Time 2025-04-27T04:28:13\n",
            "Episode 379 - Steps this episode 241813 - Epsilon 0.001 - Learning Rate 0.0002471228835181924 - Cummulative Reward 600.17 - Max Length 829 - Mean Loss 1.507 - Mean Q Value 25.51 - Time Delta 6.009 - Time 2025-04-27T04:28:19\n",
            "Episode 380 - Steps this episode 242454 - Epsilon 0.001 - Learning Rate 0.000247115080736431 - Cummulative Reward 600.24 - Max Length 837 - Mean Loss 1.508 - Mean Q Value 25.515 - Time Delta 6.199 - Time 2025-04-27T04:28:26\n",
            "Episode 381 - Steps this episode 243089 - Epsilon 0.001 - Learning Rate 0.00024710720406788265 - Cummulative Reward 600.34 - Max Length 838 - Mean Loss 1.509 - Mean Q Value 25.519 - Time Delta 6.152 - Time 2025-04-27T04:28:32\n",
            "Episode 382 - Steps this episode 243707 - Epsilon 0.001 - Learning Rate 0.00024709947590986374 - Cummulative Reward 600.34 - Max Length 829 - Mean Loss 1.512 - Mean Q Value 25.524 - Time Delta 5.999 - Time 2025-04-27T04:28:38\n",
            "Episode 383 - Steps this episode 244352 - Epsilon 0.001 - Learning Rate 0.0002470916738673812 - Cummulative Reward 594.7 - Max Length 837 - Mean Loss 1.514 - Mean Q Value 25.527 - Time Delta 6.276 - Time 2025-04-27T04:28:44\n",
            "Episode 384 - Steps this episode 244974 - Epsilon 0.001 - Learning Rate 0.0002470838350070998 - Cummulative Reward 594.62 - Max Length 829 - Mean Loss 1.513 - Mean Q Value 25.529 - Time Delta 6.036 - Time 2025-04-27T04:28:50\n",
            "Episode 385 - Steps this episode 245592 - Epsilon 0.001 - Learning Rate 0.00024707616317236276 - Cummulative Reward 594.62 - Max Length 829 - Mean Loss 1.514 - Mean Q Value 25.531 - Time Delta 6.003 - Time 2025-04-27T04:28:56\n",
            "Episode 386 - Steps this episode 246230 - Epsilon 0.001 - Learning Rate 0.0002470684174560633 - Cummulative Reward 594.74 - Max Length 837 - Mean Loss 1.515 - Mean Q Value 25.535 - Time Delta 6.188 - Time 2025-04-27T04:29:02\n",
            "Episode 387 - Steps this episode 246874 - Epsilon 0.001 - Learning Rate 0.00024706050521639423 - Cummulative Reward 594.78 - Max Length 836 - Mean Loss 1.513 - Mean Q Value 25.54 - Time Delta 6.339 - Time 2025-04-27T04:29:09\n",
            "Episode 388 - Steps this episode 247504 - Epsilon 0.001 - Learning Rate 0.00024705263028721624 - Cummulative Reward 594.78 - Max Length 838 - Mean Loss 1.514 - Mean Q Value 25.544 - Time Delta 6.153 - Time 2025-04-27T04:29:15\n",
            "Episode 389 - Steps this episode 248125 - Epsilon 0.001 - Learning Rate 0.0002470449038361591 - Cummulative Reward 594.78 - Max Length 829 - Mean Loss 1.519 - Mean Q Value 25.549 - Time Delta 6.108 - Time 2025-04-27T04:29:21\n",
            "Episode 390 - Steps this episode 248753 - Epsilon 0.001 - Learning Rate 0.0002470371961550156 - Cummulative Reward 594.9 - Max Length 829 - Mean Loss 1.521 - Mean Q Value 25.553 - Time Delta 6.104 - Time 2025-04-27T04:29:27\n",
            "Episode 391 - Steps this episode 249382 - Epsilon 0.001 - Learning Rate 0.00024702943313261957 - Cummulative Reward 594.9 - Max Length 829 - Mean Loss 1.521 - Mean Q Value 25.557 - Time Delta 6.149 - Time 2025-04-27T04:29:33\n",
            "Episode 392 - Steps this episode 250011 - Epsilon 0.001 - Learning Rate 0.00024702165182744976 - Cummulative Reward 594.92 - Max Length 836 - Mean Loss 1.521 - Mean Q Value 25.561 - Time Delta 6.101 - Time 2025-04-27T04:29:39\n",
            "Episode 393 - Steps this episode 250629 - Epsilon 0.001 - Learning Rate 0.00024701394487117975 - Cummulative Reward 595.04 - Max Length 829 - Mean Loss 1.522 - Mean Q Value 25.566 - Time Delta 6.082 - Time 2025-04-27T04:29:45\n",
            "Episode 394 - Steps this episode 251269 - Epsilon 0.001 - Learning Rate 0.00024700618258002605 - Cummulative Reward 595.05 - Max Length 836 - Mean Loss 1.522 - Mean Q Value 25.571 - Time Delta 6.263 - Time 2025-04-27T04:29:51\n",
            "Episode 395 - Steps this episode 251957 - Epsilon 0.001 - Learning Rate 0.00024699799446181714 - Cummulative Reward 595.11 - Max Length 836 - Mean Loss 1.524 - Mean Q Value 25.58 - Time Delta 6.754 - Time 2025-04-27T04:29:58\n",
            "Episode 396 - Steps this episode 252575 - Epsilon 0.001 - Learning Rate 0.0002469899362807778 - Cummulative Reward 595.12 - Max Length 829 - Mean Loss 1.525 - Mean Q Value 25.586 - Time Delta 6.02 - Time 2025-04-27T04:30:04\n",
            "Episode 397 - Steps this episode 253220 - Epsilon 0.001 - Learning Rate 0.0002469821376969543 - Cummulative Reward 595.2 - Max Length 835 - Mean Loss 1.525 - Mean Q Value 25.591 - Time Delta 6.357 - Time 2025-04-27T04:30:11\n",
            "Episode 398 - Steps this episode 253849 - Epsilon 0.001 - Learning Rate 0.00024697426526570145 - Cummulative Reward 595.23 - Max Length 836 - Mean Loss 1.525 - Mean Q Value 25.6 - Time Delta 6.161 - Time 2025-04-27T04:30:17\n",
            "Episode 399 - Steps this episode 254489 - Epsilon 0.001 - Learning Rate 0.00024696643013112884 - Cummulative Reward 595.29 - Max Length 836 - Mean Loss 1.526 - Mean Q Value 25.605 - Time Delta 6.336 - Time 2025-04-27T04:30:23\n",
            "MarioNet saved to checkpoints/Super_Mario_Land/2025-04-27T03-53-55/mario_net_00.chkpt at step 254489\n",
            "MarioNet saved to checkpoints/Super_Mario_Land/2025-04-27T03-53-55-boss/mario_net_00.chkpt at step 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hzro71ndoER-"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}